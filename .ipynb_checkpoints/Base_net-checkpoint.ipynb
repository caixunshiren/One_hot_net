{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c291a2e1f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "random_seed = 420\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network flowchart:\n",
    "#input vector --- random initialized weights ---> hyperdimensional vecotor ---> one_hot_net l1 ---> ...ln... ---> sigmoid/softmax output\n",
    "#One hot net\n",
    "\n",
    "class One_hot_op(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A, W, epsilon):\n",
    "        Z = torch.matmul(W, A)\n",
    "        ctx.Z = Z\n",
    "        ctx.A = A\n",
    "        ctx.W = W\n",
    "        ctx.epsilon = epsilon\n",
    "        ret = Z > epsilon\n",
    "        #print(ret[1:10][1:10])\n",
    "        return ret.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dA):\n",
    "        step = ctx.Z > ctx.epsilon\n",
    "        step = step.float()\n",
    "        dL_dZ = dL_dA * step \n",
    "        \n",
    "        dZ_dW = torch.transpose(ctx.A, 0,1)\n",
    "        dZ_dW = torch.sign(dZ_dW)\n",
    "        dZ_dA = torch.transpose(ctx.W, 0,1)\n",
    "        dZ_dA = torch.sign(dZ_dA)\n",
    "        dA = torch.matmul(dZ_dA,dL_dZ)\n",
    "        dW = torch.matmul(dL_dZ,dZ_dW)\n",
    "        return dA, dW, None\n",
    "\n",
    "\n",
    "class One_hot_layer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, initialization_f, epsilon):\n",
    "        super(One_hot_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.initialization_f = initialization_f\n",
    "        initialized_weight = initialization_f(out_dim, in_dim)\n",
    "        self.weight = nn.Parameter(initialized_weight, requires_grad = True)\n",
    "        self.op = One_hot_op\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_dim) + ',' \\\n",
    "               + str(self.out_dim) + ')'\n",
    "        \n",
    "    def forward(self, A):\n",
    "        #print(self.weight[:3][:3])\n",
    "        return self.op.apply(A, self.weight, self.epsilon)\n",
    "    \n",
    "\n",
    "class One_hot_net(nn.Module):\n",
    "    def __init__(self, in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers=2, layer_size_factor=[1, 5], dropout=[-1, 0.5]):\n",
    "        super(One_hot_net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.in_dim = in_dim\n",
    "        feature_len = in_dim * encoder_multiplier\n",
    "        self.feature_len = feature_len\n",
    "        self.n_layers=n_layers\n",
    "        self.layer_size_factor=layer_size_factor\n",
    "        self.dropout=dropout\n",
    "        self.epsilon = epsilon\n",
    "        self.n_class = n_class\n",
    "        self.f_encoder = f_encoder\n",
    "        self.f_initializer = f_initializer\n",
    "        for i in range(n_layers):\n",
    "            if dropout[i] > 0:\n",
    "                self.layers.append(nn.Dropout(dropout[i]))\n",
    "            if i < n_layers - 1:\n",
    "                self.layers.append(\n",
    "                    One_hot_layer(int(feature_len // layer_size_factor[i]), int(feature_len // layer_size_factor[i + 1]), f_initializer, epsilon))\n",
    "        self.tail = nn.Linear(int(feature_len // layer_size_factor[-1]), n_class)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def flatten(self, X):\n",
    "        return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.f_encoder.apply(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.tail(X)\n",
    "        return self.out(X)\n",
    "\n",
    "class toy_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_Net, self).__init__()\n",
    "        self.fc2 = nn.Linear(784, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "    def flatten(self, X):\n",
    "            return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = (x > -0.4).float()\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "class toy_Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 784*20)\n",
    "        self.fc2 = nn.Linear(784*20, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "    def flatten(self, X):\n",
    "            return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializers and encoders\n",
    "def uniform_initializer(out_dim, in_dim, cuda = True):\n",
    "    tensor = torch.empty(out_dim, in_dim)\n",
    "    if cuda:\n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2).cuda()\n",
    "    else: \n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2)\n",
    "\n",
    "class simple_encoder():\n",
    "    def __init__(self, out_dim, in_dim):\n",
    "        self.W = uniform_initializer(out_dim, in_dim)\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return torch.matmul(self.W, X)\n",
    "    \n",
    "class simple_encoder_wthreshold():\n",
    "    def __init__(self, out_dim, in_dim, epsilon, cuda = True):\n",
    "        self.W = uniform_initializer(out_dim, in_dim, cuda)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return (torch.matmul(self.W, X) > self.epsilon).float()\n",
    "    \n",
    "class non_linear_encoder():\n",
    "    def __init__(self, out_dim, in_dim, activation, cuda = True):\n",
    "        self.W = uniform_initializer(out_dim, in_dim, cuda)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return self.activation((torch.matmul(self.W, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'in_dim': 784,\n",
    "    'n_class': 10,\n",
    "    'f_encoder': non_linear_encoder(784*20, 784, nn.Sigmoid()),\n",
    "    'f_initializer': uniform_initializer,\n",
    "    'encoder_multiplier': 20,\n",
    "    'epsilon': 10e-3,\n",
    "    'n_layers': 2,\n",
    "    'layer_size_factor': [1, 1, 1],\n",
    "    'dropout': [-1, -1, -1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model1 = One_hot_net(parameters['in_dim'], parameters['n_class'], parameters['f_encoder'], parameters['encoder_multiplier'], \n",
    "                     parameters['f_initializer'], parameters['epsilon'], parameters['n_layers'], \n",
    "                     parameters['layer_size_factor'], parameters['dropout']).to(device)\n",
    "\n",
    "#model1 = toy_Net2().to(device)\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer1 = torch.optim.SGD([{'params': model1.layers.parameters(), 'lr': 0.01}, {'params': model1.tail.parameters(), 'lr': 0.01}], lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 15680]      12,308,800\n",
      "            Linear-2                   [-1, 10]         156,810\n",
      "        LogSoftmax-3                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 12,465,610\n",
      "Trainable params: 12,465,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 47.55\n",
      "Estimated Total Size (MB): 47.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model1, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, trainloader, log_interval = 10, device = torch.device(\"cuda:0\")):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(model.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device = torch.device(\"cuda:0\")):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3110, Accuracy: 1092/10000 (10.9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319737\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.108468\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.707941\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.603052\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.393216\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.356164\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.422954\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.369583\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.345813\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.522532\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.260564\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.436767\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.280520\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.360268\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.285464\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.354857\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.346182\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.514608\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.370186\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.176185\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.247562\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.505785\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.209104\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.353750\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.339861\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.255077\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.406413\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.220902\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.174421\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.308914\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.327596\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.307028\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.493292\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.493782\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.387684\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.256900\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.200821\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.307143\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.326165\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.191280\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.214348\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.216226\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.304768\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.372313\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.155585\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.211549\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.262784\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.179148\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.167900\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.157958\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.202445\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.155693\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.242843\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.137274\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.140440\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.233246\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.281315\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.307715\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.329177\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.089510\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.184558\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.205953\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.289243\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.291347\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.134809\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.088929\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.336580\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.215111\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.197949\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.276309\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.092410\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.081278\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.424207\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.235608\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.159835\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.264929\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.271242\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.105580\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.142774\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.093821\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.250918\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.203388\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.068669\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.130245\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.157713\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.158786\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.281968\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.071827\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.087441\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.160761\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.332979\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.080036\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.366798\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.152612\n",
      "\n",
      "Test set: Avg. loss: 0.1873, Accuracy: 9468/10000 (94.7%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.194496\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.219709\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.091488\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.262898\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.236812\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.218785\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.137782\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.306282\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.256213\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.149172\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.121538\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.239585\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.220417\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.229970\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.100714\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.277408\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.159067\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.267911\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.163074\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.044637\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.152429\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.073026\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.105178\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.065217\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.105119\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.118140\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.153095\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.103362\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.225799\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.210072\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.116377\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.102832\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.140227\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.070623\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.124202\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.218082\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.131820\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.144869\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.196026\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.180047\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.289356\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.314806\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.189575\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.071628\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.067199\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.264160\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.094851\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.173192\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.166388\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.080283\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.190131\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.137130\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.191779\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.078190\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.083838\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.163666\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.216216\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.163236\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.114720\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.096225\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.041001\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.093304\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.079442\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.116980\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.083825\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.223818\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.248420\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.218278\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.116204\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.182393\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.049738\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.109546\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.105816\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.111398\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.240117\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.053930\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.290037\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.189116\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.047374\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.093513\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.096251\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.140274\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.157372\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.148855\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.126944\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.087694\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.147902\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.067142\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.154007\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.247867\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.148393\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.158263\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.065577\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.224303\n",
      "\n",
      "Test set: Avg. loss: 0.1412, Accuracy: 9585/10000 (95.8%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.082120\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.166646\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.113452\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.197722\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.106301\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.253262\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.134910\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.138709\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.165732\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.231500\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.171172\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.050755\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.163857\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.224042\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.217817\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.082161\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.161786\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.035894\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.052444\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.098987\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.199295\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.060070\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.110455\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.082439\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.101489\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.181378\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.066525\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.131695\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.229167\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.224202\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.089497\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.048959\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.075344\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.143919\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.141160\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.115035\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.069781\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.049453\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.080954\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.087065\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.117239\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.210630\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.192461\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.084764\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.170925\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.023604\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.059026\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.125700\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.059660\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.112763\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.107900\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.171818\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.227576\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.248582\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.310445\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.074826\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.113649\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.055286\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.092104\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.090293\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.074683\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.071101\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.063144\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.105259\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.220647\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.103855\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.145147\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.282958\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.120003\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.111962\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.158349\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.186437\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.331203\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.056418\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.138521\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.134957\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.107254\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.112825\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.074290\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.158298\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.081281\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.067507\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.082297\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.141724\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.108372\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.063068\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.053807\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.073108\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.078281\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.060465\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.114604\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.198428\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.193764\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.094410\n",
      "\n",
      "Test set: Avg. loss: 0.1197, Accuracy: 9665/10000 (96.6%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.043755\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.083610\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.229810\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.112919\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.084710\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.171914\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.111993\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.092361\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.111064\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.140775\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.044574\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.080781\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.017061\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.209945\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.116914\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.174981\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.109082\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.090865\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.171126\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.146398\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.093937\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.054651\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.160995\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.115296\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.229223\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.065638\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.110563\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.049448\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.072349\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.102038\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.105492\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.103118\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.082261\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.103921\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.126789\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.081741\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.097036\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.179798\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.165645\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.153306\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.040893\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.048285\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.215371\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.098440\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.122790\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.034986\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.037619\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.179697\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.081472\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.066453\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.091706\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.071232\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.096644\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.066923\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.061211\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.075845\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.022668\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.160097\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.037999\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.162620\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.064436\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.131919\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.048017\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.080689\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.162252\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.179712\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.139863\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.042936\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.068504\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.030285\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.101581\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.081739\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.055390\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.205433\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.121326\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.090563\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.057956\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.063699\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.064673\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.090062\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.030177\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.130858\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.041682\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.084092\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.193356\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.137290\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.047406\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.144034\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.236060\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.033765\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.098163\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.060669\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.143523\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.011966\n",
      "\n",
      "Test set: Avg. loss: 0.1027, Accuracy: 9693/10000 (96.9%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.045925\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.116181\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.070150\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.048470\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.094884\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.042721\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.049064\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.087405\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.116885\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.043481\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.038891\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.061071\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.067282\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.118738\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.042052\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.126265\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.023045\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.112552\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.053632\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.042474\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.078090\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.200356\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.044941\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.025217\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.065436\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.059099\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.072115\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.061449\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.038644\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.148982\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.077480\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.024843\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.107982\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.037709\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.084942\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.075688\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.125797\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.039384\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.043884\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.097362\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.055273\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.051606\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.039142\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.029675\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.057317\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.083686\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.048056\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.133386\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.089630\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.085954\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.088454\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.026567\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.103482\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.134473\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.082075\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.078722\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.075541\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.078582\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.102088\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.080473\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.083891\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.085313\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.036011\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.093392\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.062992\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.143029\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.031854\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.049064\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.022527\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.081814\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.087323\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.032945\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.040705\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.145080\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.057666\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.059337\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.041421\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.076747\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.046116\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.245209\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.031125\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.171129\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.084264\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.051217\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.140612\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.042011\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.063998\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.021307\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.083849\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.052979\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.224119\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.078587\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.048990\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.070461\n",
      "\n",
      "Test set: Avg. loss: 0.0908, Accuracy: 9740/10000 (97.4%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.031632\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.035443\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.077244\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.034429\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.029097\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.084381\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.077416\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.057326\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.035113\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.056461\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.046840\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.060230\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.077224\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.054175\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.082956\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.096538\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.045529\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.026528\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.121750\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.054941\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.096881\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.171031\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.124294\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.040369\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.108453\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.012852\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.029686\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.078485\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.056331\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.041948\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.071020\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.034325\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.104401\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.044802\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.107022\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.046923\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.083096\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.059153\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.120083\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.056774\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.032012\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.031213\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.027207\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.208789\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.118607\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.056412\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.035809\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.050406\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.080436\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.092096\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.100606\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.020980\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.024358\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.043763\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.075045\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.186709\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.054947\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.082196\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.137361\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.115976\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.071559\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.157750\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.060759\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.174178\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.093229\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.073812\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.026821\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.040080\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.177715\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.018127\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.063113\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.025600\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.056902\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.018467\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.045105\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.081115\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.065199\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.070881\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.057338\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.054099\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.094023\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.110918\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.059909\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.036107\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.039542\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.033844\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.071344\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.018214\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.036813\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.045832\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.048610\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.049199\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.040969\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.084545\n",
      "\n",
      "Test set: Avg. loss: 0.0835, Accuracy: 9748/10000 (97.5%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.047039\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.023465\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.033485\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.066040\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.034567\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.056199\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.012991\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.025029\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.035222\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.054545\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.093945\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.095756\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.037951\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.095689\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.041825\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.041592\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.062536\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.033261\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.055435\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.032360\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.086909\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.034365\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.059277\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.073453\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.037387\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.028748\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.028626\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.033695\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.019706\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.017207\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.030537\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.148437\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.043568\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.126926\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.132727\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.046709\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.068917\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.013494\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.045151\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.039469\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.023400\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.052267\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.043359\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.061187\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.034469\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.028110\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.066533\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.086732\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.101763\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.084696\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.040787\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.020274\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.055545\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.082226\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.030755\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.111226\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.028093\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.030049\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.035928\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.096527\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.038148\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.052668\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.034175\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.017410\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.037006\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.024222\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.012726\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.149721\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.131013\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.131340\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.061620\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.044157\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.052140\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.079979\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.039038\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.051626\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.031141\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.007938\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.061733\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.043024\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.049268\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.032914\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.011196\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.020256\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.140529\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.048918\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.068470\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.017295\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.041639\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.023684\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.102425\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.116940\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.110310\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.024214\n",
      "\n",
      "Test set: Avg. loss: 0.0801, Accuracy: 9753/10000 (97.5%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.041204\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.028047\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.137152\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.082377\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.031577\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.017767\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.028499\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.048153\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.059820\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.030967\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.038078\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.066991\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.023744\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.060507\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.059837\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.036789\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.078541\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.021877\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.024313\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.019538\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.031171\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.055573\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.086829\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.019008\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.019237\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.094043\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.151316\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.044581\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.035311\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.020691\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.028468\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.045704\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.018984\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.129211\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.017354\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.051873\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.022870\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.051838\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.066524\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.060747\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.039375\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.034686\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.031697\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.011743\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.038715\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.020953\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.018023\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.028600\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.014254\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.040437\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.043546\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.054884\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.055085\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.048041\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.070694\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.030043\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.035537\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.050989\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.045694\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.032632\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.039998\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.040494\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.076215\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.032663\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.032204\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.057355\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.014474\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.025910\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.104972\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.052768\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.009758\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.015994\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.193298\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.036140\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.027329\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.061659\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.019056\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.051260\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.036570\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.049640\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.047450\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.031648\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.077536\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.130799\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.048814\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.034197\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.116373\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.025945\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.050199\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.034997\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.046676\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.062924\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.112378\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.198393\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 9771/10000 (97.7%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.027303\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.039778\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.033475\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.015446\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.057756\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.033845\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.036122\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.039933\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.019496\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.024296\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.013476\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.079218\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.039291\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.014023\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.075897\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.008605\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.071522\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.075909\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.093170\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.019210\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.031513\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.024459\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.032984\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.082002\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.016369\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.043213\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.028231\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.080747\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.034033\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.092255\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.019313\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.007617\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.037316\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.029560\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.040552\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.017005\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.028233\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.040966\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.057696\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.024746\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.059513\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.095789\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.091458\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.042722\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.013329\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.078317\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.021124\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.030377\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.035008\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.094469\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.050263\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.017094\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.009735\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.054208\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.024182\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.024404\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.030201\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.045402\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.055348\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.037300\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.073572\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.058271\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.117661\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.077622\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.052136\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.024677\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.068238\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.035686\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.031405\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.053010\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.045412\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.032184\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.016083\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.013459\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.127585\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.015885\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.065533\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.079763\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.035668\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.018271\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.123560\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.027391\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.034892\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.079452\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.025103\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.020980\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.017358\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.013741\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.033360\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.020518\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.009377\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.032483\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.105142\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.064567\n",
      "\n",
      "Test set: Avg. loss: 0.0758, Accuracy: 9763/10000 (97.6%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.012915\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.025979\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.034623\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.015471\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.041387\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.037242\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.034166\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.086952\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.032461\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.025241\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.041222\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.046226\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.011878\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.013867\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.056205\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.038279\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.049769\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.038308\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.016660\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.019217\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.083690\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.043465\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.035861\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.022102\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.044233\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.026462\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.025022\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.018972\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.022536\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.015376\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.106918\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.046429\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.025604\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.026203\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.034504\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.012986\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.031656\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.025646\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.025351\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.032367\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.022947\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.087732\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.028556\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.049471\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.014496\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.017429\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.011413\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.030528\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.020673\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.009178\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.068448\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.033787\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.014120\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.038795\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.023585\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.022634\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.031861\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.099743\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.017892\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.111575\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.053992\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.070464\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.045198\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.027630\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.016279\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.027067\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.005624\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.076865\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.039592\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.017714\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.062427\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.059206\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.121832\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.029982\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.011340\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.028170\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.056431\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.026933\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.045286\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.036355\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.112453\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.043408\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.061624\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.035419\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.013898\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.028680\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.030490\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.016639\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.040577\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.012029\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.015566\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.038503\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.048376\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.021548\n",
      "\n",
      "Test set: Avg. loss: 0.0713, Accuracy: 9782/10000 (97.8%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.010107\n",
      "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.013535\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.015065\n",
      "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.050378\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.039279\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.060003\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.022576\n",
      "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.014765\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.019609\n",
      "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.033352\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.022040\n",
      "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.034151\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.074028\n",
      "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.038861\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.018137\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.035614\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.039083\n",
      "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.025334\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.006302\n",
      "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.017520\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.016219\n",
      "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.027893\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.021698\n",
      "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.036999\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.050335\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.025907\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.050820\n",
      "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.037490\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.023341\n",
      "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.029573\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.049150\n",
      "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.016394\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.020626\n",
      "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.014730\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.031612\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.018034\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.023561\n",
      "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.030556\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.018571\n",
      "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.018792\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.064674\n",
      "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.019703\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.028839\n",
      "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.024825\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.034276\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.015991\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.067173\n",
      "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.031153\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.017309\n",
      "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.062383\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.116473\n",
      "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.011728\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.092291\n",
      "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.033684\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.008893\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.036767\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.022521\n",
      "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.066943\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.033143\n",
      "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.020095\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.013306\n",
      "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.048261\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.028860\n",
      "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.016274\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.010640\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.025382\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.019773\n",
      "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.035843\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.041879\n",
      "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.083015\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.060666\n",
      "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.030582\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.048497\n",
      "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.029791\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.012567\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.025286\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.041832\n",
      "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.022066\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.060591\n",
      "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.023858\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.024543\n",
      "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.019973\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.040965\n",
      "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.044336\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.020085\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.110075\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.014524\n",
      "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.027731\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.016288\n",
      "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.057061\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.035948\n",
      "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.040734\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.040158\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.030622\n",
      "\n",
      "Test set: Avg. loss: 0.0673, Accuracy: 9799/10000 (98.0%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.008352\n",
      "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.021891\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.036607\n",
      "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.024372\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.015355\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.022024\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.019451\n",
      "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.113243\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.047609\n",
      "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.018241\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.041808\n",
      "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.045877\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.013861\n",
      "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.006385\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.013498\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.054048\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.008639\n",
      "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.031758\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.006361\n",
      "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.031128\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.019958\n",
      "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.027809\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.030646\n",
      "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.019993\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.021153\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.129643\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.019396\n",
      "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.037734\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.023741\n",
      "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.014223\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.013370\n",
      "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.028546\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.039328\n",
      "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.038265\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.016492\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.018379\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.020868\n",
      "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.014795\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.063576\n",
      "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.025399\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.026929\n",
      "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.034533\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.045894\n",
      "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.005558\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.037606\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.017512\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.071056\n",
      "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.018479\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.070052\n",
      "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.015332\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.011369\n",
      "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.042364\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.027861\n",
      "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.111804\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.035315\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.027348\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.036032\n",
      "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.052715\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.014362\n",
      "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.022885\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.055779\n",
      "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.019968\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.015140\n",
      "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.016678\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.047998\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.010893\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.008502\n",
      "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.024614\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.013491\n",
      "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.040196\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.010056\n",
      "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.009747\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.023826\n",
      "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.021459\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.013675\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.022269\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.013843\n",
      "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.020536\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.022818\n",
      "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.022659\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.016652\n",
      "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.028460\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.017009\n",
      "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.022552\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.035164\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.019363\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.006835\n",
      "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.008233\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.042987\n",
      "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.018637\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.014256\n",
      "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.007287\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.025158\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.021097\n",
      "\n",
      "Test set: Avg. loss: 0.0658, Accuracy: 9793/10000 (97.9%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.014688\n",
      "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.011901\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.036344\n",
      "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.025477\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.017996\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.015098\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.013304\n",
      "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.010276\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.023783\n",
      "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.020438\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.021651\n",
      "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.023706\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.019140\n",
      "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.009518\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.026163\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.009391\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.020623\n",
      "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.017825\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.007275\n",
      "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.053338\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.008835\n",
      "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.015245\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.039936\n",
      "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.019006\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.020635\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.037936\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.086051\n",
      "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.040121\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.024299\n",
      "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.012869\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.012530\n",
      "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.048307\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.028178\n",
      "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.006049\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.022434\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.063842\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.037863\n",
      "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.014149\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.044823\n",
      "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.055404\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.031106\n",
      "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.066921\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.031632\n",
      "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.012613\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.043671\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.020719\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.023222\n",
      "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.016602\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.017035\n",
      "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.017367\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.081416\n",
      "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.043631\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.017957\n",
      "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.031816\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.014893\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.060940\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.013321\n",
      "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.014274\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.012763\n",
      "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.047541\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.015037\n",
      "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.017093\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.055680\n",
      "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.095080\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.070041\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.012227\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.006563\n",
      "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.027765\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.030484\n",
      "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.027241\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.013523\n",
      "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.015181\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.039325\n",
      "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.042861\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.021030\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.017412\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.008008\n",
      "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.009224\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.027269\n",
      "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.018139\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.015841\n",
      "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.080469\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.040092\n",
      "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.013468\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.021706\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.011808\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.023099\n",
      "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.022131\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.009284\n",
      "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.007711\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.019346\n",
      "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.007762\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.006002\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.013690\n",
      "\n",
      "Test set: Avg. loss: 0.0642, Accuracy: 9804/10000 (98.0%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.010052\n",
      "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.011681\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.017560\n",
      "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.005692\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.013743\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.012693\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.026899\n",
      "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.006669\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.030259\n",
      "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.011297\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.010162\n",
      "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.033315\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.008596\n",
      "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.018217\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.023704\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.022547\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.100692\n",
      "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.029863\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.011330\n",
      "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.072013\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.015204\n",
      "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.007945\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.013199\n",
      "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.004960\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.006179\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.013349\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.034377\n",
      "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.008645\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.027118\n",
      "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.013318\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.011544\n",
      "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.014037\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.019598\n",
      "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.035825\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.009901\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.027502\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.051645\n",
      "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.016454\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.015570\n",
      "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.023002\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.016140\n",
      "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.012167\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.025768\n",
      "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.088448\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.007837\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.026531\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.025215\n",
      "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.028717\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.018118\n",
      "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.034642\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.027289\n",
      "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.012490\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.018008\n",
      "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.050300\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.013267\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.012903\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.015773\n",
      "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.069842\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.016215\n",
      "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.008608\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.012876\n",
      "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.021089\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.024484\n",
      "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.026922\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.010240\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.024523\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.012916\n",
      "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.029805\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.028198\n",
      "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.027058\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.019800\n",
      "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.007893\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.029686\n",
      "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.065665\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.017778\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.019881\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.024048\n",
      "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.010812\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.018798\n",
      "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.022509\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.008075\n",
      "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.048872\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.025149\n",
      "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.013221\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.008511\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.010394\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.013368\n",
      "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.006223\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.008474\n",
      "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.042756\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.037055\n",
      "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.015778\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.035862\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.010626\n",
      "\n",
      "Test set: Avg. loss: 0.0647, Accuracy: 9806/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.009113\n",
      "Train Epoch: 15 [640/60000 (1%)]\tLoss: 0.012643\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.020368\n",
      "Train Epoch: 15 [1920/60000 (3%)]\tLoss: 0.024343\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.008590\n",
      "Train Epoch: 15 [3200/60000 (5%)]\tLoss: 0.009463\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.008175\n",
      "Train Epoch: 15 [4480/60000 (7%)]\tLoss: 0.017444\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.014298\n",
      "Train Epoch: 15 [5760/60000 (10%)]\tLoss: 0.025082\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.010316\n",
      "Train Epoch: 15 [7040/60000 (12%)]\tLoss: 0.030597\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.018461\n",
      "Train Epoch: 15 [8320/60000 (14%)]\tLoss: 0.011850\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.009041\n",
      "Train Epoch: 15 [9600/60000 (16%)]\tLoss: 0.019655\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.039216\n",
      "Train Epoch: 15 [10880/60000 (18%)]\tLoss: 0.014656\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.033836\n",
      "Train Epoch: 15 [12160/60000 (20%)]\tLoss: 0.024901\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.025853\n",
      "Train Epoch: 15 [13440/60000 (22%)]\tLoss: 0.011721\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.008095\n",
      "Train Epoch: 15 [14720/60000 (25%)]\tLoss: 0.053973\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.014034\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.007606\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.016782\n",
      "Train Epoch: 15 [17280/60000 (29%)]\tLoss: 0.014472\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.010623\n",
      "Train Epoch: 15 [18560/60000 (31%)]\tLoss: 0.030535\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.027131\n",
      "Train Epoch: 15 [19840/60000 (33%)]\tLoss: 0.019463\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.049737\n",
      "Train Epoch: 15 [21120/60000 (35%)]\tLoss: 0.015121\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.021976\n",
      "Train Epoch: 15 [22400/60000 (37%)]\tLoss: 0.007483\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.003129\n",
      "Train Epoch: 15 [23680/60000 (39%)]\tLoss: 0.005365\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.010621\n",
      "Train Epoch: 15 [24960/60000 (42%)]\tLoss: 0.015710\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.012176\n",
      "Train Epoch: 15 [26240/60000 (44%)]\tLoss: 0.058585\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.014381\n",
      "Train Epoch: 15 [27520/60000 (46%)]\tLoss: 0.010211\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.031003\n",
      "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.020906\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.006375\n",
      "Train Epoch: 15 [30080/60000 (50%)]\tLoss: 0.020055\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.041534\n",
      "Train Epoch: 15 [31360/60000 (52%)]\tLoss: 0.037776\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.037036\n",
      "Train Epoch: 15 [32640/60000 (54%)]\tLoss: 0.017339\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.033415\n",
      "Train Epoch: 15 [33920/60000 (57%)]\tLoss: 0.011712\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.018142\n",
      "Train Epoch: 15 [35200/60000 (59%)]\tLoss: 0.014438\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.055872\n",
      "Train Epoch: 15 [36480/60000 (61%)]\tLoss: 0.007679\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.013390\n",
      "Train Epoch: 15 [37760/60000 (63%)]\tLoss: 0.006389\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.032026\n",
      "Train Epoch: 15 [39040/60000 (65%)]\tLoss: 0.015049\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.008720\n",
      "Train Epoch: 15 [40320/60000 (67%)]\tLoss: 0.011817\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.027432\n",
      "Train Epoch: 15 [41600/60000 (69%)]\tLoss: 0.026156\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.044246\n",
      "Train Epoch: 15 [42880/60000 (71%)]\tLoss: 0.053205\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.006137\n",
      "Train Epoch: 15 [44160/60000 (74%)]\tLoss: 0.016136\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.061434\n",
      "Train Epoch: 15 [45440/60000 (76%)]\tLoss: 0.010426\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.026884\n",
      "Train Epoch: 15 [46720/60000 (78%)]\tLoss: 0.013636\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.079456\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.051445\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.032349\n",
      "Train Epoch: 15 [49280/60000 (82%)]\tLoss: 0.018895\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.009781\n",
      "Train Epoch: 15 [50560/60000 (84%)]\tLoss: 0.018986\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.008762\n",
      "Train Epoch: 15 [51840/60000 (86%)]\tLoss: 0.018579\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.009719\n",
      "Train Epoch: 15 [53120/60000 (88%)]\tLoss: 0.025678\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.023187\n",
      "Train Epoch: 15 [54400/60000 (91%)]\tLoss: 0.009691\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.020100\n",
      "Train Epoch: 15 [55680/60000 (93%)]\tLoss: 0.010698\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.013670\n",
      "Train Epoch: 15 [56960/60000 (95%)]\tLoss: 0.061993\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.022352\n",
      "Train Epoch: 15 [58240/60000 (97%)]\tLoss: 0.009072\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.013121\n",
      "Train Epoch: 15 [59520/60000 (99%)]\tLoss: 0.016830\n",
      "\n",
      "Test set: Avg. loss: 0.0644, Accuracy: 9795/10000 (97.9%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.019382\n",
      "Train Epoch: 16 [640/60000 (1%)]\tLoss: 0.021494\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.003398\n",
      "Train Epoch: 16 [1920/60000 (3%)]\tLoss: 0.024403\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.012870\n",
      "Train Epoch: 16 [3200/60000 (5%)]\tLoss: 0.018385\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.033513\n",
      "Train Epoch: 16 [4480/60000 (7%)]\tLoss: 0.009091\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.008578\n",
      "Train Epoch: 16 [5760/60000 (10%)]\tLoss: 0.018880\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.029111\n",
      "Train Epoch: 16 [7040/60000 (12%)]\tLoss: 0.029620\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.008966\n",
      "Train Epoch: 16 [8320/60000 (14%)]\tLoss: 0.022097\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.008888\n",
      "Train Epoch: 16 [9600/60000 (16%)]\tLoss: 0.011869\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.022379\n",
      "Train Epoch: 16 [10880/60000 (18%)]\tLoss: 0.006686\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.011618\n",
      "Train Epoch: 16 [12160/60000 (20%)]\tLoss: 0.014112\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.026692\n",
      "Train Epoch: 16 [13440/60000 (22%)]\tLoss: 0.009836\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.028464\n",
      "Train Epoch: 16 [14720/60000 (25%)]\tLoss: 0.015508\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.004582\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.005363\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.024958\n",
      "Train Epoch: 16 [17280/60000 (29%)]\tLoss: 0.018369\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.012852\n",
      "Train Epoch: 16 [18560/60000 (31%)]\tLoss: 0.032158\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.021813\n",
      "Train Epoch: 16 [19840/60000 (33%)]\tLoss: 0.011458\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.052605\n",
      "Train Epoch: 16 [21120/60000 (35%)]\tLoss: 0.021708\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.010687\n",
      "Train Epoch: 16 [22400/60000 (37%)]\tLoss: 0.016695\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.034630\n",
      "Train Epoch: 16 [23680/60000 (39%)]\tLoss: 0.009135\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.004134\n",
      "Train Epoch: 16 [24960/60000 (42%)]\tLoss: 0.014540\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.031891\n",
      "Train Epoch: 16 [26240/60000 (44%)]\tLoss: 0.015174\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.009828\n",
      "Train Epoch: 16 [27520/60000 (46%)]\tLoss: 0.010202\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.006744\n",
      "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.034720\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.020872\n",
      "Train Epoch: 16 [30080/60000 (50%)]\tLoss: 0.007840\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.094927\n",
      "Train Epoch: 16 [31360/60000 (52%)]\tLoss: 0.014392\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.011499\n",
      "Train Epoch: 16 [32640/60000 (54%)]\tLoss: 0.004223\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.010906\n",
      "Train Epoch: 16 [33920/60000 (57%)]\tLoss: 0.008032\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.029204\n",
      "Train Epoch: 16 [35200/60000 (59%)]\tLoss: 0.020648\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.020381\n",
      "Train Epoch: 16 [36480/60000 (61%)]\tLoss: 0.048934\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.005626\n",
      "Train Epoch: 16 [37760/60000 (63%)]\tLoss: 0.011555\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.010609\n",
      "Train Epoch: 16 [39040/60000 (65%)]\tLoss: 0.012287\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.006872\n",
      "Train Epoch: 16 [40320/60000 (67%)]\tLoss: 0.009083\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.015954\n",
      "Train Epoch: 16 [41600/60000 (69%)]\tLoss: 0.036688\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.012438\n",
      "Train Epoch: 16 [42880/60000 (71%)]\tLoss: 0.018154\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.014633\n",
      "Train Epoch: 16 [44160/60000 (74%)]\tLoss: 0.009683\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.024276\n",
      "Train Epoch: 16 [45440/60000 (76%)]\tLoss: 0.032383\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.029354\n",
      "Train Epoch: 16 [46720/60000 (78%)]\tLoss: 0.027663\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.012468\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.013291\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.008483\n",
      "Train Epoch: 16 [49280/60000 (82%)]\tLoss: 0.008037\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.012248\n",
      "Train Epoch: 16 [50560/60000 (84%)]\tLoss: 0.014683\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.009263\n",
      "Train Epoch: 16 [51840/60000 (86%)]\tLoss: 0.030470\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.013661\n",
      "Train Epoch: 16 [53120/60000 (88%)]\tLoss: 0.094651\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.008187\n",
      "Train Epoch: 16 [54400/60000 (91%)]\tLoss: 0.012777\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.014056\n",
      "Train Epoch: 16 [55680/60000 (93%)]\tLoss: 0.031854\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.033318\n",
      "Train Epoch: 16 [56960/60000 (95%)]\tLoss: 0.015956\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.038495\n",
      "Train Epoch: 16 [58240/60000 (97%)]\tLoss: 0.064636\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.016239\n",
      "Train Epoch: 16 [59520/60000 (99%)]\tLoss: 0.030857\n",
      "\n",
      "Test set: Avg. loss: 0.0617, Accuracy: 9812/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.020396\n",
      "Train Epoch: 17 [640/60000 (1%)]\tLoss: 0.017792\n",
      "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.011158\n",
      "Train Epoch: 17 [1920/60000 (3%)]\tLoss: 0.015873\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.032958\n",
      "Train Epoch: 17 [3200/60000 (5%)]\tLoss: 0.010172\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.038914\n",
      "Train Epoch: 17 [4480/60000 (7%)]\tLoss: 0.014759\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.015233\n",
      "Train Epoch: 17 [5760/60000 (10%)]\tLoss: 0.007433\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.018617\n",
      "Train Epoch: 17 [7040/60000 (12%)]\tLoss: 0.016876\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.014440\n",
      "Train Epoch: 17 [8320/60000 (14%)]\tLoss: 0.008090\n",
      "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.015298\n",
      "Train Epoch: 17 [9600/60000 (16%)]\tLoss: 0.007106\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.030874\n",
      "Train Epoch: 17 [10880/60000 (18%)]\tLoss: 0.026928\n",
      "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.013158\n",
      "Train Epoch: 17 [12160/60000 (20%)]\tLoss: 0.007433\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.012534\n",
      "Train Epoch: 17 [13440/60000 (22%)]\tLoss: 0.011018\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.026478\n",
      "Train Epoch: 17 [14720/60000 (25%)]\tLoss: 0.008736\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.006199\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.009945\n",
      "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.011607\n",
      "Train Epoch: 17 [17280/60000 (29%)]\tLoss: 0.010783\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.007686\n",
      "Train Epoch: 17 [18560/60000 (31%)]\tLoss: 0.011866\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.010296\n",
      "Train Epoch: 17 [19840/60000 (33%)]\tLoss: 0.013388\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.015527\n",
      "Train Epoch: 17 [21120/60000 (35%)]\tLoss: 0.026079\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.014129\n",
      "Train Epoch: 17 [22400/60000 (37%)]\tLoss: 0.018565\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.017714\n",
      "Train Epoch: 17 [23680/60000 (39%)]\tLoss: 0.012677\n",
      "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 0.005316\n",
      "Train Epoch: 17 [24960/60000 (42%)]\tLoss: 0.008664\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.038209\n",
      "Train Epoch: 17 [26240/60000 (44%)]\tLoss: 0.013068\n",
      "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 0.025289\n",
      "Train Epoch: 17 [27520/60000 (46%)]\tLoss: 0.008956\n",
      "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.012409\n",
      "Train Epoch: 17 [28800/60000 (48%)]\tLoss: 0.009472\n",
      "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 0.059539\n",
      "Train Epoch: 17 [30080/60000 (50%)]\tLoss: 0.033778\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.016304\n",
      "Train Epoch: 17 [31360/60000 (52%)]\tLoss: 0.014035\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.013465\n",
      "Train Epoch: 17 [32640/60000 (54%)]\tLoss: 0.011357\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.009996\n",
      "Train Epoch: 17 [33920/60000 (57%)]\tLoss: 0.012264\n",
      "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 0.010611\n",
      "Train Epoch: 17 [35200/60000 (59%)]\tLoss: 0.030736\n",
      "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.012880\n",
      "Train Epoch: 17 [36480/60000 (61%)]\tLoss: 0.008612\n",
      "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 0.006453\n",
      "Train Epoch: 17 [37760/60000 (63%)]\tLoss: 0.011022\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.009812\n",
      "Train Epoch: 17 [39040/60000 (65%)]\tLoss: 0.005782\n",
      "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 0.014729\n",
      "Train Epoch: 17 [40320/60000 (67%)]\tLoss: 0.007443\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.015890\n",
      "Train Epoch: 17 [41600/60000 (69%)]\tLoss: 0.025745\n",
      "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 0.008617\n",
      "Train Epoch: 17 [42880/60000 (71%)]\tLoss: 0.021580\n",
      "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.021154\n",
      "Train Epoch: 17 [44160/60000 (74%)]\tLoss: 0.012322\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.037018\n",
      "Train Epoch: 17 [45440/60000 (76%)]\tLoss: 0.025984\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.011368\n",
      "Train Epoch: 17 [46720/60000 (78%)]\tLoss: 0.007169\n",
      "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 0.012675\n",
      "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.027596\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.008105\n",
      "Train Epoch: 17 [49280/60000 (82%)]\tLoss: 0.007346\n",
      "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 0.016790\n",
      "Train Epoch: 17 [50560/60000 (84%)]\tLoss: 0.007412\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.020105\n",
      "Train Epoch: 17 [51840/60000 (86%)]\tLoss: 0.040373\n",
      "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 0.029668\n",
      "Train Epoch: 17 [53120/60000 (88%)]\tLoss: 0.012359\n",
      "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.006599\n",
      "Train Epoch: 17 [54400/60000 (91%)]\tLoss: 0.014225\n",
      "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 0.014530\n",
      "Train Epoch: 17 [55680/60000 (93%)]\tLoss: 0.015415\n",
      "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.005193\n",
      "Train Epoch: 17 [56960/60000 (95%)]\tLoss: 0.007915\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.016257\n",
      "Train Epoch: 17 [58240/60000 (97%)]\tLoss: 0.008870\n",
      "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.007740\n",
      "Train Epoch: 17 [59520/60000 (99%)]\tLoss: 0.016166\n",
      "\n",
      "Test set: Avg. loss: 0.0608, Accuracy: 9815/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.039334\n",
      "Train Epoch: 18 [640/60000 (1%)]\tLoss: 0.009822\n",
      "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 0.008194\n",
      "Train Epoch: 18 [1920/60000 (3%)]\tLoss: 0.012173\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.011715\n",
      "Train Epoch: 18 [3200/60000 (5%)]\tLoss: 0.011593\n",
      "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 0.035108\n",
      "Train Epoch: 18 [4480/60000 (7%)]\tLoss: 0.020785\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.009474\n",
      "Train Epoch: 18 [5760/60000 (10%)]\tLoss: 0.027249\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.011196\n",
      "Train Epoch: 18 [7040/60000 (12%)]\tLoss: 0.009131\n",
      "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.016332\n",
      "Train Epoch: 18 [8320/60000 (14%)]\tLoss: 0.019662\n",
      "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 0.025908\n",
      "Train Epoch: 18 [9600/60000 (16%)]\tLoss: 0.007082\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.014713\n",
      "Train Epoch: 18 [10880/60000 (18%)]\tLoss: 0.014580\n",
      "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 0.009692\n",
      "Train Epoch: 18 [12160/60000 (20%)]\tLoss: 0.016476\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.016983\n",
      "Train Epoch: 18 [13440/60000 (22%)]\tLoss: 0.017028\n",
      "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 0.011997\n",
      "Train Epoch: 18 [14720/60000 (25%)]\tLoss: 0.027140\n",
      "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.017241\n",
      "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.015860\n",
      "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 0.020191\n",
      "Train Epoch: 18 [17280/60000 (29%)]\tLoss: 0.007544\n",
      "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.006622\n",
      "Train Epoch: 18 [18560/60000 (31%)]\tLoss: 0.007876\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.010120\n",
      "Train Epoch: 18 [19840/60000 (33%)]\tLoss: 0.017568\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.032305\n",
      "Train Epoch: 18 [21120/60000 (35%)]\tLoss: 0.008762\n",
      "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 0.022584\n",
      "Train Epoch: 18 [22400/60000 (37%)]\tLoss: 0.020356\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.010733\n",
      "Train Epoch: 18 [23680/60000 (39%)]\tLoss: 0.031542\n",
      "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 0.007571\n",
      "Train Epoch: 18 [24960/60000 (42%)]\tLoss: 0.009712\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.007307\n",
      "Train Epoch: 18 [26240/60000 (44%)]\tLoss: 0.015680\n",
      "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 0.010252\n",
      "Train Epoch: 18 [27520/60000 (46%)]\tLoss: 0.017590\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.011771\n",
      "Train Epoch: 18 [28800/60000 (48%)]\tLoss: 0.013742\n",
      "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 0.008139\n",
      "Train Epoch: 18 [30080/60000 (50%)]\tLoss: 0.004231\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.014781\n",
      "Train Epoch: 18 [31360/60000 (52%)]\tLoss: 0.013506\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.014300\n",
      "Train Epoch: 18 [32640/60000 (54%)]\tLoss: 0.011710\n",
      "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.032176\n",
      "Train Epoch: 18 [33920/60000 (57%)]\tLoss: 0.018592\n",
      "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 0.013962\n",
      "Train Epoch: 18 [35200/60000 (59%)]\tLoss: 0.011339\n",
      "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.035228\n",
      "Train Epoch: 18 [36480/60000 (61%)]\tLoss: 0.002984\n",
      "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 0.023799\n",
      "Train Epoch: 18 [37760/60000 (63%)]\tLoss: 0.014018\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.013442\n",
      "Train Epoch: 18 [39040/60000 (65%)]\tLoss: 0.069096\n",
      "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 0.017279\n",
      "Train Epoch: 18 [40320/60000 (67%)]\tLoss: 0.023369\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.027207\n",
      "Train Epoch: 18 [41600/60000 (69%)]\tLoss: 0.065370\n",
      "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 0.029299\n",
      "Train Epoch: 18 [42880/60000 (71%)]\tLoss: 0.012847\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.005073\n",
      "Train Epoch: 18 [44160/60000 (74%)]\tLoss: 0.028496\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.024996\n",
      "Train Epoch: 18 [45440/60000 (76%)]\tLoss: 0.012081\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.012317\n",
      "Train Epoch: 18 [46720/60000 (78%)]\tLoss: 0.014933\n",
      "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 0.017828\n",
      "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.009514\n",
      "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.023282\n",
      "Train Epoch: 18 [49280/60000 (82%)]\tLoss: 0.003186\n",
      "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 0.010684\n",
      "Train Epoch: 18 [50560/60000 (84%)]\tLoss: 0.033069\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.027322\n",
      "Train Epoch: 18 [51840/60000 (86%)]\tLoss: 0.020204\n",
      "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 0.021922\n",
      "Train Epoch: 18 [53120/60000 (88%)]\tLoss: 0.010424\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.013614\n",
      "Train Epoch: 18 [54400/60000 (91%)]\tLoss: 0.021266\n",
      "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 0.012897\n",
      "Train Epoch: 18 [55680/60000 (93%)]\tLoss: 0.010835\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.006325\n",
      "Train Epoch: 18 [56960/60000 (95%)]\tLoss: 0.023793\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.018209\n",
      "Train Epoch: 18 [58240/60000 (97%)]\tLoss: 0.008977\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.006697\n",
      "Train Epoch: 18 [59520/60000 (99%)]\tLoss: 0.010051\n",
      "\n",
      "Test set: Avg. loss: 0.0597, Accuracy: 9813/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.003884\n",
      "Train Epoch: 19 [640/60000 (1%)]\tLoss: 0.018173\n",
      "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 0.010808\n",
      "Train Epoch: 19 [1920/60000 (3%)]\tLoss: 0.004592\n",
      "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.016793\n",
      "Train Epoch: 19 [3200/60000 (5%)]\tLoss: 0.013044\n",
      "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 0.014591\n",
      "Train Epoch: 19 [4480/60000 (7%)]\tLoss: 0.025230\n",
      "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.007994\n",
      "Train Epoch: 19 [5760/60000 (10%)]\tLoss: 0.006887\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.012398\n",
      "Train Epoch: 19 [7040/60000 (12%)]\tLoss: 0.012011\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.030674\n",
      "Train Epoch: 19 [8320/60000 (14%)]\tLoss: 0.065687\n",
      "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 0.009412\n",
      "Train Epoch: 19 [9600/60000 (16%)]\tLoss: 0.005090\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.008206\n",
      "Train Epoch: 19 [10880/60000 (18%)]\tLoss: 0.009795\n",
      "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 0.007363\n",
      "Train Epoch: 19 [12160/60000 (20%)]\tLoss: 0.008078\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.011198\n",
      "Train Epoch: 19 [13440/60000 (22%)]\tLoss: 0.010047\n",
      "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 0.035447\n",
      "Train Epoch: 19 [14720/60000 (25%)]\tLoss: 0.013165\n",
      "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.011677\n",
      "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.028459\n",
      "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 0.004724\n",
      "Train Epoch: 19 [17280/60000 (29%)]\tLoss: 0.023127\n",
      "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.015499\n",
      "Train Epoch: 19 [18560/60000 (31%)]\tLoss: 0.010899\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.011069\n",
      "Train Epoch: 19 [19840/60000 (33%)]\tLoss: 0.018812\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.037164\n",
      "Train Epoch: 19 [21120/60000 (35%)]\tLoss: 0.018801\n",
      "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 0.012757\n",
      "Train Epoch: 19 [22400/60000 (37%)]\tLoss: 0.017506\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.016223\n",
      "Train Epoch: 19 [23680/60000 (39%)]\tLoss: 0.009885\n",
      "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 0.005869\n",
      "Train Epoch: 19 [24960/60000 (42%)]\tLoss: 0.023781\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.007776\n",
      "Train Epoch: 19 [26240/60000 (44%)]\tLoss: 0.011606\n",
      "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 0.009215\n",
      "Train Epoch: 19 [27520/60000 (46%)]\tLoss: 0.010153\n",
      "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.010920\n",
      "Train Epoch: 19 [28800/60000 (48%)]\tLoss: 0.052885\n",
      "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 0.012139\n",
      "Train Epoch: 19 [30080/60000 (50%)]\tLoss: 0.031525\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.016892\n",
      "Train Epoch: 19 [31360/60000 (52%)]\tLoss: 0.028109\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.007482\n",
      "Train Epoch: 19 [32640/60000 (54%)]\tLoss: 0.012571\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.008164\n",
      "Train Epoch: 19 [33920/60000 (57%)]\tLoss: 0.005132\n",
      "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 0.011675\n",
      "Train Epoch: 19 [35200/60000 (59%)]\tLoss: 0.014673\n",
      "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.009979\n",
      "Train Epoch: 19 [36480/60000 (61%)]\tLoss: 0.010710\n",
      "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 0.019240\n",
      "Train Epoch: 19 [37760/60000 (63%)]\tLoss: 0.007625\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.015005\n",
      "Train Epoch: 19 [39040/60000 (65%)]\tLoss: 0.028336\n",
      "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 0.013224\n",
      "Train Epoch: 19 [40320/60000 (67%)]\tLoss: 0.008515\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.003721\n",
      "Train Epoch: 19 [41600/60000 (69%)]\tLoss: 0.008574\n",
      "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 0.013799\n",
      "Train Epoch: 19 [42880/60000 (71%)]\tLoss: 0.004979\n",
      "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.015897\n",
      "Train Epoch: 19 [44160/60000 (74%)]\tLoss: 0.017533\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.013402\n",
      "Train Epoch: 19 [45440/60000 (76%)]\tLoss: 0.009227\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.006374\n",
      "Train Epoch: 19 [46720/60000 (78%)]\tLoss: 0.010742\n",
      "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 0.025830\n",
      "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.024409\n",
      "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.004982\n",
      "Train Epoch: 19 [49280/60000 (82%)]\tLoss: 0.033612\n",
      "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 0.016932\n",
      "Train Epoch: 19 [50560/60000 (84%)]\tLoss: 0.009709\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.010431\n",
      "Train Epoch: 19 [51840/60000 (86%)]\tLoss: 0.010215\n",
      "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 0.004836\n",
      "Train Epoch: 19 [53120/60000 (88%)]\tLoss: 0.003731\n",
      "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.050346\n",
      "Train Epoch: 19 [54400/60000 (91%)]\tLoss: 0.017066\n",
      "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 0.017724\n",
      "Train Epoch: 19 [55680/60000 (93%)]\tLoss: 0.016493\n",
      "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.008239\n",
      "Train Epoch: 19 [56960/60000 (95%)]\tLoss: 0.009666\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.009254\n",
      "Train Epoch: 19 [58240/60000 (97%)]\tLoss: 0.016061\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.042405\n",
      "Train Epoch: 19 [59520/60000 (99%)]\tLoss: 0.003474\n",
      "\n",
      "Test set: Avg. loss: 0.0607, Accuracy: 9810/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.020896\n",
      "Train Epoch: 20 [640/60000 (1%)]\tLoss: 0.009358\n",
      "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 0.023432\n",
      "Train Epoch: 20 [1920/60000 (3%)]\tLoss: 0.009303\n",
      "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.013848\n",
      "Train Epoch: 20 [3200/60000 (5%)]\tLoss: 0.021196\n",
      "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 0.005322\n",
      "Train Epoch: 20 [4480/60000 (7%)]\tLoss: 0.029535\n",
      "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.004144\n",
      "Train Epoch: 20 [5760/60000 (10%)]\tLoss: 0.018099\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.003171\n",
      "Train Epoch: 20 [7040/60000 (12%)]\tLoss: 0.010744\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.007902\n",
      "Train Epoch: 20 [8320/60000 (14%)]\tLoss: 0.019324\n",
      "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 0.003233\n",
      "Train Epoch: 20 [9600/60000 (16%)]\tLoss: 0.015126\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.014191\n",
      "Train Epoch: 20 [10880/60000 (18%)]\tLoss: 0.043766\n",
      "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 0.004952\n",
      "Train Epoch: 20 [12160/60000 (20%)]\tLoss: 0.004689\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.005381\n",
      "Train Epoch: 20 [13440/60000 (22%)]\tLoss: 0.008164\n",
      "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 0.020659\n",
      "Train Epoch: 20 [14720/60000 (25%)]\tLoss: 0.012196\n",
      "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.004916\n",
      "Train Epoch: 20 [16000/60000 (27%)]\tLoss: 0.003678\n",
      "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 0.017520\n",
      "Train Epoch: 20 [17280/60000 (29%)]\tLoss: 0.008141\n",
      "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.023902\n",
      "Train Epoch: 20 [18560/60000 (31%)]\tLoss: 0.006396\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.007184\n",
      "Train Epoch: 20 [19840/60000 (33%)]\tLoss: 0.010805\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.006847\n",
      "Train Epoch: 20 [21120/60000 (35%)]\tLoss: 0.005531\n",
      "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 0.009710\n",
      "Train Epoch: 20 [22400/60000 (37%)]\tLoss: 0.008822\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.010207\n",
      "Train Epoch: 20 [23680/60000 (39%)]\tLoss: 0.027417\n",
      "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 0.009229\n",
      "Train Epoch: 20 [24960/60000 (42%)]\tLoss: 0.007182\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.026182\n",
      "Train Epoch: 20 [26240/60000 (44%)]\tLoss: 0.021104\n",
      "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 0.018066\n",
      "Train Epoch: 20 [27520/60000 (46%)]\tLoss: 0.011164\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.008730\n",
      "Train Epoch: 20 [28800/60000 (48%)]\tLoss: 0.005054\n",
      "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 0.017727\n",
      "Train Epoch: 20 [30080/60000 (50%)]\tLoss: 0.011029\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.006425\n",
      "Train Epoch: 20 [31360/60000 (52%)]\tLoss: 0.020506\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.007098\n",
      "Train Epoch: 20 [32640/60000 (54%)]\tLoss: 0.015642\n",
      "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.011642\n",
      "Train Epoch: 20 [33920/60000 (57%)]\tLoss: 0.014370\n",
      "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 0.017848\n",
      "Train Epoch: 20 [35200/60000 (59%)]\tLoss: 0.010083\n",
      "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.009933\n",
      "Train Epoch: 20 [36480/60000 (61%)]\tLoss: 0.022298\n",
      "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 0.009899\n",
      "Train Epoch: 20 [37760/60000 (63%)]\tLoss: 0.012231\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.009828\n",
      "Train Epoch: 20 [39040/60000 (65%)]\tLoss: 0.010602\n",
      "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 0.011917\n",
      "Train Epoch: 20 [40320/60000 (67%)]\tLoss: 0.011240\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.009264\n",
      "Train Epoch: 20 [41600/60000 (69%)]\tLoss: 0.012941\n",
      "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 0.005210\n",
      "Train Epoch: 20 [42880/60000 (71%)]\tLoss: 0.006009\n",
      "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.038768\n",
      "Train Epoch: 20 [44160/60000 (74%)]\tLoss: 0.009349\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.009040\n",
      "Train Epoch: 20 [45440/60000 (76%)]\tLoss: 0.022125\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.018195\n",
      "Train Epoch: 20 [46720/60000 (78%)]\tLoss: 0.009875\n",
      "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 0.017233\n",
      "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 0.010983\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.012378\n",
      "Train Epoch: 20 [49280/60000 (82%)]\tLoss: 0.016466\n",
      "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 0.020003\n",
      "Train Epoch: 20 [50560/60000 (84%)]\tLoss: 0.006659\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.005735\n",
      "Train Epoch: 20 [51840/60000 (86%)]\tLoss: 0.007512\n",
      "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 0.017451\n",
      "Train Epoch: 20 [53120/60000 (88%)]\tLoss: 0.009936\n",
      "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.013813\n",
      "Train Epoch: 20 [54400/60000 (91%)]\tLoss: 0.012839\n",
      "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 0.012414\n",
      "Train Epoch: 20 [55680/60000 (93%)]\tLoss: 0.018310\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.024752\n",
      "Train Epoch: 20 [56960/60000 (95%)]\tLoss: 0.013280\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.030449\n",
      "Train Epoch: 20 [58240/60000 (97%)]\tLoss: 0.012131\n",
      "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.012715\n",
      "Train Epoch: 20 [59520/60000 (99%)]\tLoss: 0.014452\n",
      "\n",
      "Test set: Avg. loss: 0.0603, Accuracy: 9814/10000 (98.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.004661\n",
      "Train Epoch: 21 [640/60000 (1%)]\tLoss: 0.007544\n",
      "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 0.006085\n",
      "Train Epoch: 21 [1920/60000 (3%)]\tLoss: 0.006599\n",
      "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 0.007976\n",
      "Train Epoch: 21 [3200/60000 (5%)]\tLoss: 0.010603\n",
      "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 0.017243\n",
      "Train Epoch: 21 [4480/60000 (7%)]\tLoss: 0.011457\n",
      "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 0.012426\n",
      "Train Epoch: 21 [5760/60000 (10%)]\tLoss: 0.012810\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.012374\n",
      "Train Epoch: 21 [7040/60000 (12%)]\tLoss: 0.012772\n",
      "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 0.007666\n",
      "Train Epoch: 21 [8320/60000 (14%)]\tLoss: 0.005758\n",
      "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 0.008000\n",
      "Train Epoch: 21 [9600/60000 (16%)]\tLoss: 0.014040\n",
      "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.006634\n",
      "Train Epoch: 21 [10880/60000 (18%)]\tLoss: 0.021037\n",
      "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 0.011355\n",
      "Train Epoch: 21 [12160/60000 (20%)]\tLoss: 0.013933\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.006611\n",
      "Train Epoch: 21 [13440/60000 (22%)]\tLoss: 0.009732\n",
      "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 0.005744\n",
      "Train Epoch: 21 [14720/60000 (25%)]\tLoss: 0.011909\n",
      "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 0.010317\n",
      "Train Epoch: 21 [16000/60000 (27%)]\tLoss: 0.012590\n",
      "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 0.013146\n",
      "Train Epoch: 21 [17280/60000 (29%)]\tLoss: 0.022823\n",
      "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 0.015018\n",
      "Train Epoch: 21 [18560/60000 (31%)]\tLoss: 0.012230\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.016357\n",
      "Train Epoch: 21 [19840/60000 (33%)]\tLoss: 0.013928\n",
      "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.007918\n",
      "Train Epoch: 21 [21120/60000 (35%)]\tLoss: 0.012002\n",
      "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 0.020543\n",
      "Train Epoch: 21 [22400/60000 (37%)]\tLoss: 0.010317\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.014076\n",
      "Train Epoch: 21 [23680/60000 (39%)]\tLoss: 0.018179\n",
      "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 0.009458\n",
      "Train Epoch: 21 [24960/60000 (42%)]\tLoss: 0.009725\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.008085\n",
      "Train Epoch: 21 [26240/60000 (44%)]\tLoss: 0.004525\n",
      "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 0.010688\n",
      "Train Epoch: 21 [27520/60000 (46%)]\tLoss: 0.006036\n",
      "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 0.005588\n",
      "Train Epoch: 21 [28800/60000 (48%)]\tLoss: 0.008042\n",
      "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 0.010712\n",
      "Train Epoch: 21 [30080/60000 (50%)]\tLoss: 0.004428\n",
      "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.012187\n",
      "Train Epoch: 21 [31360/60000 (52%)]\tLoss: 0.006897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-92c9a59e4697>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0macc_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0macc_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7cedabeb16e9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, model, optimizer, trainloader, log_interval, device)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"base_net1\"\n",
    "acc_max = test(model1, test_loader)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch, model1, optimizer1, train_loader)\n",
    "    acc = test(model1, test_loader)\n",
    "    if acc > acc_max:\n",
    "        acc = acc_max\n",
    "        print()\n",
    "        print(\"--- saving model for best accuracy ---\")\n",
    "        #torch.save(model1.state_dict(), 'results/'+model_name+'.pth')\n",
    "        #torch.save(optimizer1.state_dict(), 'results/'+model_name+'_optimizer.pth')\n",
    "        print(\"--- saving finished ---\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model1.state_dict(), 'results/base_model.pth')\n",
    "#torch.save(optimizer1.state_dict(), 'results/base_optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
