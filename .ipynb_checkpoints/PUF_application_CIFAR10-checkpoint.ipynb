{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1641c2321d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 500\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow((example_data[i]/2+0.5).permute(1,2,0))\n",
    "    plt.title(\"Ground Truth: {}\".format(classes[example_targets[i]]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network flowchart:\n",
    "#input vector --- random initialized weights ---> hyperdimensional vecotor ---> one_hot_net l1 ---> ...ln... ---> sigmoid/softmax output\n",
    "#One hot net\n",
    "\n",
    "class One_hot_op(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A, W, epsilon):\n",
    "        Z = torch.matmul(W, A)\n",
    "        ctx.Z = Z\n",
    "        ctx.A = A\n",
    "        ctx.W = W\n",
    "        ctx.epsilon = epsilon\n",
    "        ret = Z > epsilon\n",
    "        #print(ret[1:10][1:10])\n",
    "        return ret.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dA):\n",
    "        step = ctx.Z > ctx.epsilon\n",
    "        step = step.float()\n",
    "        dL_dZ = dL_dA * step \n",
    "        \n",
    "        dZ_dW = torch.transpose(ctx.A, 0,1)\n",
    "        dZ_dW = torch.sign(dZ_dW)\n",
    "        dZ_dA = torch.transpose(ctx.W, 0,1)\n",
    "        dZ_dA = torch.sign(dZ_dA)\n",
    "        dA = torch.matmul(dZ_dA,dL_dZ)\n",
    "        dW = torch.matmul(dL_dZ,dZ_dW)\n",
    "        return dA, dW, None\n",
    "\n",
    "\n",
    "class One_hot_layer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, initialization_f, epsilon):\n",
    "        super(One_hot_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.initialization_f = initialization_f\n",
    "        initialized_weight = initialization_f(out_dim, in_dim)\n",
    "        self.weight = nn.Parameter(initialized_weight, requires_grad = True)\n",
    "        self.op = One_hot_op\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_dim) + ',' \\\n",
    "               + str(self.out_dim) + ')'\n",
    "        \n",
    "    def forward(self, A):\n",
    "        #print(self.weight[:3][:3])\n",
    "        return self.op.apply(A, self.weight, self.epsilon)\n",
    "    \n",
    "\n",
    "class One_hot_net(nn.Module):\n",
    "    def __init__(self, in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers=2, layer_size_factor=[1, 5], dropout=[-1, 0.5]):\n",
    "        super(One_hot_net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.in_dim = in_dim\n",
    "        feature_len = in_dim * encoder_multiplier\n",
    "        self.feature_len = feature_len\n",
    "        self.n_layers=n_layers\n",
    "        self.layer_size_factor=layer_size_factor\n",
    "        self.dropout=dropout\n",
    "        self.epsilon = epsilon\n",
    "        self.n_class = n_class\n",
    "        self.f_encoder = f_encoder\n",
    "        self.f_initializer = f_initializer\n",
    "        for i in range(n_layers):\n",
    "            if dropout[i] > 0:\n",
    "                self.layers.append(nn.Dropout(dropout[i]))\n",
    "            if i < n_layers - 1:\n",
    "                self.layers.append(\n",
    "                    One_hot_layer(int(feature_len // layer_size_factor[i]), int(feature_len // layer_size_factor[i + 1]), f_initializer, epsilon))\n",
    "        self.tail = nn.Linear(int(feature_len // layer_size_factor[-1]), n_class)\n",
    "    \n",
    "    def flatten(self, X):\n",
    "        return X.view(X.shape[0], X.shape[1]*X.shape[2])\n",
    "    \n",
    "    def unflatten(self, X):\n",
    "        return X.view(X.shape[0], int(self.in_dim**(1/2)), int(self.in_dim**(1/2)))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.f_encoder.apply(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.tail(X)\n",
    "        return self.unflatten(X)\n",
    "\n",
    "class OHN_3_channels(nn.Module):\n",
    "    def __init__(self, in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers=2, layer_size_factor=[1, 5], dropout=[-1, 0.5]):\n",
    "        super(OHN_3_channels, self).__init__()\n",
    "        self.c1 = One_hot_net(in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers, layer_size_factor, dropout)\n",
    "        self.c2 = One_hot_net(in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers, layer_size_factor, dropout)\n",
    "        self.c3 = One_hot_net(in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers, layer_size_factor, dropout)\n",
    "    def forward(self, X):\n",
    "        out = torch.empty(X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "        \n",
    "        out[:,0,:,:] = self.c1(X[:,0,:,:])\n",
    "        out[:,1,:,:] = self.c2(X[:,1,:,:])\n",
    "        out[:,2,:,:] = self.c3(X[:,2,:,:])\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializers and encoders\n",
    "def uniform_initializer(out_dim, in_dim, cuda = True):\n",
    "    tensor = torch.empty(out_dim, in_dim)\n",
    "    if cuda:\n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2).cuda()\n",
    "    else: \n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2)\n",
    "\n",
    "class simple_encoder():\n",
    "    def __init__(self, out_dim, in_dim):\n",
    "        self.W = uniform_initializer(out_dim, in_dim)\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return torch.matmul(self.W, X)\n",
    "    \n",
    "class simple_encoder_wthreshold():\n",
    "    def __init__(self, out_dim, in_dim, epsilon, cuda = True):\n",
    "        self.W = uniform_initializer(out_dim, in_dim, cuda)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return (torch.matmul(self.W, X) > self.epsilon).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'in_dim': 1024,\n",
    "    'n_class': 1024,\n",
    "    'f_encoder': simple_encoder_wthreshold(1024*100, 1024, 1e-3),\n",
    "    'f_initializer': uniform_initializer,\n",
    "    'encoder_multiplier': 100,\n",
    "    'epsilon': 10e-3,\n",
    "    'n_layers': 1,\n",
    "    'layer_size_factor': [1],\n",
    "    'dropout': [-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model1 = OHN_3_channels(parameters['in_dim'], parameters['n_class'], parameters['f_encoder'], parameters['encoder_multiplier'], \n",
    "                     parameters['f_initializer'], parameters['epsilon'], parameters['n_layers'], \n",
    "                     parameters['layer_size_factor'], parameters['dropout']).to(device)\n",
    "\n",
    "#model1 = toy_Net().to(device)\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer1 = torch.optim.SGD([{'params': model1.layers.parameters(), 'lr': 0.01}, {'params': model1.tail.parameters(), 'lr': 0.01}], lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]     104,858,624\n",
      "       One_hot_net-2               [-1, 32, 32]               0\n",
      "            Linear-3                 [-1, 1024]     104,858,624\n",
      "       One_hot_net-4               [-1, 32, 32]               0\n",
      "            Linear-5                 [-1, 1024]     104,858,624\n",
      "       One_hot_net-6               [-1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 314,575,872\n",
      "Trainable params: 314,575,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 1200.01\n",
      "Estimated Total Size (MB): 1200.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model1, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, trainloader, log_interval = 10, device = torch.device(\"cuda:0\")):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = nn.MSELoss()(output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(model.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device = torch.device(\"cuda:0\")):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data).to(device)\n",
    "            test_loss += nn.MSELoss()(output, data).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_loss *=500\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.6f}\\n'.format(\n",
    "        test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.423565\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.404186\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 0.223029\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 0.195097\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 0.186060\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 0.153172\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.167648\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 0.147946\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 0.140893\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 0.152606\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 0.144197\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.135654\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 0.136485\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 0.120583\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 0.128067\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 0.116005\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.130822\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 0.120155\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 0.111983\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 0.122811\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 0.104819\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.114615\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 0.102965\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 0.118610\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 0.102748\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 0.120406\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.102621\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 0.100895\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 0.096366\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 0.095793\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 0.105563\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.111259\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 0.097347\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 0.102534\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 0.111980\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 0.094311\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.096186\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 0.091112\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 0.089880\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 0.092594\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 0.091336\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.098100\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 0.092117\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 0.095623\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 0.102490\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 0.096909\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.101251\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 0.085075\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 0.097451\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 0.087873\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 0.091791\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.083484\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 0.085703\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 0.094425\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 0.090999\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 0.084875\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.088850\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 0.088053\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 0.086809\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 0.087466\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 0.090564\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.087685\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 0.083825\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 0.082109\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 0.092767\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 0.085677\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.084495\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 0.081673\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 0.083681\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 0.082520\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 0.082713\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.081238\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 0.076577\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.082885\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 0.079026\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 0.082572\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.082124\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 0.076803\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 0.087008\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 0.078820\n",
      "\n",
      "Test set: Avg. loss: 0.081651\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.078629\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 0.084404\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 0.083509\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 0.080316\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 0.077547\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.082138\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 0.080924\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 0.079329\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.078932\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 0.074927\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.085087\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 0.080331\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 0.079057\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 0.077190\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 0.083903\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.080982\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.080717\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 0.075078\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 0.071464\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 0.072341\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.074053\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 0.078860\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 0.080224\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 0.076325\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.075612\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.077056\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 0.072494\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 0.078636\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 0.079449\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 0.076886\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.074762\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 0.069933\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.073066\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 0.079817\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 0.073296\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.070556\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 0.075733\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 0.072395\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 0.074194\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 0.077817\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.070963\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 0.070722\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 0.069961\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 0.078932\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 0.069024\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.075682\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 0.074749\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 0.072965\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.071478\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 0.070465\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.067940\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 0.069447\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 0.072780\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 0.069128\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 0.075834\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.071304\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.068614\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 0.067203\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 0.069073\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 0.065423\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.076438\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 0.070201\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 0.065187\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 0.066778\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.067640\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.070484\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 0.075201\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 0.069472\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 0.069071\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 0.072486\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.069067\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 0.069344\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.066327\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 0.069253\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 0.074436\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.063335\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 0.068544\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 0.066622\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 0.069635\n",
      "\n",
      "Test set: Avg. loss: 0.069192\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.071560\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 0.069501\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 0.071332\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 0.070727\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 0.071292\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.074964\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 0.069488\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 0.067634\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.068688\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 0.066433\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.065166\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 0.066391\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 0.064193\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 0.064909\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 0.067914\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.069123\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.070895\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 0.060511\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 0.067498\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 0.067364\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.069834\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 0.065704\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 0.066228\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 0.063880\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.068723\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.068944\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 0.069770\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 0.065847\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 0.065169\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 0.069123\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.062462\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 0.070690\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.071688\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 0.067832\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 0.060455\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.058808\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 0.064871\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 0.066797\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 0.064988\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 0.067077\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.067254\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 0.068795\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 0.064294\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 0.062369\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 0.066818\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.061704\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 0.065739\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 0.063622\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.064898\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 0.063076\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.065649\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 0.062029\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 0.060832\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 0.066785\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 0.068261\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.065470\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 0.058010\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 0.061845\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 0.065026\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 0.067698\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.066126\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 0.060790\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 0.059962\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 0.064002\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.062953\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.064377\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 0.057544\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 0.059970\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 0.061310\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 0.065773\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.065985\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 0.063053\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.061778\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 0.057481\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 0.068158\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.061785\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 0.061659\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 0.061827\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 0.058829\n",
      "\n",
      "Test set: Avg. loss: 0.063083\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.060973\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 0.056751\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 0.059295\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 0.062325\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 0.061332\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.063328\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 0.058363\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 0.061299\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.058226\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 0.057638\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.067842\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 0.057900\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 0.060820\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 0.064958\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 0.060813\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.060534\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.060972\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 0.058808\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 0.062449\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 0.059463\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.060659\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 0.060315\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 0.060726\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 0.058950\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 0.060871\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.061059\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 0.057497\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 0.059729\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 0.058330\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 0.062182\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.059363\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 0.065673\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 0.060496\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 0.062017\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 0.065738\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.061278\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 0.059583\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 0.060491\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 0.057862\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 0.059356\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.061113\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 0.054667\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 0.058612\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 0.060432\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 0.058239\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.056899\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 0.062780\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 0.058300\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 0.061100\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 0.061482\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.062680\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 0.057782\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 0.059659\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 0.058512\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 0.061556\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.057034\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 0.063956\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 0.058475\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 0.057433\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 0.058665\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.059158\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 0.054851\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 0.060163\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 0.060120\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 0.055696\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.057101\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 0.062004\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 0.058302\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 0.059566\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 0.056353\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.052485\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 0.056091\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 0.058645\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 0.060140\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 0.059279\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.056442\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 0.055669\n",
      "Train Epoch: 4 [49280/50000 (98%)]\tLoss: 0.063470\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 0.058328\n",
      "\n",
      "Test set: Avg. loss: 0.059172\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.057378\n",
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 0.058327\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.056869\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 0.055701\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 0.060099\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.060200\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 0.059471\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 0.063114\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.056552\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 0.058114\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.053170\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 0.058229\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 0.056203\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 0.057277\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 0.058287\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.056736\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.058493\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 0.061516\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 0.059094\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 0.057757\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.056530\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 0.057064\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 0.057031\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 0.059150\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.061019\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.057399\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 0.055978\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 0.052618\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 0.055480\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 0.062039\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.056731\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 0.057517\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.052961\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 0.053535\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 0.055994\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.057007\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 0.057602\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 0.051990\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 0.052161\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 0.054341\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.055839\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 0.054681\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 0.057736\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 0.054626\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 0.057522\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.055399\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 0.055226\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 0.058843\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.054501\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 0.056902\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.056249\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 0.055190\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 0.052826\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 0.055827\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 0.056457\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.055150\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.054740\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 0.062117\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 0.055692\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 0.055528\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.055447\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 0.053476\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 0.056000\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 0.056713\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.056455\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.052363\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 0.053335\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 0.057528\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 0.055109\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 0.051838\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.058615\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 0.056332\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.056827\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 0.058012\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 0.060449\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.057082\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 0.052930\n",
      "Train Epoch: 5 [49280/50000 (98%)]\tLoss: 0.054049\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 0.053690\n",
      "\n",
      "Test set: Avg. loss: 0.056435\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.056069\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 0.054061\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 0.058341\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 0.056241\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 0.057347\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.052564\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 0.055823\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 0.054331\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 0.053355\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 0.052906\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.050462\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 0.052187\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 0.052133\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 0.051329\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 0.053337\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.052709\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 0.054651\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 0.054689\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 0.057448\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 0.054950\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.056577\n",
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 0.054427\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 0.054254\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 0.054421\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 0.055656\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.050061\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 0.057263\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 0.051820\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 0.053001\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 0.052944\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.053125\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 0.052187\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 0.056253\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 0.056532\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 0.051855\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.054756\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 0.056176\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 0.051028\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 0.054101\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 0.051023\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.055140\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 0.053385\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 0.052792\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 0.050572\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 0.056577\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.053433\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 0.054291\n",
      "Train Epoch: 6 [30080/50000 (60%)]\tLoss: 0.052780\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 0.052523\n",
      "Train Epoch: 6 [31360/50000 (63%)]\tLoss: 0.053992\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.060134\n",
      "Train Epoch: 6 [32640/50000 (65%)]\tLoss: 0.056960\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 0.048270\n",
      "Train Epoch: 6 [33920/50000 (68%)]\tLoss: 0.051517\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 0.051128\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.051182\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 0.054129\n",
      "Train Epoch: 6 [36480/50000 (73%)]\tLoss: 0.052827\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 0.056911\n",
      "Train Epoch: 6 [37760/50000 (75%)]\tLoss: 0.052379\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.054259\n",
      "Train Epoch: 6 [39040/50000 (78%)]\tLoss: 0.051881\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 0.051936\n",
      "Train Epoch: 6 [40320/50000 (81%)]\tLoss: 0.054325\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 0.057862\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.056845\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 0.052067\n",
      "Train Epoch: 6 [42880/50000 (86%)]\tLoss: 0.052020\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 0.054096\n",
      "Train Epoch: 6 [44160/50000 (88%)]\tLoss: 0.052320\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.051835\n",
      "Train Epoch: 6 [45440/50000 (91%)]\tLoss: 0.051803\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 0.051923\n",
      "Train Epoch: 6 [46720/50000 (93%)]\tLoss: 0.051189\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 0.053109\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.053389\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 0.051290\n",
      "Train Epoch: 6 [49280/50000 (98%)]\tLoss: 0.053771\n",
      "Train Epoch: 6 [49920/50000 (100%)]\tLoss: 0.053172\n",
      "\n",
      "Test set: Avg. loss: 0.054349\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.054622\n",
      "Train Epoch: 7 [640/50000 (1%)]\tLoss: 0.052366\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 0.054863\n",
      "Train Epoch: 7 [1920/50000 (4%)]\tLoss: 0.050847\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 0.050018\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.050970\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 0.053295\n",
      "Train Epoch: 7 [4480/50000 (9%)]\tLoss: 0.051670\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 0.053437\n",
      "Train Epoch: 7 [5760/50000 (12%)]\tLoss: 0.054454\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.053883\n",
      "Train Epoch: 7 [7040/50000 (14%)]\tLoss: 0.049091\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 0.053601\n",
      "Train Epoch: 7 [8320/50000 (17%)]\tLoss: 0.056768\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 0.053062\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.053879\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 0.052333\n",
      "Train Epoch: 7 [10880/50000 (22%)]\tLoss: 0.052239\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 0.050139\n",
      "Train Epoch: 7 [12160/50000 (24%)]\tLoss: 0.053707\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.054696\n",
      "Train Epoch: 7 [13440/50000 (27%)]\tLoss: 0.053490\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 0.054165\n",
      "Train Epoch: 7 [14720/50000 (29%)]\tLoss: 0.054459\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 0.052550\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.050165\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 0.055312\n",
      "Train Epoch: 7 [17280/50000 (35%)]\tLoss: 0.048048\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 0.052010\n",
      "Train Epoch: 7 [18560/50000 (37%)]\tLoss: 0.049941\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.049437\n",
      "Train Epoch: 7 [19840/50000 (40%)]\tLoss: 0.049499\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 0.049978\n",
      "Train Epoch: 7 [21120/50000 (42%)]\tLoss: 0.052392\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 0.052494\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.050057\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 0.048726\n",
      "Train Epoch: 7 [23680/50000 (47%)]\tLoss: 0.051091\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 0.051898\n",
      "Train Epoch: 7 [24960/50000 (50%)]\tLoss: 0.052744\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.050913\n",
      "Train Epoch: 7 [26240/50000 (52%)]\tLoss: 0.051422\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 0.053458\n",
      "Train Epoch: 7 [27520/50000 (55%)]\tLoss: 0.052819\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 0.051183\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.053955\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 0.052233\n",
      "Train Epoch: 7 [30080/50000 (60%)]\tLoss: 0.053946\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 0.055501\n",
      "Train Epoch: 7 [31360/50000 (63%)]\tLoss: 0.052382\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.055630\n",
      "Train Epoch: 7 [32640/50000 (65%)]\tLoss: 0.053675\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 0.051979\n",
      "Train Epoch: 7 [33920/50000 (68%)]\tLoss: 0.052809\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 0.054894\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.053508\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 0.052573\n",
      "Train Epoch: 7 [36480/50000 (73%)]\tLoss: 0.048021\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 0.051593\n",
      "Train Epoch: 7 [37760/50000 (75%)]\tLoss: 0.050314\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.051973\n",
      "Train Epoch: 7 [39040/50000 (78%)]\tLoss: 0.057588\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 0.052444\n",
      "Train Epoch: 7 [40320/50000 (81%)]\tLoss: 0.050055\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 0.049219\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.050546\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 0.054284\n",
      "Train Epoch: 7 [42880/50000 (86%)]\tLoss: 0.050296\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 0.051211\n",
      "Train Epoch: 7 [44160/50000 (88%)]\tLoss: 0.052757\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.051854\n",
      "Train Epoch: 7 [45440/50000 (91%)]\tLoss: 0.053898\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 0.052065\n",
      "Train Epoch: 7 [46720/50000 (93%)]\tLoss: 0.048929\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 0.051634\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.054190\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 0.055582\n",
      "Train Epoch: 7 [49280/50000 (98%)]\tLoss: 0.052707\n",
      "Train Epoch: 7 [49920/50000 (100%)]\tLoss: 0.052527\n",
      "\n",
      "Test set: Avg. loss: 0.052693\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.051081\n",
      "Train Epoch: 8 [640/50000 (1%)]\tLoss: 0.051861\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 0.049955\n",
      "Train Epoch: 8 [1920/50000 (4%)]\tLoss: 0.050645\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 0.048852\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.053539\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 0.050434\n",
      "Train Epoch: 8 [4480/50000 (9%)]\tLoss: 0.051202\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 0.050685\n",
      "Train Epoch: 8 [5760/50000 (12%)]\tLoss: 0.047654\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.051777\n",
      "Train Epoch: 8 [7040/50000 (14%)]\tLoss: 0.052432\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 0.048772\n",
      "Train Epoch: 8 [8320/50000 (17%)]\tLoss: 0.050411\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 0.049980\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.052035\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 0.053315\n",
      "Train Epoch: 8 [10880/50000 (22%)]\tLoss: 0.052433\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 0.049740\n",
      "Train Epoch: 8 [12160/50000 (24%)]\tLoss: 0.047537\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.052687\n",
      "Train Epoch: 8 [13440/50000 (27%)]\tLoss: 0.050202\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 0.049612\n",
      "Train Epoch: 8 [14720/50000 (29%)]\tLoss: 0.055027\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 0.051609\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.049496\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 0.050056\n",
      "Train Epoch: 8 [17280/50000 (35%)]\tLoss: 0.051030\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 0.050664\n",
      "Train Epoch: 8 [18560/50000 (37%)]\tLoss: 0.046696\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.049293\n",
      "Train Epoch: 8 [19840/50000 (40%)]\tLoss: 0.047559\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 0.049556\n",
      "Train Epoch: 8 [21120/50000 (42%)]\tLoss: 0.050116\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 0.049890\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.049403\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 0.052636\n",
      "Train Epoch: 8 [23680/50000 (47%)]\tLoss: 0.052841\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 0.047404\n",
      "Train Epoch: 8 [24960/50000 (50%)]\tLoss: 0.050120\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.050564\n",
      "Train Epoch: 8 [26240/50000 (52%)]\tLoss: 0.048480\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 0.049535\n",
      "Train Epoch: 8 [27520/50000 (55%)]\tLoss: 0.055910\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 0.049524\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.048652\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 0.049315\n",
      "Train Epoch: 8 [30080/50000 (60%)]\tLoss: 0.048060\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 0.051970\n",
      "Train Epoch: 8 [31360/50000 (63%)]\tLoss: 0.049287\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.049158\n",
      "Train Epoch: 8 [32640/50000 (65%)]\tLoss: 0.047894\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 0.050677\n",
      "Train Epoch: 8 [33920/50000 (68%)]\tLoss: 0.053279\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 0.046814\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.049949\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 0.050089\n",
      "Train Epoch: 8 [36480/50000 (73%)]\tLoss: 0.049636\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 0.046375\n",
      "Train Epoch: 8 [37760/50000 (75%)]\tLoss: 0.051571\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.049144\n",
      "Train Epoch: 8 [39040/50000 (78%)]\tLoss: 0.051405\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 0.052378\n",
      "Train Epoch: 8 [40320/50000 (81%)]\tLoss: 0.050536\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 0.049382\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.046195\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 0.047287\n",
      "Train Epoch: 8 [42880/50000 (86%)]\tLoss: 0.049306\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 0.050677\n",
      "Train Epoch: 8 [44160/50000 (88%)]\tLoss: 0.047609\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.049832\n",
      "Train Epoch: 8 [45440/50000 (91%)]\tLoss: 0.051655\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 0.049395\n",
      "Train Epoch: 8 [46720/50000 (93%)]\tLoss: 0.048255\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 0.048987\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.052720\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 0.048208\n",
      "Train Epoch: 8 [49280/50000 (98%)]\tLoss: 0.050432\n",
      "Train Epoch: 8 [49920/50000 (100%)]\tLoss: 0.049049\n",
      "\n",
      "Test set: Avg. loss: 0.051360\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.046218\n",
      "Train Epoch: 9 [640/50000 (1%)]\tLoss: 0.049500\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 0.046970\n",
      "Train Epoch: 9 [1920/50000 (4%)]\tLoss: 0.049638\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 0.046574\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.050385\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 0.047062\n",
      "Train Epoch: 9 [4480/50000 (9%)]\tLoss: 0.053007\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 0.049133\n",
      "Train Epoch: 9 [5760/50000 (12%)]\tLoss: 0.047146\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.049136\n",
      "Train Epoch: 9 [7040/50000 (14%)]\tLoss: 0.048319\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 0.055471\n",
      "Train Epoch: 9 [8320/50000 (17%)]\tLoss: 0.048380\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 0.048150\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.052774\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 0.044673\n",
      "Train Epoch: 9 [10880/50000 (22%)]\tLoss: 0.048102\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 0.051729\n",
      "Train Epoch: 9 [12160/50000 (24%)]\tLoss: 0.049276\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.049715\n",
      "Train Epoch: 9 [13440/50000 (27%)]\tLoss: 0.050072\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 0.049460\n",
      "Train Epoch: 9 [14720/50000 (29%)]\tLoss: 0.048039\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 0.046531\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.053346\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 0.051486\n",
      "Train Epoch: 9 [17280/50000 (35%)]\tLoss: 0.049101\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 0.052064\n",
      "Train Epoch: 9 [18560/50000 (37%)]\tLoss: 0.050544\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.047647\n",
      "Train Epoch: 9 [19840/50000 (40%)]\tLoss: 0.051207\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 0.049365\n",
      "Train Epoch: 9 [21120/50000 (42%)]\tLoss: 0.047649\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 0.046497\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.049108\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 0.044082\n",
      "Train Epoch: 9 [23680/50000 (47%)]\tLoss: 0.050301\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 0.048982\n",
      "Train Epoch: 9 [24960/50000 (50%)]\tLoss: 0.046939\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.050976\n",
      "Train Epoch: 9 [26240/50000 (52%)]\tLoss: 0.047881\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 0.050904\n",
      "Train Epoch: 9 [27520/50000 (55%)]\tLoss: 0.051280\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 0.049520\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.048078\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 0.046495\n",
      "Train Epoch: 9 [30080/50000 (60%)]\tLoss: 0.049664\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 0.049331\n",
      "Train Epoch: 9 [31360/50000 (63%)]\tLoss: 0.048459\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.050525\n",
      "Train Epoch: 9 [32640/50000 (65%)]\tLoss: 0.051476\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 0.049274\n",
      "Train Epoch: 9 [33920/50000 (68%)]\tLoss: 0.045620\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 0.047443\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.049156\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 0.048624\n",
      "Train Epoch: 9 [36480/50000 (73%)]\tLoss: 0.051886\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 0.052248\n",
      "Train Epoch: 9 [37760/50000 (75%)]\tLoss: 0.050689\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.048111\n",
      "Train Epoch: 9 [39040/50000 (78%)]\tLoss: 0.050211\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 0.052557\n",
      "Train Epoch: 9 [40320/50000 (81%)]\tLoss: 0.050533\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 0.046494\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.046670\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 0.051125\n",
      "Train Epoch: 9 [42880/50000 (86%)]\tLoss: 0.049203\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 0.048500\n",
      "Train Epoch: 9 [44160/50000 (88%)]\tLoss: 0.048371\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.049189\n",
      "Train Epoch: 9 [45440/50000 (91%)]\tLoss: 0.051511\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 0.046158\n",
      "Train Epoch: 9 [46720/50000 (93%)]\tLoss: 0.047827\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 0.049567\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.047220\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 0.047991\n",
      "Train Epoch: 9 [49280/50000 (98%)]\tLoss: 0.053662\n",
      "Train Epoch: 9 [49920/50000 (100%)]\tLoss: 0.049861\n",
      "\n",
      "Test set: Avg. loss: 0.050204\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.053182\n",
      "Train Epoch: 10 [640/50000 (1%)]\tLoss: 0.045358\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 0.048666\n",
      "Train Epoch: 10 [1920/50000 (4%)]\tLoss: 0.049806\n",
      "Train Epoch: 10 [2560/50000 (5%)]\tLoss: 0.050612\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 0.047889\n",
      "Train Epoch: 10 [3840/50000 (8%)]\tLoss: 0.045135\n",
      "Train Epoch: 10 [4480/50000 (9%)]\tLoss: 0.045956\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 0.050841\n",
      "Train Epoch: 10 [5760/50000 (12%)]\tLoss: 0.045706\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.049839\n",
      "Train Epoch: 10 [7040/50000 (14%)]\tLoss: 0.050919\n",
      "Train Epoch: 10 [7680/50000 (15%)]\tLoss: 0.049378\n",
      "Train Epoch: 10 [8320/50000 (17%)]\tLoss: 0.045461\n",
      "Train Epoch: 10 [8960/50000 (18%)]\tLoss: 0.045872\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.043992\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 0.044510\n",
      "Train Epoch: 10 [10880/50000 (22%)]\tLoss: 0.047129\n",
      "Train Epoch: 10 [11520/50000 (23%)]\tLoss: 0.046791\n",
      "Train Epoch: 10 [12160/50000 (24%)]\tLoss: 0.045510\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.048407\n",
      "Train Epoch: 10 [13440/50000 (27%)]\tLoss: 0.049126\n",
      "Train Epoch: 10 [14080/50000 (28%)]\tLoss: 0.050153\n",
      "Train Epoch: 10 [14720/50000 (29%)]\tLoss: 0.049003\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 0.049351\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.049599\n",
      "Train Epoch: 10 [16640/50000 (33%)]\tLoss: 0.050774\n",
      "Train Epoch: 10 [17280/50000 (35%)]\tLoss: 0.049112\n",
      "Train Epoch: 10 [17920/50000 (36%)]\tLoss: 0.045183\n",
      "Train Epoch: 10 [18560/50000 (37%)]\tLoss: 0.049323\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.048552\n",
      "Train Epoch: 10 [19840/50000 (40%)]\tLoss: 0.046940\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 0.044882\n",
      "Train Epoch: 10 [21120/50000 (42%)]\tLoss: 0.046371\n",
      "Train Epoch: 10 [21760/50000 (43%)]\tLoss: 0.050413\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.045535\n",
      "Train Epoch: 10 [23040/50000 (46%)]\tLoss: 0.044345\n",
      "Train Epoch: 10 [23680/50000 (47%)]\tLoss: 0.050366\n",
      "Train Epoch: 10 [24320/50000 (49%)]\tLoss: 0.047891\n",
      "Train Epoch: 10 [24960/50000 (50%)]\tLoss: 0.046467\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.048957\n",
      "Train Epoch: 10 [26240/50000 (52%)]\tLoss: 0.049749\n",
      "Train Epoch: 10 [26880/50000 (54%)]\tLoss: 0.048910\n",
      "Train Epoch: 10 [27520/50000 (55%)]\tLoss: 0.049045\n",
      "Train Epoch: 10 [28160/50000 (56%)]\tLoss: 0.048088\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.048010\n",
      "Train Epoch: 10 [29440/50000 (59%)]\tLoss: 0.047425\n",
      "Train Epoch: 10 [30080/50000 (60%)]\tLoss: 0.049830\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 0.047551\n",
      "Train Epoch: 10 [31360/50000 (63%)]\tLoss: 0.045869\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.044784\n",
      "Train Epoch: 10 [32640/50000 (65%)]\tLoss: 0.047232\n",
      "Train Epoch: 10 [33280/50000 (66%)]\tLoss: 0.048985\n",
      "Train Epoch: 10 [33920/50000 (68%)]\tLoss: 0.047292\n",
      "Train Epoch: 10 [34560/50000 (69%)]\tLoss: 0.050975\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 0.044812\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 0.047835\n",
      "Train Epoch: 10 [36480/50000 (73%)]\tLoss: 0.049889\n",
      "Train Epoch: 10 [37120/50000 (74%)]\tLoss: 0.047227\n",
      "Train Epoch: 10 [37760/50000 (75%)]\tLoss: 0.049611\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.048178\n",
      "Train Epoch: 10 [39040/50000 (78%)]\tLoss: 0.046724\n",
      "Train Epoch: 10 [39680/50000 (79%)]\tLoss: 0.046762\n",
      "Train Epoch: 10 [40320/50000 (81%)]\tLoss: 0.052110\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 0.045724\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.051437\n",
      "Train Epoch: 10 [42240/50000 (84%)]\tLoss: 0.045163\n",
      "Train Epoch: 10 [42880/50000 (86%)]\tLoss: 0.045236\n",
      "Train Epoch: 10 [43520/50000 (87%)]\tLoss: 0.046522\n",
      "Train Epoch: 10 [44160/50000 (88%)]\tLoss: 0.048646\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.049969\n",
      "Train Epoch: 10 [45440/50000 (91%)]\tLoss: 0.045723\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 0.045492\n",
      "Train Epoch: 10 [46720/50000 (93%)]\tLoss: 0.044729\n",
      "Train Epoch: 10 [47360/50000 (95%)]\tLoss: 0.045122\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.047763\n",
      "Train Epoch: 10 [48640/50000 (97%)]\tLoss: 0.050636\n",
      "Train Epoch: 10 [49280/50000 (98%)]\tLoss: 0.045799\n",
      "Train Epoch: 10 [49920/50000 (100%)]\tLoss: 0.048642\n",
      "\n",
      "Test set: Avg. loss: 0.049244\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.046968\n",
      "Train Epoch: 11 [640/50000 (1%)]\tLoss: 0.046264\n",
      "Train Epoch: 11 [1280/50000 (3%)]\tLoss: 0.046148\n",
      "Train Epoch: 11 [1920/50000 (4%)]\tLoss: 0.047936\n",
      "Train Epoch: 11 [2560/50000 (5%)]\tLoss: 0.047196\n",
      "Train Epoch: 11 [3200/50000 (6%)]\tLoss: 0.046058\n",
      "Train Epoch: 11 [3840/50000 (8%)]\tLoss: 0.047103\n",
      "Train Epoch: 11 [4480/50000 (9%)]\tLoss: 0.048367\n",
      "Train Epoch: 11 [5120/50000 (10%)]\tLoss: 0.043189\n",
      "Train Epoch: 11 [5760/50000 (12%)]\tLoss: 0.046964\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.047680\n",
      "Train Epoch: 11 [7040/50000 (14%)]\tLoss: 0.048057\n",
      "Train Epoch: 11 [7680/50000 (15%)]\tLoss: 0.048336\n",
      "Train Epoch: 11 [8320/50000 (17%)]\tLoss: 0.043647\n",
      "Train Epoch: 11 [8960/50000 (18%)]\tLoss: 0.046834\n",
      "Train Epoch: 11 [9600/50000 (19%)]\tLoss: 0.048396\n",
      "Train Epoch: 11 [10240/50000 (20%)]\tLoss: 0.044559\n",
      "Train Epoch: 11 [10880/50000 (22%)]\tLoss: 0.045190\n",
      "Train Epoch: 11 [11520/50000 (23%)]\tLoss: 0.045065\n",
      "Train Epoch: 11 [12160/50000 (24%)]\tLoss: 0.048157\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.050500\n",
      "Train Epoch: 11 [13440/50000 (27%)]\tLoss: 0.047789\n",
      "Train Epoch: 11 [14080/50000 (28%)]\tLoss: 0.049419\n",
      "Train Epoch: 11 [14720/50000 (29%)]\tLoss: 0.046197\n",
      "Train Epoch: 11 [15360/50000 (31%)]\tLoss: 0.051625\n",
      "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.047275\n",
      "Train Epoch: 11 [16640/50000 (33%)]\tLoss: 0.051927\n",
      "Train Epoch: 11 [17280/50000 (35%)]\tLoss: 0.046544\n",
      "Train Epoch: 11 [17920/50000 (36%)]\tLoss: 0.044146\n",
      "Train Epoch: 11 [18560/50000 (37%)]\tLoss: 0.047064\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.045071\n",
      "Train Epoch: 11 [19840/50000 (40%)]\tLoss: 0.046933\n",
      "Train Epoch: 11 [20480/50000 (41%)]\tLoss: 0.047678\n",
      "Train Epoch: 11 [21120/50000 (42%)]\tLoss: 0.047352\n",
      "Train Epoch: 11 [21760/50000 (43%)]\tLoss: 0.047253\n",
      "Train Epoch: 11 [22400/50000 (45%)]\tLoss: 0.044267\n",
      "Train Epoch: 11 [23040/50000 (46%)]\tLoss: 0.044371\n",
      "Train Epoch: 11 [23680/50000 (47%)]\tLoss: 0.044557\n",
      "Train Epoch: 11 [24320/50000 (49%)]\tLoss: 0.045197\n",
      "Train Epoch: 11 [24960/50000 (50%)]\tLoss: 0.048020\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.051579\n",
      "Train Epoch: 11 [26240/50000 (52%)]\tLoss: 0.045949\n",
      "Train Epoch: 11 [26880/50000 (54%)]\tLoss: 0.047944\n",
      "Train Epoch: 11 [27520/50000 (55%)]\tLoss: 0.046760\n",
      "Train Epoch: 11 [28160/50000 (56%)]\tLoss: 0.048059\n",
      "Train Epoch: 11 [28800/50000 (58%)]\tLoss: 0.047556\n",
      "Train Epoch: 11 [29440/50000 (59%)]\tLoss: 0.046279\n",
      "Train Epoch: 11 [30080/50000 (60%)]\tLoss: 0.046978\n",
      "Train Epoch: 11 [30720/50000 (61%)]\tLoss: 0.046832\n",
      "Train Epoch: 11 [31360/50000 (63%)]\tLoss: 0.045118\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.046756\n",
      "Train Epoch: 11 [32640/50000 (65%)]\tLoss: 0.047065\n",
      "Train Epoch: 11 [33280/50000 (66%)]\tLoss: 0.046881\n",
      "Train Epoch: 11 [33920/50000 (68%)]\tLoss: 0.045969\n",
      "Train Epoch: 11 [34560/50000 (69%)]\tLoss: 0.049676\n",
      "Train Epoch: 11 [35200/50000 (70%)]\tLoss: 0.042211\n",
      "Train Epoch: 11 [35840/50000 (72%)]\tLoss: 0.048177\n",
      "Train Epoch: 11 [36480/50000 (73%)]\tLoss: 0.048410\n",
      "Train Epoch: 11 [37120/50000 (74%)]\tLoss: 0.044428\n",
      "Train Epoch: 11 [37760/50000 (75%)]\tLoss: 0.045627\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.048334\n",
      "Train Epoch: 11 [39040/50000 (78%)]\tLoss: 0.043434\n",
      "Train Epoch: 11 [39680/50000 (79%)]\tLoss: 0.046032\n",
      "Train Epoch: 11 [40320/50000 (81%)]\tLoss: 0.048827\n",
      "Train Epoch: 11 [40960/50000 (82%)]\tLoss: 0.045291\n",
      "Train Epoch: 11 [41600/50000 (83%)]\tLoss: 0.044866\n",
      "Train Epoch: 11 [42240/50000 (84%)]\tLoss: 0.046798\n",
      "Train Epoch: 11 [42880/50000 (86%)]\tLoss: 0.041575\n",
      "Train Epoch: 11 [43520/50000 (87%)]\tLoss: 0.043149\n",
      "Train Epoch: 11 [44160/50000 (88%)]\tLoss: 0.047234\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.048616\n",
      "Train Epoch: 11 [45440/50000 (91%)]\tLoss: 0.047371\n",
      "Train Epoch: 11 [46080/50000 (92%)]\tLoss: 0.044523\n",
      "Train Epoch: 11 [46720/50000 (93%)]\tLoss: 0.046587\n",
      "Train Epoch: 11 [47360/50000 (95%)]\tLoss: 0.047549\n",
      "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.044224\n",
      "Train Epoch: 11 [48640/50000 (97%)]\tLoss: 0.044791\n",
      "Train Epoch: 11 [49280/50000 (98%)]\tLoss: 0.042443\n",
      "Train Epoch: 11 [49920/50000 (100%)]\tLoss: 0.043975\n",
      "\n",
      "Test set: Avg. loss: 0.048425\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.048384\n",
      "Train Epoch: 12 [640/50000 (1%)]\tLoss: 0.047340\n",
      "Train Epoch: 12 [1280/50000 (3%)]\tLoss: 0.045562\n",
      "Train Epoch: 12 [1920/50000 (4%)]\tLoss: 0.046102\n",
      "Train Epoch: 12 [2560/50000 (5%)]\tLoss: 0.047458\n",
      "Train Epoch: 12 [3200/50000 (6%)]\tLoss: 0.046329\n",
      "Train Epoch: 12 [3840/50000 (8%)]\tLoss: 0.047103\n",
      "Train Epoch: 12 [4480/50000 (9%)]\tLoss: 0.048302\n",
      "Train Epoch: 12 [5120/50000 (10%)]\tLoss: 0.047847\n",
      "Train Epoch: 12 [5760/50000 (12%)]\tLoss: 0.044755\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.043518\n",
      "Train Epoch: 12 [7040/50000 (14%)]\tLoss: 0.045392\n",
      "Train Epoch: 12 [7680/50000 (15%)]\tLoss: 0.045283\n",
      "Train Epoch: 12 [8320/50000 (17%)]\tLoss: 0.045494\n",
      "Train Epoch: 12 [8960/50000 (18%)]\tLoss: 0.043742\n",
      "Train Epoch: 12 [9600/50000 (19%)]\tLoss: 0.046406\n",
      "Train Epoch: 12 [10240/50000 (20%)]\tLoss: 0.046101\n",
      "Train Epoch: 12 [10880/50000 (22%)]\tLoss: 0.046011\n",
      "Train Epoch: 12 [11520/50000 (23%)]\tLoss: 0.046244\n",
      "Train Epoch: 12 [12160/50000 (24%)]\tLoss: 0.048543\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.047638\n",
      "Train Epoch: 12 [13440/50000 (27%)]\tLoss: 0.043702\n",
      "Train Epoch: 12 [14080/50000 (28%)]\tLoss: 0.045620\n",
      "Train Epoch: 12 [14720/50000 (29%)]\tLoss: 0.047108\n",
      "Train Epoch: 12 [15360/50000 (31%)]\tLoss: 0.048187\n",
      "Train Epoch: 12 [16000/50000 (32%)]\tLoss: 0.049096\n",
      "Train Epoch: 12 [16640/50000 (33%)]\tLoss: 0.046596\n",
      "Train Epoch: 12 [17280/50000 (35%)]\tLoss: 0.047982\n",
      "Train Epoch: 12 [17920/50000 (36%)]\tLoss: 0.046892\n",
      "Train Epoch: 12 [18560/50000 (37%)]\tLoss: 0.045460\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.043752\n",
      "Train Epoch: 12 [19840/50000 (40%)]\tLoss: 0.043615\n",
      "Train Epoch: 12 [20480/50000 (41%)]\tLoss: 0.046082\n",
      "Train Epoch: 12 [21120/50000 (42%)]\tLoss: 0.049509\n",
      "Train Epoch: 12 [21760/50000 (43%)]\tLoss: 0.044034\n",
      "Train Epoch: 12 [22400/50000 (45%)]\tLoss: 0.045861\n",
      "Train Epoch: 12 [23040/50000 (46%)]\tLoss: 0.047173\n",
      "Train Epoch: 12 [23680/50000 (47%)]\tLoss: 0.044829\n",
      "Train Epoch: 12 [24320/50000 (49%)]\tLoss: 0.047776\n",
      "Train Epoch: 12 [24960/50000 (50%)]\tLoss: 0.041710\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.045942\n",
      "Train Epoch: 12 [26240/50000 (52%)]\tLoss: 0.043869\n",
      "Train Epoch: 12 [26880/50000 (54%)]\tLoss: 0.048653\n",
      "Train Epoch: 12 [27520/50000 (55%)]\tLoss: 0.044914\n",
      "Train Epoch: 12 [28160/50000 (56%)]\tLoss: 0.045897\n",
      "Train Epoch: 12 [28800/50000 (58%)]\tLoss: 0.046835\n",
      "Train Epoch: 12 [29440/50000 (59%)]\tLoss: 0.046160\n",
      "Train Epoch: 12 [30080/50000 (60%)]\tLoss: 0.046247\n",
      "Train Epoch: 12 [30720/50000 (61%)]\tLoss: 0.046312\n",
      "Train Epoch: 12 [31360/50000 (63%)]\tLoss: 0.042919\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.048953\n",
      "Train Epoch: 12 [32640/50000 (65%)]\tLoss: 0.045804\n",
      "Train Epoch: 12 [33280/50000 (66%)]\tLoss: 0.046943\n",
      "Train Epoch: 12 [33920/50000 (68%)]\tLoss: 0.045595\n",
      "Train Epoch: 12 [34560/50000 (69%)]\tLoss: 0.044617\n",
      "Train Epoch: 12 [35200/50000 (70%)]\tLoss: 0.047577\n",
      "Train Epoch: 12 [35840/50000 (72%)]\tLoss: 0.044263\n",
      "Train Epoch: 12 [36480/50000 (73%)]\tLoss: 0.047051\n",
      "Train Epoch: 12 [37120/50000 (74%)]\tLoss: 0.046803\n",
      "Train Epoch: 12 [37760/50000 (75%)]\tLoss: 0.042367\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.047867\n",
      "Train Epoch: 12 [39040/50000 (78%)]\tLoss: 0.045775\n",
      "Train Epoch: 12 [39680/50000 (79%)]\tLoss: 0.046487\n",
      "Train Epoch: 12 [40320/50000 (81%)]\tLoss: 0.045514\n",
      "Train Epoch: 12 [40960/50000 (82%)]\tLoss: 0.046538\n",
      "Train Epoch: 12 [41600/50000 (83%)]\tLoss: 0.045775\n",
      "Train Epoch: 12 [42240/50000 (84%)]\tLoss: 0.043824\n",
      "Train Epoch: 12 [42880/50000 (86%)]\tLoss: 0.044335\n",
      "Train Epoch: 12 [43520/50000 (87%)]\tLoss: 0.045507\n",
      "Train Epoch: 12 [44160/50000 (88%)]\tLoss: 0.043073\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.045868\n",
      "Train Epoch: 12 [45440/50000 (91%)]\tLoss: 0.046963\n",
      "Train Epoch: 12 [46080/50000 (92%)]\tLoss: 0.044935\n",
      "Train Epoch: 12 [46720/50000 (93%)]\tLoss: 0.044439\n",
      "Train Epoch: 12 [47360/50000 (95%)]\tLoss: 0.045147\n",
      "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 0.046634\n",
      "Train Epoch: 12 [48640/50000 (97%)]\tLoss: 0.047665\n",
      "Train Epoch: 12 [49280/50000 (98%)]\tLoss: 0.047710\n",
      "Train Epoch: 12 [49920/50000 (100%)]\tLoss: 0.047620\n",
      "\n",
      "Test set: Avg. loss: 0.047686\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.044253\n",
      "Train Epoch: 13 [640/50000 (1%)]\tLoss: 0.044919\n",
      "Train Epoch: 13 [1280/50000 (3%)]\tLoss: 0.043164\n",
      "Train Epoch: 13 [1920/50000 (4%)]\tLoss: 0.045174\n",
      "Train Epoch: 13 [2560/50000 (5%)]\tLoss: 0.046408\n",
      "Train Epoch: 13 [3200/50000 (6%)]\tLoss: 0.044977\n",
      "Train Epoch: 13 [3840/50000 (8%)]\tLoss: 0.048204\n",
      "Train Epoch: 13 [4480/50000 (9%)]\tLoss: 0.044453\n",
      "Train Epoch: 13 [5120/50000 (10%)]\tLoss: 0.041639\n",
      "Train Epoch: 13 [5760/50000 (12%)]\tLoss: 0.043382\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.045113\n",
      "Train Epoch: 13 [7040/50000 (14%)]\tLoss: 0.045987\n",
      "Train Epoch: 13 [7680/50000 (15%)]\tLoss: 0.043015\n",
      "Train Epoch: 13 [8320/50000 (17%)]\tLoss: 0.043816\n",
      "Train Epoch: 13 [8960/50000 (18%)]\tLoss: 0.045192\n",
      "Train Epoch: 13 [9600/50000 (19%)]\tLoss: 0.047760\n",
      "Train Epoch: 13 [10240/50000 (20%)]\tLoss: 0.043822\n",
      "Train Epoch: 13 [10880/50000 (22%)]\tLoss: 0.045497\n",
      "Train Epoch: 13 [11520/50000 (23%)]\tLoss: 0.045939\n",
      "Train Epoch: 13 [12160/50000 (24%)]\tLoss: 0.042944\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.043340\n",
      "Train Epoch: 13 [13440/50000 (27%)]\tLoss: 0.042987\n",
      "Train Epoch: 13 [14080/50000 (28%)]\tLoss: 0.043892\n",
      "Train Epoch: 13 [14720/50000 (29%)]\tLoss: 0.043546\n",
      "Train Epoch: 13 [15360/50000 (31%)]\tLoss: 0.042227\n",
      "Train Epoch: 13 [16000/50000 (32%)]\tLoss: 0.045359\n",
      "Train Epoch: 13 [16640/50000 (33%)]\tLoss: 0.045516\n",
      "Train Epoch: 13 [17280/50000 (35%)]\tLoss: 0.043803\n",
      "Train Epoch: 13 [17920/50000 (36%)]\tLoss: 0.046662\n",
      "Train Epoch: 13 [18560/50000 (37%)]\tLoss: 0.043627\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.044490\n",
      "Train Epoch: 13 [19840/50000 (40%)]\tLoss: 0.047195\n",
      "Train Epoch: 13 [20480/50000 (41%)]\tLoss: 0.045863\n",
      "Train Epoch: 13 [21120/50000 (42%)]\tLoss: 0.046729\n",
      "Train Epoch: 13 [21760/50000 (43%)]\tLoss: 0.045540\n",
      "Train Epoch: 13 [22400/50000 (45%)]\tLoss: 0.042888\n",
      "Train Epoch: 13 [23040/50000 (46%)]\tLoss: 0.041668\n",
      "Train Epoch: 13 [23680/50000 (47%)]\tLoss: 0.042330\n",
      "Train Epoch: 13 [24320/50000 (49%)]\tLoss: 0.046277\n",
      "Train Epoch: 13 [24960/50000 (50%)]\tLoss: 0.042898\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.044631\n",
      "Train Epoch: 13 [26240/50000 (52%)]\tLoss: 0.045925\n",
      "Train Epoch: 13 [26880/50000 (54%)]\tLoss: 0.045094\n",
      "Train Epoch: 13 [27520/50000 (55%)]\tLoss: 0.045463\n",
      "Train Epoch: 13 [28160/50000 (56%)]\tLoss: 0.043253\n",
      "Train Epoch: 13 [28800/50000 (58%)]\tLoss: 0.046413\n",
      "Train Epoch: 13 [29440/50000 (59%)]\tLoss: 0.047714\n",
      "Train Epoch: 13 [30080/50000 (60%)]\tLoss: 0.044058\n",
      "Train Epoch: 13 [30720/50000 (61%)]\tLoss: 0.047956\n",
      "Train Epoch: 13 [31360/50000 (63%)]\tLoss: 0.046365\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.044904\n",
      "Train Epoch: 13 [32640/50000 (65%)]\tLoss: 0.046058\n",
      "Train Epoch: 13 [33280/50000 (66%)]\tLoss: 0.045624\n",
      "Train Epoch: 13 [33920/50000 (68%)]\tLoss: 0.046432\n",
      "Train Epoch: 13 [34560/50000 (69%)]\tLoss: 0.043955\n",
      "Train Epoch: 13 [35200/50000 (70%)]\tLoss: 0.045470\n",
      "Train Epoch: 13 [35840/50000 (72%)]\tLoss: 0.044370\n",
      "Train Epoch: 13 [36480/50000 (73%)]\tLoss: 0.049294\n",
      "Train Epoch: 13 [37120/50000 (74%)]\tLoss: 0.043991\n",
      "Train Epoch: 13 [37760/50000 (75%)]\tLoss: 0.041144\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.042993\n",
      "Train Epoch: 13 [39040/50000 (78%)]\tLoss: 0.044311\n",
      "Train Epoch: 13 [39680/50000 (79%)]\tLoss: 0.043236\n",
      "Train Epoch: 13 [40320/50000 (81%)]\tLoss: 0.041529\n",
      "Train Epoch: 13 [40960/50000 (82%)]\tLoss: 0.043302\n",
      "Train Epoch: 13 [41600/50000 (83%)]\tLoss: 0.043047\n",
      "Train Epoch: 13 [42240/50000 (84%)]\tLoss: 0.045118\n",
      "Train Epoch: 13 [42880/50000 (86%)]\tLoss: 0.044922\n",
      "Train Epoch: 13 [43520/50000 (87%)]\tLoss: 0.043429\n",
      "Train Epoch: 13 [44160/50000 (88%)]\tLoss: 0.043376\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.042371\n",
      "Train Epoch: 13 [45440/50000 (91%)]\tLoss: 0.046249\n",
      "Train Epoch: 13 [46080/50000 (92%)]\tLoss: 0.043997\n",
      "Train Epoch: 13 [46720/50000 (93%)]\tLoss: 0.043496\n",
      "Train Epoch: 13 [47360/50000 (95%)]\tLoss: 0.045027\n",
      "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 0.046594\n",
      "Train Epoch: 13 [48640/50000 (97%)]\tLoss: 0.044093\n",
      "Train Epoch: 13 [49280/50000 (98%)]\tLoss: 0.041514\n",
      "Train Epoch: 13 [49920/50000 (100%)]\tLoss: 0.046457\n",
      "\n",
      "Test set: Avg. loss: 0.047043\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.043893\n",
      "Train Epoch: 14 [640/50000 (1%)]\tLoss: 0.041293\n",
      "Train Epoch: 14 [1280/50000 (3%)]\tLoss: 0.043413\n",
      "Train Epoch: 14 [1920/50000 (4%)]\tLoss: 0.048146\n",
      "Train Epoch: 14 [2560/50000 (5%)]\tLoss: 0.045138\n",
      "Train Epoch: 14 [3200/50000 (6%)]\tLoss: 0.043147\n",
      "Train Epoch: 14 [3840/50000 (8%)]\tLoss: 0.042623\n",
      "Train Epoch: 14 [4480/50000 (9%)]\tLoss: 0.042070\n",
      "Train Epoch: 14 [5120/50000 (10%)]\tLoss: 0.043416\n",
      "Train Epoch: 14 [5760/50000 (12%)]\tLoss: 0.042063\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.042615\n",
      "Train Epoch: 14 [7040/50000 (14%)]\tLoss: 0.045985\n",
      "Train Epoch: 14 [7680/50000 (15%)]\tLoss: 0.043940\n",
      "Train Epoch: 14 [8320/50000 (17%)]\tLoss: 0.044157\n",
      "Train Epoch: 14 [8960/50000 (18%)]\tLoss: 0.042666\n",
      "Train Epoch: 14 [9600/50000 (19%)]\tLoss: 0.044870\n",
      "Train Epoch: 14 [10240/50000 (20%)]\tLoss: 0.044259\n",
      "Train Epoch: 14 [10880/50000 (22%)]\tLoss: 0.045989\n",
      "Train Epoch: 14 [11520/50000 (23%)]\tLoss: 0.044068\n",
      "Train Epoch: 14 [12160/50000 (24%)]\tLoss: 0.043490\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.044255\n",
      "Train Epoch: 14 [13440/50000 (27%)]\tLoss: 0.047573\n",
      "Train Epoch: 14 [14080/50000 (28%)]\tLoss: 0.045131\n",
      "Train Epoch: 14 [14720/50000 (29%)]\tLoss: 0.044425\n",
      "Train Epoch: 14 [15360/50000 (31%)]\tLoss: 0.042151\n",
      "Train Epoch: 14 [16000/50000 (32%)]\tLoss: 0.046227\n",
      "Train Epoch: 14 [16640/50000 (33%)]\tLoss: 0.043849\n",
      "Train Epoch: 14 [17280/50000 (35%)]\tLoss: 0.046936\n",
      "Train Epoch: 14 [17920/50000 (36%)]\tLoss: 0.044572\n",
      "Train Epoch: 14 [18560/50000 (37%)]\tLoss: 0.045838\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.043566\n",
      "Train Epoch: 14 [19840/50000 (40%)]\tLoss: 0.045591\n",
      "Train Epoch: 14 [20480/50000 (41%)]\tLoss: 0.044552\n",
      "Train Epoch: 14 [21120/50000 (42%)]\tLoss: 0.043258\n",
      "Train Epoch: 14 [21760/50000 (43%)]\tLoss: 0.044028\n",
      "Train Epoch: 14 [22400/50000 (45%)]\tLoss: 0.045862\n",
      "Train Epoch: 14 [23040/50000 (46%)]\tLoss: 0.046602\n",
      "Train Epoch: 14 [23680/50000 (47%)]\tLoss: 0.042529\n",
      "Train Epoch: 14 [24320/50000 (49%)]\tLoss: 0.046823\n",
      "Train Epoch: 14 [24960/50000 (50%)]\tLoss: 0.044849\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.042243\n",
      "Train Epoch: 14 [26240/50000 (52%)]\tLoss: 0.046739\n",
      "Train Epoch: 14 [26880/50000 (54%)]\tLoss: 0.045352\n",
      "Train Epoch: 14 [27520/50000 (55%)]\tLoss: 0.042356\n",
      "Train Epoch: 14 [28160/50000 (56%)]\tLoss: 0.044597\n",
      "Train Epoch: 14 [28800/50000 (58%)]\tLoss: 0.045477\n",
      "Train Epoch: 14 [29440/50000 (59%)]\tLoss: 0.044136\n",
      "Train Epoch: 14 [30080/50000 (60%)]\tLoss: 0.044291\n",
      "Train Epoch: 14 [30720/50000 (61%)]\tLoss: 0.044673\n",
      "Train Epoch: 14 [31360/50000 (63%)]\tLoss: 0.045529\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.041414\n",
      "Train Epoch: 14 [32640/50000 (65%)]\tLoss: 0.047227\n",
      "Train Epoch: 14 [33280/50000 (66%)]\tLoss: 0.042962\n",
      "Train Epoch: 14 [33920/50000 (68%)]\tLoss: 0.043076\n",
      "Train Epoch: 14 [34560/50000 (69%)]\tLoss: 0.044522\n",
      "Train Epoch: 14 [35200/50000 (70%)]\tLoss: 0.041876\n",
      "Train Epoch: 14 [35840/50000 (72%)]\tLoss: 0.044325\n",
      "Train Epoch: 14 [36480/50000 (73%)]\tLoss: 0.047244\n",
      "Train Epoch: 14 [37120/50000 (74%)]\tLoss: 0.043317\n",
      "Train Epoch: 14 [37760/50000 (75%)]\tLoss: 0.045267\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.042558\n",
      "Train Epoch: 14 [39040/50000 (78%)]\tLoss: 0.044505\n",
      "Train Epoch: 14 [39680/50000 (79%)]\tLoss: 0.042643\n",
      "Train Epoch: 14 [40320/50000 (81%)]\tLoss: 0.044072\n",
      "Train Epoch: 14 [40960/50000 (82%)]\tLoss: 0.042549\n",
      "Train Epoch: 14 [41600/50000 (83%)]\tLoss: 0.044451\n",
      "Train Epoch: 14 [42240/50000 (84%)]\tLoss: 0.044550\n",
      "Train Epoch: 14 [42880/50000 (86%)]\tLoss: 0.039341\n",
      "Train Epoch: 14 [43520/50000 (87%)]\tLoss: 0.046770\n",
      "Train Epoch: 14 [44160/50000 (88%)]\tLoss: 0.042959\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.042288\n",
      "Train Epoch: 14 [45440/50000 (91%)]\tLoss: 0.044897\n",
      "Train Epoch: 14 [46080/50000 (92%)]\tLoss: 0.046065\n",
      "Train Epoch: 14 [46720/50000 (93%)]\tLoss: 0.044049\n",
      "Train Epoch: 14 [47360/50000 (95%)]\tLoss: 0.045491\n",
      "Train Epoch: 14 [48000/50000 (96%)]\tLoss: 0.047557\n",
      "Train Epoch: 14 [48640/50000 (97%)]\tLoss: 0.044545\n",
      "Train Epoch: 14 [49280/50000 (98%)]\tLoss: 0.043382\n",
      "Train Epoch: 14 [49920/50000 (100%)]\tLoss: 0.043392\n",
      "\n",
      "Test set: Avg. loss: 0.046443\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.040290\n",
      "Train Epoch: 15 [640/50000 (1%)]\tLoss: 0.043468\n",
      "Train Epoch: 15 [1280/50000 (3%)]\tLoss: 0.046046\n",
      "Train Epoch: 15 [1920/50000 (4%)]\tLoss: 0.043152\n",
      "Train Epoch: 15 [2560/50000 (5%)]\tLoss: 0.043002\n",
      "Train Epoch: 15 [3200/50000 (6%)]\tLoss: 0.041067\n",
      "Train Epoch: 15 [3840/50000 (8%)]\tLoss: 0.041709\n",
      "Train Epoch: 15 [4480/50000 (9%)]\tLoss: 0.044859\n",
      "Train Epoch: 15 [5120/50000 (10%)]\tLoss: 0.042770\n",
      "Train Epoch: 15 [5760/50000 (12%)]\tLoss: 0.044402\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.044935\n",
      "Train Epoch: 15 [7040/50000 (14%)]\tLoss: 0.041480\n",
      "Train Epoch: 15 [7680/50000 (15%)]\tLoss: 0.043534\n",
      "Train Epoch: 15 [8320/50000 (17%)]\tLoss: 0.044381\n",
      "Train Epoch: 15 [8960/50000 (18%)]\tLoss: 0.047888\n",
      "Train Epoch: 15 [9600/50000 (19%)]\tLoss: 0.045516\n",
      "Train Epoch: 15 [10240/50000 (20%)]\tLoss: 0.043146\n",
      "Train Epoch: 15 [10880/50000 (22%)]\tLoss: 0.045289\n",
      "Train Epoch: 15 [11520/50000 (23%)]\tLoss: 0.047440\n",
      "Train Epoch: 15 [12160/50000 (24%)]\tLoss: 0.046052\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.044910\n",
      "Train Epoch: 15 [13440/50000 (27%)]\tLoss: 0.044522\n",
      "Train Epoch: 15 [14080/50000 (28%)]\tLoss: 0.043659\n",
      "Train Epoch: 15 [14720/50000 (29%)]\tLoss: 0.044641\n",
      "Train Epoch: 15 [15360/50000 (31%)]\tLoss: 0.043725\n",
      "Train Epoch: 15 [16000/50000 (32%)]\tLoss: 0.043741\n",
      "Train Epoch: 15 [16640/50000 (33%)]\tLoss: 0.042799\n",
      "Train Epoch: 15 [17280/50000 (35%)]\tLoss: 0.044912\n",
      "Train Epoch: 15 [17920/50000 (36%)]\tLoss: 0.044099\n",
      "Train Epoch: 15 [18560/50000 (37%)]\tLoss: 0.044378\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.046362\n",
      "Train Epoch: 15 [19840/50000 (40%)]\tLoss: 0.046626\n",
      "Train Epoch: 15 [20480/50000 (41%)]\tLoss: 0.045823\n",
      "Train Epoch: 15 [21120/50000 (42%)]\tLoss: 0.047385\n",
      "Train Epoch: 15 [21760/50000 (43%)]\tLoss: 0.044546\n",
      "Train Epoch: 15 [22400/50000 (45%)]\tLoss: 0.042363\n",
      "Train Epoch: 15 [23040/50000 (46%)]\tLoss: 0.042280\n",
      "Train Epoch: 15 [23680/50000 (47%)]\tLoss: 0.042279\n",
      "Train Epoch: 15 [24320/50000 (49%)]\tLoss: 0.044086\n",
      "Train Epoch: 15 [24960/50000 (50%)]\tLoss: 0.042999\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.042539\n",
      "Train Epoch: 15 [26240/50000 (52%)]\tLoss: 0.045490\n",
      "Train Epoch: 15 [26880/50000 (54%)]\tLoss: 0.043391\n",
      "Train Epoch: 15 [27520/50000 (55%)]\tLoss: 0.042690\n",
      "Train Epoch: 15 [28160/50000 (56%)]\tLoss: 0.046831\n",
      "Train Epoch: 15 [28800/50000 (58%)]\tLoss: 0.046491\n",
      "Train Epoch: 15 [29440/50000 (59%)]\tLoss: 0.043465\n",
      "Train Epoch: 15 [30080/50000 (60%)]\tLoss: 0.044765\n",
      "Train Epoch: 15 [30720/50000 (61%)]\tLoss: 0.040741\n",
      "Train Epoch: 15 [31360/50000 (63%)]\tLoss: 0.041064\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.046414\n",
      "Train Epoch: 15 [32640/50000 (65%)]\tLoss: 0.042513\n",
      "Train Epoch: 15 [33280/50000 (66%)]\tLoss: 0.044210\n",
      "Train Epoch: 15 [33920/50000 (68%)]\tLoss: 0.045689\n",
      "Train Epoch: 15 [34560/50000 (69%)]\tLoss: 0.044910\n",
      "Train Epoch: 15 [35200/50000 (70%)]\tLoss: 0.046057\n",
      "Train Epoch: 15 [35840/50000 (72%)]\tLoss: 0.044526\n",
      "Train Epoch: 15 [36480/50000 (73%)]\tLoss: 0.042337\n",
      "Train Epoch: 15 [37120/50000 (74%)]\tLoss: 0.047671\n",
      "Train Epoch: 15 [37760/50000 (75%)]\tLoss: 0.046313\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.043788\n",
      "Train Epoch: 15 [39040/50000 (78%)]\tLoss: 0.043472\n",
      "Train Epoch: 15 [39680/50000 (79%)]\tLoss: 0.041840\n",
      "Train Epoch: 15 [40320/50000 (81%)]\tLoss: 0.040286\n",
      "Train Epoch: 15 [40960/50000 (82%)]\tLoss: 0.046529\n",
      "Train Epoch: 15 [41600/50000 (83%)]\tLoss: 0.044511\n",
      "Train Epoch: 15 [42240/50000 (84%)]\tLoss: 0.048318\n",
      "Train Epoch: 15 [42880/50000 (86%)]\tLoss: 0.041614\n",
      "Train Epoch: 15 [43520/50000 (87%)]\tLoss: 0.043126\n",
      "Train Epoch: 15 [44160/50000 (88%)]\tLoss: 0.043186\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.043943\n",
      "Train Epoch: 15 [45440/50000 (91%)]\tLoss: 0.041497\n",
      "Train Epoch: 15 [46080/50000 (92%)]\tLoss: 0.040368\n",
      "Train Epoch: 15 [46720/50000 (93%)]\tLoss: 0.044647\n",
      "Train Epoch: 15 [47360/50000 (95%)]\tLoss: 0.041010\n",
      "Train Epoch: 15 [48000/50000 (96%)]\tLoss: 0.042736\n",
      "Train Epoch: 15 [48640/50000 (97%)]\tLoss: 0.046660\n",
      "Train Epoch: 15 [49280/50000 (98%)]\tLoss: 0.045739\n",
      "Train Epoch: 15 [49920/50000 (100%)]\tLoss: 0.042177\n",
      "\n",
      "Test set: Avg. loss: 0.045895\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.045173\n",
      "Train Epoch: 16 [640/50000 (1%)]\tLoss: 0.042856\n",
      "Train Epoch: 16 [1280/50000 (3%)]\tLoss: 0.044134\n",
      "Train Epoch: 16 [1920/50000 (4%)]\tLoss: 0.042284\n",
      "Train Epoch: 16 [2560/50000 (5%)]\tLoss: 0.044749\n",
      "Train Epoch: 16 [3200/50000 (6%)]\tLoss: 0.043858\n",
      "Train Epoch: 16 [3840/50000 (8%)]\tLoss: 0.041604\n",
      "Train Epoch: 16 [4480/50000 (9%)]\tLoss: 0.039445\n",
      "Train Epoch: 16 [5120/50000 (10%)]\tLoss: 0.044427\n",
      "Train Epoch: 16 [5760/50000 (12%)]\tLoss: 0.044738\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.046776\n",
      "Train Epoch: 16 [7040/50000 (14%)]\tLoss: 0.046869\n",
      "Train Epoch: 16 [7680/50000 (15%)]\tLoss: 0.041699\n",
      "Train Epoch: 16 [8320/50000 (17%)]\tLoss: 0.043449\n",
      "Train Epoch: 16 [8960/50000 (18%)]\tLoss: 0.043815\n",
      "Train Epoch: 16 [9600/50000 (19%)]\tLoss: 0.040840\n",
      "Train Epoch: 16 [10240/50000 (20%)]\tLoss: 0.045718\n",
      "Train Epoch: 16 [10880/50000 (22%)]\tLoss: 0.043319\n",
      "Train Epoch: 16 [11520/50000 (23%)]\tLoss: 0.046085\n",
      "Train Epoch: 16 [12160/50000 (24%)]\tLoss: 0.044173\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.044289\n",
      "Train Epoch: 16 [13440/50000 (27%)]\tLoss: 0.042792\n",
      "Train Epoch: 16 [14080/50000 (28%)]\tLoss: 0.042319\n",
      "Train Epoch: 16 [14720/50000 (29%)]\tLoss: 0.041313\n",
      "Train Epoch: 16 [15360/50000 (31%)]\tLoss: 0.042371\n",
      "Train Epoch: 16 [16000/50000 (32%)]\tLoss: 0.041422\n",
      "Train Epoch: 16 [16640/50000 (33%)]\tLoss: 0.046404\n",
      "Train Epoch: 16 [17280/50000 (35%)]\tLoss: 0.041691\n",
      "Train Epoch: 16 [17920/50000 (36%)]\tLoss: 0.041495\n",
      "Train Epoch: 16 [18560/50000 (37%)]\tLoss: 0.045403\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.042473\n",
      "Train Epoch: 16 [19840/50000 (40%)]\tLoss: 0.047326\n",
      "Train Epoch: 16 [20480/50000 (41%)]\tLoss: 0.043146\n",
      "Train Epoch: 16 [21120/50000 (42%)]\tLoss: 0.042609\n",
      "Train Epoch: 16 [21760/50000 (43%)]\tLoss: 0.043025\n",
      "Train Epoch: 16 [22400/50000 (45%)]\tLoss: 0.043705\n",
      "Train Epoch: 16 [23040/50000 (46%)]\tLoss: 0.043841\n",
      "Train Epoch: 16 [23680/50000 (47%)]\tLoss: 0.041538\n",
      "Train Epoch: 16 [24320/50000 (49%)]\tLoss: 0.043284\n",
      "Train Epoch: 16 [24960/50000 (50%)]\tLoss: 0.038898\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.044587\n",
      "Train Epoch: 16 [26240/50000 (52%)]\tLoss: 0.041059\n",
      "Train Epoch: 16 [26880/50000 (54%)]\tLoss: 0.041725\n",
      "Train Epoch: 16 [27520/50000 (55%)]\tLoss: 0.044898\n",
      "Train Epoch: 16 [28160/50000 (56%)]\tLoss: 0.040040\n",
      "Train Epoch: 16 [28800/50000 (58%)]\tLoss: 0.041469\n",
      "Train Epoch: 16 [29440/50000 (59%)]\tLoss: 0.048358\n",
      "Train Epoch: 16 [30080/50000 (60%)]\tLoss: 0.046249\n",
      "Train Epoch: 16 [30720/50000 (61%)]\tLoss: 0.043049\n",
      "Train Epoch: 16 [31360/50000 (63%)]\tLoss: 0.040298\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.044835\n",
      "Train Epoch: 16 [32640/50000 (65%)]\tLoss: 0.041629\n",
      "Train Epoch: 16 [33280/50000 (66%)]\tLoss: 0.043850\n",
      "Train Epoch: 16 [33920/50000 (68%)]\tLoss: 0.043323\n",
      "Train Epoch: 16 [34560/50000 (69%)]\tLoss: 0.045394\n",
      "Train Epoch: 16 [35200/50000 (70%)]\tLoss: 0.043728\n",
      "Train Epoch: 16 [35840/50000 (72%)]\tLoss: 0.042439\n",
      "Train Epoch: 16 [36480/50000 (73%)]\tLoss: 0.041747\n",
      "Train Epoch: 16 [37120/50000 (74%)]\tLoss: 0.041350\n",
      "Train Epoch: 16 [37760/50000 (75%)]\tLoss: 0.041842\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.042572\n",
      "Train Epoch: 16 [39040/50000 (78%)]\tLoss: 0.045902\n",
      "Train Epoch: 16 [39680/50000 (79%)]\tLoss: 0.044346\n",
      "Train Epoch: 16 [40320/50000 (81%)]\tLoss: 0.041323\n",
      "Train Epoch: 16 [40960/50000 (82%)]\tLoss: 0.040665\n",
      "Train Epoch: 16 [41600/50000 (83%)]\tLoss: 0.039350\n",
      "Train Epoch: 16 [42240/50000 (84%)]\tLoss: 0.042110\n",
      "Train Epoch: 16 [42880/50000 (86%)]\tLoss: 0.040889\n",
      "Train Epoch: 16 [43520/50000 (87%)]\tLoss: 0.040732\n",
      "Train Epoch: 16 [44160/50000 (88%)]\tLoss: 0.041322\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.043168\n",
      "Train Epoch: 16 [45440/50000 (91%)]\tLoss: 0.039034\n",
      "Train Epoch: 16 [46080/50000 (92%)]\tLoss: 0.043119\n",
      "Train Epoch: 16 [46720/50000 (93%)]\tLoss: 0.042799\n",
      "Train Epoch: 16 [47360/50000 (95%)]\tLoss: 0.044841\n",
      "Train Epoch: 16 [48000/50000 (96%)]\tLoss: 0.042081\n",
      "Train Epoch: 16 [48640/50000 (97%)]\tLoss: 0.043539\n",
      "Train Epoch: 16 [49280/50000 (98%)]\tLoss: 0.043435\n",
      "Train Epoch: 16 [49920/50000 (100%)]\tLoss: 0.045372\n",
      "\n",
      "Test set: Avg. loss: 0.045504\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.039904\n",
      "Train Epoch: 17 [640/50000 (1%)]\tLoss: 0.041366\n",
      "Train Epoch: 17 [1280/50000 (3%)]\tLoss: 0.044398\n",
      "Train Epoch: 17 [1920/50000 (4%)]\tLoss: 0.041248\n",
      "Train Epoch: 17 [2560/50000 (5%)]\tLoss: 0.042947\n",
      "Train Epoch: 17 [3200/50000 (6%)]\tLoss: 0.040932\n",
      "Train Epoch: 17 [3840/50000 (8%)]\tLoss: 0.041336\n",
      "Train Epoch: 17 [4480/50000 (9%)]\tLoss: 0.040402\n",
      "Train Epoch: 17 [5120/50000 (10%)]\tLoss: 0.041176\n",
      "Train Epoch: 17 [5760/50000 (12%)]\tLoss: 0.041985\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.041416\n",
      "Train Epoch: 17 [7040/50000 (14%)]\tLoss: 0.043133\n",
      "Train Epoch: 17 [7680/50000 (15%)]\tLoss: 0.042419\n",
      "Train Epoch: 17 [8320/50000 (17%)]\tLoss: 0.041338\n",
      "Train Epoch: 17 [8960/50000 (18%)]\tLoss: 0.043421\n",
      "Train Epoch: 17 [9600/50000 (19%)]\tLoss: 0.044253\n",
      "Train Epoch: 17 [10240/50000 (20%)]\tLoss: 0.046332\n",
      "Train Epoch: 17 [10880/50000 (22%)]\tLoss: 0.040659\n",
      "Train Epoch: 17 [11520/50000 (23%)]\tLoss: 0.040758\n",
      "Train Epoch: 17 [12160/50000 (24%)]\tLoss: 0.039309\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.045322\n",
      "Train Epoch: 17 [13440/50000 (27%)]\tLoss: 0.043357\n",
      "Train Epoch: 17 [14080/50000 (28%)]\tLoss: 0.042542\n",
      "Train Epoch: 17 [14720/50000 (29%)]\tLoss: 0.041903\n",
      "Train Epoch: 17 [15360/50000 (31%)]\tLoss: 0.040211\n",
      "Train Epoch: 17 [16000/50000 (32%)]\tLoss: 0.041130\n",
      "Train Epoch: 17 [16640/50000 (33%)]\tLoss: 0.043819\n",
      "Train Epoch: 17 [17280/50000 (35%)]\tLoss: 0.043718\n",
      "Train Epoch: 17 [17920/50000 (36%)]\tLoss: 0.042413\n",
      "Train Epoch: 17 [18560/50000 (37%)]\tLoss: 0.039495\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.041478\n",
      "Train Epoch: 17 [19840/50000 (40%)]\tLoss: 0.041931\n",
      "Train Epoch: 17 [20480/50000 (41%)]\tLoss: 0.041715\n",
      "Train Epoch: 17 [21120/50000 (42%)]\tLoss: 0.044264\n",
      "Train Epoch: 17 [21760/50000 (43%)]\tLoss: 0.041347\n",
      "Train Epoch: 17 [22400/50000 (45%)]\tLoss: 0.043847\n",
      "Train Epoch: 17 [23040/50000 (46%)]\tLoss: 0.040512\n",
      "Train Epoch: 17 [23680/50000 (47%)]\tLoss: 0.040769\n",
      "Train Epoch: 17 [24320/50000 (49%)]\tLoss: 0.041837\n",
      "Train Epoch: 17 [24960/50000 (50%)]\tLoss: 0.041742\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.040478\n",
      "Train Epoch: 17 [26240/50000 (52%)]\tLoss: 0.043336\n",
      "Train Epoch: 17 [26880/50000 (54%)]\tLoss: 0.040531\n",
      "Train Epoch: 17 [27520/50000 (55%)]\tLoss: 0.042683\n",
      "Train Epoch: 17 [28160/50000 (56%)]\tLoss: 0.042201\n",
      "Train Epoch: 17 [28800/50000 (58%)]\tLoss: 0.044043\n",
      "Train Epoch: 17 [29440/50000 (59%)]\tLoss: 0.046154\n",
      "Train Epoch: 17 [30080/50000 (60%)]\tLoss: 0.041734\n",
      "Train Epoch: 17 [30720/50000 (61%)]\tLoss: 0.044747\n",
      "Train Epoch: 17 [31360/50000 (63%)]\tLoss: 0.042346\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.040735\n",
      "Train Epoch: 17 [32640/50000 (65%)]\tLoss: 0.044099\n",
      "Train Epoch: 17 [33280/50000 (66%)]\tLoss: 0.041131\n",
      "Train Epoch: 17 [33920/50000 (68%)]\tLoss: 0.040424\n",
      "Train Epoch: 17 [34560/50000 (69%)]\tLoss: 0.046132\n",
      "Train Epoch: 17 [35200/50000 (70%)]\tLoss: 0.043608\n",
      "Train Epoch: 17 [35840/50000 (72%)]\tLoss: 0.044833\n",
      "Train Epoch: 17 [36480/50000 (73%)]\tLoss: 0.043134\n",
      "Train Epoch: 17 [37120/50000 (74%)]\tLoss: 0.039419\n",
      "Train Epoch: 17 [37760/50000 (75%)]\tLoss: 0.041304\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.041882\n",
      "Train Epoch: 17 [39040/50000 (78%)]\tLoss: 0.041484\n",
      "Train Epoch: 17 [39680/50000 (79%)]\tLoss: 0.041445\n",
      "Train Epoch: 17 [40320/50000 (81%)]\tLoss: 0.045370\n",
      "Train Epoch: 17 [40960/50000 (82%)]\tLoss: 0.041542\n",
      "Train Epoch: 17 [41600/50000 (83%)]\tLoss: 0.044835\n",
      "Train Epoch: 17 [42240/50000 (84%)]\tLoss: 0.044750\n",
      "Train Epoch: 17 [42880/50000 (86%)]\tLoss: 0.044014\n",
      "Train Epoch: 17 [43520/50000 (87%)]\tLoss: 0.041023\n",
      "Train Epoch: 17 [44160/50000 (88%)]\tLoss: 0.040500\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.042288\n",
      "Train Epoch: 17 [45440/50000 (91%)]\tLoss: 0.042314\n",
      "Train Epoch: 17 [46080/50000 (92%)]\tLoss: 0.038612\n",
      "Train Epoch: 17 [46720/50000 (93%)]\tLoss: 0.040581\n",
      "Train Epoch: 17 [47360/50000 (95%)]\tLoss: 0.042484\n",
      "Train Epoch: 17 [48000/50000 (96%)]\tLoss: 0.043255\n",
      "Train Epoch: 17 [48640/50000 (97%)]\tLoss: 0.048844\n",
      "Train Epoch: 17 [49280/50000 (98%)]\tLoss: 0.044171\n",
      "Train Epoch: 17 [49920/50000 (100%)]\tLoss: 0.040175\n",
      "\n",
      "Test set: Avg. loss: 0.045005\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.038957\n",
      "Train Epoch: 18 [640/50000 (1%)]\tLoss: 0.042614\n",
      "Train Epoch: 18 [1280/50000 (3%)]\tLoss: 0.043436\n",
      "Train Epoch: 18 [1920/50000 (4%)]\tLoss: 0.042722\n",
      "Train Epoch: 18 [2560/50000 (5%)]\tLoss: 0.039707\n",
      "Train Epoch: 18 [3200/50000 (6%)]\tLoss: 0.043937\n",
      "Train Epoch: 18 [3840/50000 (8%)]\tLoss: 0.043810\n",
      "Train Epoch: 18 [4480/50000 (9%)]\tLoss: 0.044215\n",
      "Train Epoch: 18 [5120/50000 (10%)]\tLoss: 0.042306\n",
      "Train Epoch: 18 [5760/50000 (12%)]\tLoss: 0.038794\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.041772\n",
      "Train Epoch: 18 [7040/50000 (14%)]\tLoss: 0.043025\n",
      "Train Epoch: 18 [7680/50000 (15%)]\tLoss: 0.039309\n",
      "Train Epoch: 18 [8320/50000 (17%)]\tLoss: 0.043974\n",
      "Train Epoch: 18 [8960/50000 (18%)]\tLoss: 0.040986\n",
      "Train Epoch: 18 [9600/50000 (19%)]\tLoss: 0.042818\n",
      "Train Epoch: 18 [10240/50000 (20%)]\tLoss: 0.040277\n",
      "Train Epoch: 18 [10880/50000 (22%)]\tLoss: 0.040565\n",
      "Train Epoch: 18 [11520/50000 (23%)]\tLoss: 0.039769\n",
      "Train Epoch: 18 [12160/50000 (24%)]\tLoss: 0.041662\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.040219\n",
      "Train Epoch: 18 [13440/50000 (27%)]\tLoss: 0.041217\n",
      "Train Epoch: 18 [14080/50000 (28%)]\tLoss: 0.040912\n",
      "Train Epoch: 18 [14720/50000 (29%)]\tLoss: 0.041416\n",
      "Train Epoch: 18 [15360/50000 (31%)]\tLoss: 0.042300\n",
      "Train Epoch: 18 [16000/50000 (32%)]\tLoss: 0.045285\n",
      "Train Epoch: 18 [16640/50000 (33%)]\tLoss: 0.042122\n",
      "Train Epoch: 18 [17280/50000 (35%)]\tLoss: 0.041228\n",
      "Train Epoch: 18 [17920/50000 (36%)]\tLoss: 0.041976\n",
      "Train Epoch: 18 [18560/50000 (37%)]\tLoss: 0.043608\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.041507\n",
      "Train Epoch: 18 [19840/50000 (40%)]\tLoss: 0.039392\n",
      "Train Epoch: 18 [20480/50000 (41%)]\tLoss: 0.043472\n",
      "Train Epoch: 18 [21120/50000 (42%)]\tLoss: 0.037510\n",
      "Train Epoch: 18 [21760/50000 (43%)]\tLoss: 0.041771\n",
      "Train Epoch: 18 [22400/50000 (45%)]\tLoss: 0.040953\n",
      "Train Epoch: 18 [23040/50000 (46%)]\tLoss: 0.040710\n",
      "Train Epoch: 18 [23680/50000 (47%)]\tLoss: 0.043971\n",
      "Train Epoch: 18 [24320/50000 (49%)]\tLoss: 0.043357\n",
      "Train Epoch: 18 [24960/50000 (50%)]\tLoss: 0.044643\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.046580\n",
      "Train Epoch: 18 [26240/50000 (52%)]\tLoss: 0.037927\n",
      "Train Epoch: 18 [26880/50000 (54%)]\tLoss: 0.041921\n",
      "Train Epoch: 18 [27520/50000 (55%)]\tLoss: 0.042422\n",
      "Train Epoch: 18 [28160/50000 (56%)]\tLoss: 0.045173\n",
      "Train Epoch: 18 [28800/50000 (58%)]\tLoss: 0.041827\n",
      "Train Epoch: 18 [29440/50000 (59%)]\tLoss: 0.046392\n",
      "Train Epoch: 18 [30080/50000 (60%)]\tLoss: 0.040679\n",
      "Train Epoch: 18 [30720/50000 (61%)]\tLoss: 0.042715\n",
      "Train Epoch: 18 [31360/50000 (63%)]\tLoss: 0.042278\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.042441\n",
      "Train Epoch: 18 [32640/50000 (65%)]\tLoss: 0.042308\n",
      "Train Epoch: 18 [33280/50000 (66%)]\tLoss: 0.042089\n",
      "Train Epoch: 18 [33920/50000 (68%)]\tLoss: 0.039179\n",
      "Train Epoch: 18 [34560/50000 (69%)]\tLoss: 0.040582\n",
      "Train Epoch: 18 [35200/50000 (70%)]\tLoss: 0.041656\n",
      "Train Epoch: 18 [35840/50000 (72%)]\tLoss: 0.041721\n",
      "Train Epoch: 18 [36480/50000 (73%)]\tLoss: 0.039630\n",
      "Train Epoch: 18 [37120/50000 (74%)]\tLoss: 0.042744\n",
      "Train Epoch: 18 [37760/50000 (75%)]\tLoss: 0.040482\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.041858\n",
      "Train Epoch: 18 [39040/50000 (78%)]\tLoss: 0.044855\n",
      "Train Epoch: 18 [39680/50000 (79%)]\tLoss: 0.039244\n",
      "Train Epoch: 18 [40320/50000 (81%)]\tLoss: 0.042478\n",
      "Train Epoch: 18 [40960/50000 (82%)]\tLoss: 0.040481\n",
      "Train Epoch: 18 [41600/50000 (83%)]\tLoss: 0.041159\n",
      "Train Epoch: 18 [42240/50000 (84%)]\tLoss: 0.043074\n",
      "Train Epoch: 18 [42880/50000 (86%)]\tLoss: 0.040971\n",
      "Train Epoch: 18 [43520/50000 (87%)]\tLoss: 0.043866\n",
      "Train Epoch: 18 [44160/50000 (88%)]\tLoss: 0.041194\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.042933\n",
      "Train Epoch: 18 [45440/50000 (91%)]\tLoss: 0.041831\n",
      "Train Epoch: 18 [46080/50000 (92%)]\tLoss: 0.041584\n",
      "Train Epoch: 18 [46720/50000 (93%)]\tLoss: 0.042643\n",
      "Train Epoch: 18 [47360/50000 (95%)]\tLoss: 0.042829\n",
      "Train Epoch: 18 [48000/50000 (96%)]\tLoss: 0.042737\n",
      "Train Epoch: 18 [48640/50000 (97%)]\tLoss: 0.041506\n",
      "Train Epoch: 18 [49280/50000 (98%)]\tLoss: 0.044736\n",
      "Train Epoch: 18 [49920/50000 (100%)]\tLoss: 0.043268\n",
      "\n",
      "Test set: Avg. loss: 0.044574\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.042368\n",
      "Train Epoch: 19 [640/50000 (1%)]\tLoss: 0.041330\n",
      "Train Epoch: 19 [1280/50000 (3%)]\tLoss: 0.040164\n",
      "Train Epoch: 19 [1920/50000 (4%)]\tLoss: 0.039270\n",
      "Train Epoch: 19 [2560/50000 (5%)]\tLoss: 0.043246\n",
      "Train Epoch: 19 [3200/50000 (6%)]\tLoss: 0.037412\n",
      "Train Epoch: 19 [3840/50000 (8%)]\tLoss: 0.041979\n",
      "Train Epoch: 19 [4480/50000 (9%)]\tLoss: 0.039224\n",
      "Train Epoch: 19 [5120/50000 (10%)]\tLoss: 0.043605\n",
      "Train Epoch: 19 [5760/50000 (12%)]\tLoss: 0.039062\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.045478\n",
      "Train Epoch: 19 [7040/50000 (14%)]\tLoss: 0.044154\n",
      "Train Epoch: 19 [7680/50000 (15%)]\tLoss: 0.039511\n",
      "Train Epoch: 19 [8320/50000 (17%)]\tLoss: 0.041012\n",
      "Train Epoch: 19 [8960/50000 (18%)]\tLoss: 0.043000\n",
      "Train Epoch: 19 [9600/50000 (19%)]\tLoss: 0.043339\n",
      "Train Epoch: 19 [10240/50000 (20%)]\tLoss: 0.041111\n",
      "Train Epoch: 19 [10880/50000 (22%)]\tLoss: 0.045395\n",
      "Train Epoch: 19 [11520/50000 (23%)]\tLoss: 0.041253\n",
      "Train Epoch: 19 [12160/50000 (24%)]\tLoss: 0.040954\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.042084\n",
      "Train Epoch: 19 [13440/50000 (27%)]\tLoss: 0.044502\n",
      "Train Epoch: 19 [14080/50000 (28%)]\tLoss: 0.044187\n",
      "Train Epoch: 19 [14720/50000 (29%)]\tLoss: 0.039493\n",
      "Train Epoch: 19 [15360/50000 (31%)]\tLoss: 0.039036\n",
      "Train Epoch: 19 [16000/50000 (32%)]\tLoss: 0.044002\n",
      "Train Epoch: 19 [16640/50000 (33%)]\tLoss: 0.042669\n",
      "Train Epoch: 19 [17280/50000 (35%)]\tLoss: 0.038735\n",
      "Train Epoch: 19 [17920/50000 (36%)]\tLoss: 0.040868\n",
      "Train Epoch: 19 [18560/50000 (37%)]\tLoss: 0.042412\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.042087\n",
      "Train Epoch: 19 [19840/50000 (40%)]\tLoss: 0.037865\n",
      "Train Epoch: 19 [20480/50000 (41%)]\tLoss: 0.041799\n",
      "Train Epoch: 19 [21120/50000 (42%)]\tLoss: 0.040471\n",
      "Train Epoch: 19 [21760/50000 (43%)]\tLoss: 0.043217\n",
      "Train Epoch: 19 [22400/50000 (45%)]\tLoss: 0.044065\n",
      "Train Epoch: 19 [23040/50000 (46%)]\tLoss: 0.040071\n",
      "Train Epoch: 19 [23680/50000 (47%)]\tLoss: 0.040334\n",
      "Train Epoch: 19 [24320/50000 (49%)]\tLoss: 0.042305\n",
      "Train Epoch: 19 [24960/50000 (50%)]\tLoss: 0.039088\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.038184\n",
      "Train Epoch: 19 [26240/50000 (52%)]\tLoss: 0.043982\n",
      "Train Epoch: 19 [26880/50000 (54%)]\tLoss: 0.045285\n",
      "Train Epoch: 19 [27520/50000 (55%)]\tLoss: 0.043184\n",
      "Train Epoch: 19 [28160/50000 (56%)]\tLoss: 0.041631\n",
      "Train Epoch: 19 [28800/50000 (58%)]\tLoss: 0.039832\n",
      "Train Epoch: 19 [29440/50000 (59%)]\tLoss: 0.040703\n",
      "Train Epoch: 19 [30080/50000 (60%)]\tLoss: 0.039587\n",
      "Train Epoch: 19 [30720/50000 (61%)]\tLoss: 0.039280\n",
      "Train Epoch: 19 [31360/50000 (63%)]\tLoss: 0.042710\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.038088\n",
      "Train Epoch: 19 [32640/50000 (65%)]\tLoss: 0.040521\n",
      "Train Epoch: 19 [33280/50000 (66%)]\tLoss: 0.041869\n",
      "Train Epoch: 19 [33920/50000 (68%)]\tLoss: 0.040661\n",
      "Train Epoch: 19 [34560/50000 (69%)]\tLoss: 0.039814\n",
      "Train Epoch: 19 [35200/50000 (70%)]\tLoss: 0.039193\n",
      "Train Epoch: 19 [35840/50000 (72%)]\tLoss: 0.041728\n",
      "Train Epoch: 19 [36480/50000 (73%)]\tLoss: 0.040715\n",
      "Train Epoch: 19 [37120/50000 (74%)]\tLoss: 0.039135\n",
      "Train Epoch: 19 [37760/50000 (75%)]\tLoss: 0.040106\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.042724\n",
      "Train Epoch: 19 [39040/50000 (78%)]\tLoss: 0.045558\n",
      "Train Epoch: 19 [39680/50000 (79%)]\tLoss: 0.039962\n",
      "Train Epoch: 19 [40320/50000 (81%)]\tLoss: 0.039853\n",
      "Train Epoch: 19 [40960/50000 (82%)]\tLoss: 0.042744\n",
      "Train Epoch: 19 [41600/50000 (83%)]\tLoss: 0.040080\n",
      "Train Epoch: 19 [42240/50000 (84%)]\tLoss: 0.040219\n",
      "Train Epoch: 19 [42880/50000 (86%)]\tLoss: 0.040691\n",
      "Train Epoch: 19 [43520/50000 (87%)]\tLoss: 0.043909\n",
      "Train Epoch: 19 [44160/50000 (88%)]\tLoss: 0.040329\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.040351\n",
      "Train Epoch: 19 [45440/50000 (91%)]\tLoss: 0.044082\n",
      "Train Epoch: 19 [46080/50000 (92%)]\tLoss: 0.039032\n",
      "Train Epoch: 19 [46720/50000 (93%)]\tLoss: 0.039729\n",
      "Train Epoch: 19 [47360/50000 (95%)]\tLoss: 0.043739\n",
      "Train Epoch: 19 [48000/50000 (96%)]\tLoss: 0.042106\n",
      "Train Epoch: 19 [48640/50000 (97%)]\tLoss: 0.041596\n",
      "Train Epoch: 19 [49280/50000 (98%)]\tLoss: 0.038907\n",
      "Train Epoch: 19 [49920/50000 (100%)]\tLoss: 0.043313\n",
      "\n",
      "Test set: Avg. loss: 0.044173\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.043310\n",
      "Train Epoch: 20 [640/50000 (1%)]\tLoss: 0.040708\n",
      "Train Epoch: 20 [1280/50000 (3%)]\tLoss: 0.038399\n",
      "Train Epoch: 20 [1920/50000 (4%)]\tLoss: 0.042010\n",
      "Train Epoch: 20 [2560/50000 (5%)]\tLoss: 0.042306\n",
      "Train Epoch: 20 [3200/50000 (6%)]\tLoss: 0.039499\n",
      "Train Epoch: 20 [3840/50000 (8%)]\tLoss: 0.042934\n",
      "Train Epoch: 20 [4480/50000 (9%)]\tLoss: 0.042380\n",
      "Train Epoch: 20 [5120/50000 (10%)]\tLoss: 0.038104\n",
      "Train Epoch: 20 [5760/50000 (12%)]\tLoss: 0.040667\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.038950\n",
      "Train Epoch: 20 [7040/50000 (14%)]\tLoss: 0.040734\n",
      "Train Epoch: 20 [7680/50000 (15%)]\tLoss: 0.042237\n",
      "Train Epoch: 20 [8320/50000 (17%)]\tLoss: 0.039602\n",
      "Train Epoch: 20 [8960/50000 (18%)]\tLoss: 0.048297\n",
      "Train Epoch: 20 [9600/50000 (19%)]\tLoss: 0.040414\n",
      "Train Epoch: 20 [10240/50000 (20%)]\tLoss: 0.041650\n",
      "Train Epoch: 20 [10880/50000 (22%)]\tLoss: 0.039203\n",
      "Train Epoch: 20 [11520/50000 (23%)]\tLoss: 0.041449\n",
      "Train Epoch: 20 [12160/50000 (24%)]\tLoss: 0.044209\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.040732\n",
      "Train Epoch: 20 [13440/50000 (27%)]\tLoss: 0.039473\n",
      "Train Epoch: 20 [14080/50000 (28%)]\tLoss: 0.040534\n",
      "Train Epoch: 20 [14720/50000 (29%)]\tLoss: 0.041993\n",
      "Train Epoch: 20 [15360/50000 (31%)]\tLoss: 0.039983\n",
      "Train Epoch: 20 [16000/50000 (32%)]\tLoss: 0.039302\n",
      "Train Epoch: 20 [16640/50000 (33%)]\tLoss: 0.040586\n",
      "Train Epoch: 20 [17280/50000 (35%)]\tLoss: 0.043161\n",
      "Train Epoch: 20 [17920/50000 (36%)]\tLoss: 0.040659\n",
      "Train Epoch: 20 [18560/50000 (37%)]\tLoss: 0.036551\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.039380\n",
      "Train Epoch: 20 [19840/50000 (40%)]\tLoss: 0.040560\n",
      "Train Epoch: 20 [20480/50000 (41%)]\tLoss: 0.037712\n",
      "Train Epoch: 20 [21120/50000 (42%)]\tLoss: 0.038545\n",
      "Train Epoch: 20 [21760/50000 (43%)]\tLoss: 0.038974\n",
      "Train Epoch: 20 [22400/50000 (45%)]\tLoss: 0.042302\n",
      "Train Epoch: 20 [23040/50000 (46%)]\tLoss: 0.042504\n",
      "Train Epoch: 20 [23680/50000 (47%)]\tLoss: 0.039036\n",
      "Train Epoch: 20 [24320/50000 (49%)]\tLoss: 0.036346\n",
      "Train Epoch: 20 [24960/50000 (50%)]\tLoss: 0.042611\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.039946\n",
      "Train Epoch: 20 [26240/50000 (52%)]\tLoss: 0.043427\n",
      "Train Epoch: 20 [26880/50000 (54%)]\tLoss: 0.040205\n",
      "Train Epoch: 20 [27520/50000 (55%)]\tLoss: 0.040475\n",
      "Train Epoch: 20 [28160/50000 (56%)]\tLoss: 0.039515\n",
      "Train Epoch: 20 [28800/50000 (58%)]\tLoss: 0.043025\n",
      "Train Epoch: 20 [29440/50000 (59%)]\tLoss: 0.041567\n",
      "Train Epoch: 20 [30080/50000 (60%)]\tLoss: 0.042231\n",
      "Train Epoch: 20 [30720/50000 (61%)]\tLoss: 0.043878\n",
      "Train Epoch: 20 [31360/50000 (63%)]\tLoss: 0.038489\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.040620\n",
      "Train Epoch: 20 [32640/50000 (65%)]\tLoss: 0.042239\n",
      "Train Epoch: 20 [33280/50000 (66%)]\tLoss: 0.041356\n",
      "Train Epoch: 20 [33920/50000 (68%)]\tLoss: 0.037398\n",
      "Train Epoch: 20 [34560/50000 (69%)]\tLoss: 0.042146\n",
      "Train Epoch: 20 [35200/50000 (70%)]\tLoss: 0.039615\n",
      "Train Epoch: 20 [35840/50000 (72%)]\tLoss: 0.039418\n",
      "Train Epoch: 20 [36480/50000 (73%)]\tLoss: 0.042540\n",
      "Train Epoch: 20 [37120/50000 (74%)]\tLoss: 0.043508\n",
      "Train Epoch: 20 [37760/50000 (75%)]\tLoss: 0.040343\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.040482\n",
      "Train Epoch: 20 [39040/50000 (78%)]\tLoss: 0.038712\n",
      "Train Epoch: 20 [39680/50000 (79%)]\tLoss: 0.041038\n",
      "Train Epoch: 20 [40320/50000 (81%)]\tLoss: 0.040039\n",
      "Train Epoch: 20 [40960/50000 (82%)]\tLoss: 0.042174\n",
      "Train Epoch: 20 [41600/50000 (83%)]\tLoss: 0.041490\n",
      "Train Epoch: 20 [42240/50000 (84%)]\tLoss: 0.041621\n",
      "Train Epoch: 20 [42880/50000 (86%)]\tLoss: 0.037906\n",
      "Train Epoch: 20 [43520/50000 (87%)]\tLoss: 0.039262\n",
      "Train Epoch: 20 [44160/50000 (88%)]\tLoss: 0.038028\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.044187\n",
      "Train Epoch: 20 [45440/50000 (91%)]\tLoss: 0.045727\n"
     ]
    }
   ],
   "source": [
    "model_name = \"crypto_cfnet1\"\n",
    "test(model1, test_loader)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch, model1, optimizer1, train_loader)\n",
    "    test(model1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = \"figures\\cryptography\\\\reconstructed_160D.png\"\n",
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "reconstructed_example_data = model1(example_data.to(torch.device(\"cuda:0\"))).cpu().detach().numpy()\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(np.transpose(reconstructed_example_data[i]/2+0.5, [1,2,0]))\n",
    "    plt.title(\"Ground Truth: {}\".format(classes[example_targets[i]]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "#plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
