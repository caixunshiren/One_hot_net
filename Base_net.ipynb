{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size_train = 64\n",
    "batch_size_test = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAELCAYAAAARNxsIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdnklEQVR4nO3de5CUxbnH8V+DXMUAggiI3I6JFxQ4gGUwXohlFMPFEpSjR8UkAh4loSyjaHJMUOPxAhqEoxhRFDEQvGtAUQO6WGjCUYwYSQVU5C4gIooILrp9/pjhtfuFmZ2Z7dl5Z/l+qraqH/q99O528ezb3dOvsdYKAIAQ6pW6AQCAuoOkAgAIhqQCAAiGpAIACIakAgAIhqQCAAimTicVY0xnY4w1xhxQgnuvMsacXtv3RRj0HRRqf+87NU4qxpjzjTGLjTE7jDGb0+UrjDEmRAOLxRjzhfNVZYzZ6cQX5nmt6caYmwO37xfGmA+NMZ8bY940xpwU8vpJQN8J33dMyn8bY9ak+85sY8x3Ql0/Keg7Rek7/dJtctt4Sb7XqVFSMcb8UtIkSRMktZV0qKT/kvQDSQ0znFO/JvcMxVrbbM+XpDWSBjn/NnPPcSX6a+MESbdJOldSc0nTJD2dlJ9dCPSdohku6WKlfo7tJTWR9L8laEfR0HeKaoPbRmvtw3lfwVpb0JdS/9ntkDS0muOmS7pX0vPp40+XdLSkCknbJC2TNNg5vkLSCCf+iaRFTmyV6kDvSfpU0j2STLquvqQ7JG2RtFLS6PTxB1TTxlWSTk+X+0laJ+laSRslPRJvg9OOIySNkrRbUqWkLyTNca55taR3JH0m6VFJjXP82f6HpP9z4gPT92tX6O8rSV/0naL2nSckXePEJ0raJalpqX/v9J3E951+ktbV9HdUkyeVvpIaSXo2h2P/U9L/SDpI0mJJcyS9JKmNpF9ImmmMOTKPew+UdLykHpKGSToz/e8j03X/LqmPUn/pF6KtpIMldVLql5eRtXaqpJmSxttUZh/kVA+T1F9SF0ndleokkiRjzLYsQ1rzJNU3xpyQ/gvrZ5LeVqqz1QX0HRWt75j0lxs3kvTd/L6NxKLvqGh9R5LaGGM2pYfeJxpjDsz3m6hJUmktaYu19us9/2CMeT3d6J3GmFOcY5+11r5mra2S1FNSM0m3WWsrrbUvS5or6YI87n2btXabtXaNpFfS15RSP8y7rLVrrbVbJd1a4PdWJWmctfYra+3OAq8hSZOttRvSbZnjtFPW2hbW2kUZztsu6UlJiyR9JWmcpFE2/edEHUDfqV6hfWeepBHpyeLmSv3lK0lNa9CWJKHvVK/QvvOv9LHtJJ0mqbek3+d785oklU8ktXbH/qy1J1prW6Tr3GuvdcrtJa1N/6L3WC3psDzu7f7F/qVSnSW6duy6hfjYWrurwHNdmdpZnRFKPZ10U2qM+CJJc40x7QO0KQnoO9UrtO88KOlPSg3nLFPqPz8pNbRSF9B3qldQ37HWbrTW/tNaW2Wt/VDSWBXw1FWTpPJXpf6KPjuHY92/sDdIOtwY4967o6T16fIO+X9Vtc2jTR9JOjx23ULEnwi8Nhlj4m0K/QTRQ6kx0hXpX/ALSn1vJwa+T6nQdzIfXyPp/jLOWtvZWttBqcSyXt/+jModfSfz8aFZ+UOpOSk4qVhrt0m6UdIUY8y5xphmxph6xpieSk0sZ7JYqR/WWGNMA2NMP0mDJM1O178taYgxpqkx5ghJl+bRrMckjTHGdDDGtJR0XR7nZrNUUjdjTE9jTGNJN8TqN0nqGuhekvSGpAHGmK7pJaI/kvQ9Se8GvEfJ0Hc8QfuOMeZgY8y/pfvNMUoNX9wU+wu9bNF3PKH7Tj9jTMd03zlcqRWoucxdeWq0pNhaO17SVUo9Jm1W6pu8T6lx3NcznFMpabCks5RaLTFF0nBr7b/Sh0xUakXDJkkPKzUZlav7Jb2o1C/jLUlP5fcd7Zu1doWkmyTNV2r1R3xMcpqkY9Ljus/kcs30GvCTM1TPUKqzV0j6XNJkSZc5P6OyR9+JhO47rfXtiqd5kh5MT+rWGfSdSOi+00upJ8EdSv0c35U0Jt9271kSBwBAjdXpbVoAALWLpAIACIakAgAIhqQCAAiGpAIACCavnTCNMSwVSyBrbdK3+6bfJNMWa+0hpW5ENvSdxMrYd3hSAfZfhW4nAmTsOyQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDAkFQBAMHntUlxuGjZsGJU7dOiQ9dgxY8ZEZWuzb4x67733RuULL7zQq7v++uuj8o4dO7y673znO1mvCwDljicVAEAwJBUAQDCmuqEe7+CEvzDnhz/8oRe7Q1Gnnnpq1nON+fY9V/n8TLL55ptvvHjgwIFe/Je//CXIfXhJFwq0xFrbp9SNyIa+k1gZ+w5PKgCAYEgqAIBgSCoAgGDKeknxWWed5cXPPPOMF9evX78WW7O3yspKL37zzTdL1BJk06RJEy9257569+7t1Q0dOtSLjzjiiKj8wAMPeHU33XSTF69bty4qh5q3w/6nUaNGXtyyZcucz929e3dU/uSTT4K1ycWTCgAgGJIKACCYxC8prlfPz3vXXHNNVB43bpxX536CPi4+FFVRUeHFzz33XFR+6KGHvLpTTjnFi91htgMOyDyC+Oc//9mLhwwZkvHYmmBJcX46d+7sxbNmzfLiE044oSj3/elPfxqVZ8yYUZR75IklxYG5w6G//e1vvbpVq1Z58R/+8Ieo/OMf/9iri38Ewv1/ul27dl7daaedlrE97kclJOnTTz+Nyvfcc49X9+STT3rxP//5z6jsDpulsaQYAFB8JBUAQDAkFQBAMImfU+nRo4cXL1myJOdzd+7cGZVHjRrl1f3pT3/KeF7z5s29OL4UuEuXLjndPz72+fHHH+d0Xr6YU6neSSedFJXnzZvn1TVt2tSL16xZE5Xj82v/+Mc/Mt6je/fuXuzOoUh+fzj77LO9uhdeeCHjdYuIOZUacud4JemKK66Iyh07dsx67urVq6Nyp06dvLr4XEihS9Brcp1XX301Kse3wBJzKgCA2kBSAQAEQ1IBAAST+G1annjiiZyPdedQJKlv375R+d133816brNmzaLyH//4R68u1zkUSbr77ruj8rZt23I+D2G1bt3ai90tU+JzKB988IEXX3vttVH56aefzvme8WMffPDBjPfJp08hOR5//HEvHjx4sBc3aNAgKm/dutWri///FJ9Hyea1116Lyh9++KFXN3369Kicz9Yr8fufe+65OZ+bDU8qAIBgSCoAgGASP/x16KGH5nzs4sWLvTjbkJf7mCr5Szzjux/nc093ieE+tjZALenTx1/tmO3Nn2eccYYXx7fTKNTatWu9eNmyZUGui+Jq06aNF//mN7+JyvHhrvg2TQsXLtznedLev/+RI0dG5Xifc68jSZ999llU3rVrV6am5+Wdd97x4jlz5gS5Lk8qAIBgSCoAgGBIKgCAYBI/pxJfIhdfDupylwVL0sEHHxyV48v73O0UJOn3v/99VK5uKwN3/PPiiy/26phHKT/F2j4nzn3z49ixY706t38++uijtdIepMTfEBvfXmf06NEZz3VfmSFJgwYNyvm+48ePz/nYcsKTCgAgGJIKACAYkgoAIJjEb31/7LHHevHzzz8fldu3b5/1XHdrgzvvvNOru/766724d+/eUbm6n8mFF14YlZMw/s3W93uLj5O/8cYbUTn+OoXt27d78YABA/Z5XnWOO+44L46/TnbgwIEZz33rrbei8vHHH5/zPWuIre+19/8xS5cuzfncX/3qV1784osvRuX4K4KbNGnixe7re91X90plMTfL1vcAgOIjqQAAgkn88Ffc8OHDo/Ktt97q1eWzpUuc+4a0+M/k17/+tRffcccdUbmqqqrge4bC8Ff1jjrqqKj80ksveXWHHXZYbTfHG/qQ/C09li9fXlvNYPhL0oQJE7z4qquuKvha2f4fySY+PB9fcp5ADH8BAIqPpAIACIakAgAIpuzmVFxHHnmkF8+fP9+Lq1ty7KpX79v8unr1aq/OfYOkJH300Uc5X7c2MKeSH3d+Rdr795vPmPpBBx0UlQ8//PCsx7pbjZ9//vleXS3Oo7iYU9He27I88MADBV8r/tZY1zHHHOPFXbt2jcotWrTw6uJb35922mkFt6lImFMBABQfSQUAEAxJBQAQTFnPqcRNmTLFi0eNGpXzudnWl8fHNy+77LKo/P777+fTxKJgTqV0pk+fHpXjr0HYsGGDF3fp0iUqf/3110VtV46YU9HeW/q0bt264Gtt2rQpY92BBx7oxRdddFFUjv/ftXnzZi9u165dwW0qEuZUAADFR1IBAAST+Dc/ZnPWWWd58aWXXlqU+5x66qle/Oqrr0Zl942Rkr+FC+qeVq1aeXG2HYUfe+wxL07IkBdivvnmGy/ONoRVEzt27PBid8jdLe8rLic8qQAAgiGpAACCIakAAIIpuzkVd2uWe+65x6uLLw10bdu2zYtHjx7txe48SfytkCNGjPDiNm3aROVbbrnFq6usrIzKkydPztgelKfzzjvPi+NbvrimTZtW7OagjGV722x8SXE54UkFABAMSQUAEAxJBQAQTOLnVOLb28+bNy8qd+zYMeu5O3fujMpnnnmmV7dkyZKM58XnW+bOnevF7qtgGzZs6NVdeeWVUdndwkOSPv/886ztRfLFPxvlin8upUTb2SMwd9uWXr16eXWrVq3y4hUrVuR0HSn7dvYzZszIo4XJwpMKACAYkgoAIJjED3/dfPPNXpxtyCu+DcbIkSOjcrbhrupke6SNc9vXqFGjgu+JZIgvGR4wYEDGY93hVmnv7T9QHs455xwvdrde6ty5s1f3/PPPe/GgQYMyXjc+dBa/luuNN96oppXJxZMKACAYkgoAIBiSCgAgmMTNqfTp479MbODAgTmfu3jxYi+ePXt2VG7SpIlXF9/Sxd2apUePHl5d3759vTi+jNjlLiv95JNPqmkxkq5ePf/vrnLekhz7dsMNN3jxNddc48WNGzeOytddd51Xl8/S38svvzxjXXwO5c0338z5uknDkwoAIBiSCgAgmMQNf8V3dm3QoEHO555wwglePHXq1Kgc/yR0u3btvNgd1ojvGJpN/LHV/UR9VVVVztcBUBrx4a74UPnChQuj8l133eXV7d6924vdYfWjjz7aq+vZs6cXu//nvPDCC15d/C2R5YQnFQBAMCQVAEAwJBUAQDCJm1NZuXKlF3fr1i3ncw84wP92fvaznwVpU0VFhRe/9NJLUfnhhx/26sr5jW3A/ujGG2/04ltvvdWLTznllKh89tlne3XvvfeeF/fv3z8qx98KG7do0aKofNttt+XW2DLAkwoAIBiSCgAgGJIKACCYxM2pDB8+3IvjW0vHt0zJ1VNPPeXF69at82L3rYzxNzZu2LDBiysrKwtqA4DkmTRpkhd/97vf9WJ3bvbRRx/Nei13W5/qPqf2yiuvROVdu3ZV285ywZMKACAYkgoAIJjEDX9t377di08++eQStQTIzzvvvFPqJqAAX331lRf/7ne/82J3V/L4ruktWrTwYneLp9dee82rmzBhghfPnz8/77aWA55UAADBkFQAAMGQVAAAwSRuTgVIkvjbO2fOnJnx2FmzZhW7OagFa9as8eJLLrkkKrdq1cqri28N5frss8+8uC4tG86GJxUAQDAkFQBAMCQVAEAwJp9X5xpjcj8YtcZaa6o/qnToN4m1xFrbp9SNyIa+k1gZ+w5PKgCAYEgqAIBgSCoAgGBIKgCAYEgqAIBgSCoAgGDy3aZli6TVxWgICtap1A3IAf0mmeg7KFTGvpPX51QAAMiG4S8AQDAkFQBAMCQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDAkFQBAMCQVAEAwJBUAQDB1OqkYYzobY6wxJt8t/kPce5Ux5vTavi/CoO+gUPt736lxUjHGnG+MWWyM2WGM2ZwuX2GMMSEaWCzGmC+crypjzE4nvjDPa003xtwcsG3tjDF/NsZsSHfOzqGunST0naL0nV/H2rcz3cbWoe6RBPSd5PadGiUVY8wvJU2SNEFSW0mHSvovST+Q1DDDOfVrcs9QrLXN9nxJWiNpkPNvM/ccV4q/NiRVSXpB0tAS3LtW0HeK1rZbYu27XVKFtXZLbbelWOg7RWtbmL5jrS3oS1JzSTskDa3muOmS7pX0fPr40yUdLalC0jZJyyQNdo6vkDTCiX8iaZETW6U60HuSPpV0j7592Vh9SXco9ba4lZJGp48/oJo2rpJ0errcT9I6SddK2ijpkXgbnHYcIWmUpN2SKiV9IWmOc82rJb0j6TNJj0pqnOfP+ID0fToX+ntK4hd9p/h9J30dI+kDSZeU+ndO39l/+k5NnlT6Smok6dkcjv1PSf8j6SBJiyXNkfSSpDaSfiFppjHmyDzuPVDS8ZJ6SBom6cz0v49M1/27pD6Szs3jmq62kg5W6pWZo7IdaK2dKmmmpPE2leEHOdXDJPWX1EVSd6U6iSTJGLPNGHNSge0rd/Qd1UrfOVmpv+KfzOcbSDj6jpLdd2qSVFpL2mKt/XrPPxhjXk83eqcx5hTn2Getta9Za6sk9ZTUTNJt1tpKa+3LkuZKuiCPe99mrd1mrV0j6ZX0NaXUD/Mua+1aa+1WSbcW+L1VSRpnrf3KWruzwGtI0mRr7YZ0W+Y47ZS1toW1dlENrl3O6DvVC9F3LpH0hLX2ixq0I2noO9Urad+pSVL5RFJrd+zPWnuitbZFus699lqn3F7S2vQveo/Vkg7L494bnfKXSnWW6Nqx6xbiY2vtrgLPdWVq5/6OvlO9GvUdY0wTSedJejhAW5KEvlO9kvadmiSVv0r6StLZORxrnfIGSYcbY9x7d5S0Pl3eIampU9c2jzZ9JOnw2HULYWOx1yZjTLxN8eORHX0n8/GhDJG0Vam5grqEvpP5+FBq1HcKTirW2m2SbpQ0xRhzrjGmmTGmnjGmp6QDs5y6WKkf1lhjTANjTD9JgyTNTte/LWmIMaapMeYISZfm0azHJI0xxnQwxrSUdF0e52azVFI3Y0xPY0xjSTfE6jdJ6hroXpKk9H0apcNG6bhOoO94gvedtEskzbDpWde6gr7jSWTfqdGSYmvteElXSRorabNS3+R9Sq1geD3DOZWSBks6S6nVElMkDbfW/it9yESlVjRsUurxa+a+rpPB/ZJeVOqX8Zakp/L7jvbNWrtC0k2S5iu1+iM+JjlN0jHpcd1ncrlmeh34yVkO2anUqg5J+lc6rjPoO5HgfccYc5ik0yTNKKjRCUffiSSy75g69ocMAKCE6vQ2LQCA2kVSAQAEQ1IBAARDUgEABENSAQAEk9dOmMYYloolkLU26dt902+SaYu19pBSNyIb+k5iZew7PKkA+69CtxMBMvYdkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACCYvHYpLmcLFizw4pYtW3pxr169arM5AFAn8aQCAAiGpAIACGa/Gf6y1n/XT48ePby4Y8eOUXnNmjW10iYAqGt4UgEABENSAQAEQ1IBAASz38ypVOecc86JypMmTSphSwCgfPGkAgAIhqQCAAiG4a+0pk2blroJKKJhw4ZF5XHjxnl1Rx99tBcbY6Lyxo0bvbrHH3884z0++ugjL37yySe9+P3334/KVVVV1bQYIfXu3duLlyxZkvHY9u3be/GGDRsyHnvGGWdkrBswYIAXx3ftcO/TpUuXjNeJc/unJA0ZMiQqP/300zlfp1h4UgEABENSAQAEQ1IBAATDnEpahw4dSt0EBHTSSSd58fTp06Nyo0aNvLr4Fj5u3KZNG69u9OjRObfh5ptv9uLu3btH5WXLluV8HRSmW7duUXnRokVe3aeffhqV43MUjRs39uKdO3dmvEfbtm29ON6XMt1TktauXRuVKyoqvLrnnnvOi935mAsuuMCr69q1a8Z7lgJPKgCAYEgqAIBgSCoAgGCYU0lbsWJFqZuAgA455BAvdudR4p89mTVrVsbrxMfMzzvvvIzHNmjQIGubBg4cGJWZUyk+dw7j5Zdf9ur69+8flSsrKzOeJ0lz587NWBefj3HnVOLzIh9++KEXu3Mq1bnllltyPrbUeFIBAARDUgEABFOnh7/q1fs2Z9avX7+ELUFt+/vf/+7FU6ZMicp33323V7d8+fKcr3vxxRd7sbvkOL5NS1y/fv2i8u23357zPVEYd3sVdysTSZoxY0ZUbt68uVfnDo2VSsuWLb14xIgRGY9duXJlsZuTF55UAADBkFQAAMGQVAAAwZhs2wrsdbAxuR+cAMcee2xUXrp0adZj3eV/gwcPLlqbisFaa6o/qnTKrd/kI585lfXr10fljh07Fq1NeVhire1T6kZkUxt9Z9SoUV48derUYt+yWvGl7Nm232/Xrl1U3rRpU9HaFJOx7/CkAgAIhqQCAAiGpAIACKZOf05l1apVUfntt9/26nr27OnF7jbZQK7ir6nN5v777y9iS1CoJMyhxI0cOdKL3bnvZ555xqv7+OOPa6NJOeNJBQAQDEkFABBMnR7++uKLL6JyfHdRIIS+ffvmfOydd95ZxJagnMXfMBpf5uyK71hcVVVVlDYViicVAEAwJBUAQDAkFQBAMHV6TqVhw4ZRuUmTJl5d/I1t8RjIxdChQ0vdBNQBJ554ohe3b9/ei93t7ZcsWVIrbSoUTyoAgGBIKgCAYEgqAIBg6vScyve+972o/P3vf9+ri2/5n88rALD/uuiii7z4yCOPzHhsfGug3bt3F6NJKFOtWrWKytOmTfPq4nO8d9xxR620KQSeVAAAwZBUAADB1Onhr3wsW7as1E1AGfj5z3/uxe4whbstkCTdcMMNXszwF1zuDtctWrTw6jZv3uzFDz30UG00KQieVAAAwZBUAADBkFQAAMEwp5K2YMGCUjcBCdS6deussWvp0qVePGfOnKK0Ccl10EEHZaz7+uuvvTjbFj+NGzf24jFjxkTlRYsWZTwvvoVLKebxeFIBAARDUgEABENSAQAEw5xKWv/+/aPypEmTStgSlFq9et/+rTVx4kSvrkuXLhnP+9vf/la0NqF0unbtus+y5H/WRJIuu+yyqBzf+in+Oabjjjsu47HxuZnbb789Kse3cLnvvvuicvzzdsypAADKGkkFABCMyWd3XmNMWW3l27Rp06hcUVHh1cUfWysrK6Pyj370I68u2xK+JLDWJvq1leXWb1q2bBmVt2zZkvXY5cuXR+UzzzzTq1u7dm3YhoW3xFrbp9SNyCYJfcfdbbp79+45n7dq1Sovjg9pubsUr1mzxqu7+uqrvfiJJ57I+b61JGPf4UkFABAMSQUAEAxJBQAQTJ1eUvzll19G5fHjx3t1s2fP9uJGjRpF5bFjx3p1SZ9TQVjnn39+zsfOmjUrKpfBHAoK4C4r//zzz726119/PeN57jytJM2dO9eL+/btG5XdJcNSIudQcsaTCgAgGJIKACCYOr2kOJsPPvjAi91Pys6fP9+riy8xThqWFNdMjx49vHjhwoVROb4M1B1SlaROnTpF5a1btxahdUXFkuIiuvTSS7146tSpXrx69eqoHO+D27dvL17DwmBJMQCg+EgqAIBgSCoAgGDq9JLifOQzt4S65aijjvLibG/vmzx5sheX4TwKakmvXr2y1r/44otRuQzmUHLGkwoAIBiSCgAgGJIKACCY/XZO5corr/TiRx55JCo/9dRTtdwalItnn3221E1Agl1++eX7LEvS+vXrvXjChAm10qbaxpMKACAYkgoAIJj9dvhrzpw5XtyiRYvSNASJFn8jXzwGXF26dInK8Y8pLFiwwItXrlxZK22qbTypAACCIakAAIIhqQAAgtlv51SAXEybNs2LN27cWKKWIIk6d+7sxcOGDYvKVVVVXt3SpUtro0klx5MKACAYkgoAIBiSCgAgGOZUgBh3G/L4VveAq1mzZl5cv379qDx27FivbuLEibXSplLjSQUAEAxJBQAQjMnnjYfGGF6PmEDWWlPqNmRDv0msJdbaPqVuRDb0ncTK2Hd4UgEABENSAQAEQ1IBAAST75LiLZJWF6MhKFinUjcgB/SbZKLvoFAZ+05eE/UAAGTD8BcAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACCY/wdEdaqAWczc3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network flowchart:\n",
    "#input vector --- random initialized weights ---> hyperdimensional vecotor ---> one_hot_net l1 ---> ...ln... ---> sigmoid/softmax output\n",
    "#One hot net\n",
    "\n",
    "class One_hot_op(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A, W, epsilon):\n",
    "        Z = torch.matmul(W, A)\n",
    "        ctx.Z = Z\n",
    "        ctx.A = A\n",
    "        ctx.W = W\n",
    "        ret = Z > epsilon\n",
    "        #print(ret[1:10][1:10])\n",
    "        return ret.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dA):\n",
    "        step = ctx.Z > 0\n",
    "        step = step.float()\n",
    "        dL_dZ = dL_dA * step \n",
    "        \n",
    "        dZ_dW = torch.transpose(ctx.A, 0,1)\n",
    "        dZ_dW = dZ_dW / torch.abs(dZ_dW)\n",
    "        dZ_dA = torch.transpose(ctx.W, 0,1)\n",
    "        dZ_dA = dZ_dA / torch.abs(dZ_dA)\n",
    "        dA = torch.matmul(dZ_dA,dL_dZ)\n",
    "        dW = torch.matmul(dL_dZ,dZ_dW)\n",
    "        return dA, dW, None\n",
    "\n",
    "\n",
    "class One_hot_layer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, initialization_f, epsilon):\n",
    "        super(One_hot_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.initialization_f = initialization_f\n",
    "        initialized_weight = initialization_f(out_dim, in_dim)\n",
    "        self.weight = nn.Parameter(initialized_weight, requires_grad = True)\n",
    "        self.op = One_hot_op\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_dim) + ',' \\\n",
    "               + str(self.out_dim) + ')'\n",
    "        \n",
    "    def forward(self, A):\n",
    "        return self.op.apply(A, self.weight, self.epsilon)\n",
    "    \n",
    "\n",
    "class One_hot_net(nn.Module):\n",
    "    def __init__(self, in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers=2, layer_size_factor=[1, 5], dropout=[-1, 0.5]):\n",
    "        super(One_hot_net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.in_dim = in_dim\n",
    "        feature_len = in_dim * encoder_multiplier\n",
    "        self.feature_len = feature_len\n",
    "        self.n_layers=n_layers\n",
    "        self.layer_size_factor=layer_size_factor\n",
    "        self.dropout=dropout\n",
    "        self.n_class = n_class\n",
    "        self.f_encoder = f_encoder\n",
    "        self.f_initializer = f_initializer\n",
    "        for i in range(n_layers):\n",
    "            if dropout[i] > 0:\n",
    "                self.layers.append(nn.Dropout(dropout[i]))\n",
    "            if i < n_layers - 1:\n",
    "                self.layers.append(\n",
    "                    One_hot_layer(int(feature_len // layer_size_factor[i]), int(feature_len // layer_size_factor[i + 1]), f_initializer, epsilon))\n",
    "        self.tail = nn.Linear(int(feature_len // layer_size_factor[-1]), n_class)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def flatten(self, X):\n",
    "        return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.f_encoder.apply(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        X = self.tail(X)\n",
    "        return self.out(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializers and encoders\n",
    "def uniform_initializer(out_dim, in_dim):\n",
    "    tensor = torch.empty(out_dim, in_dim)\n",
    "    return torch.nn.init.uniform_(tensor, a=-2, b=2).cuda() \n",
    "\n",
    "class simple_encoder():\n",
    "    def __init__(self, out_dim, in_dim):\n",
    "        self.W = uniform_initializer(out_dim, in_dim)\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return torch.matmul(self.W, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'in_dim': 784,\n",
    "    'n_class': 10,\n",
    "    'f_encoder': simple_encoder(784*20, 784),\n",
    "    'f_initializer': uniform_initializer,\n",
    "    'encoder_multiplier': 20,\n",
    "    'epsilon': 10e-3,\n",
    "    'n_layers': 2,\n",
    "    'layer_size_factor': [1, 1, 1],\n",
    "    'dropout': [-1, -1, -1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model1 = One_hot_net(parameters['in_dim'], parameters['n_class'], parameters['f_encoder'], parameters['encoder_multiplier'], \n",
    "                     parameters['f_initializer'], parameters['epsilon'], parameters['n_layers'], \n",
    "                     parameters['layer_size_factor'], parameters['dropout']).to(device)\n",
    "\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "     One_hot_layer-1                    [-1, 2]     245,862,400\n",
      "            Linear-2                   [-1, 10]         156,810\n",
      "        LogSoftmax-3                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 246,019,210\n",
      "Trainable params: 246,019,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 938.49\n",
      "Estimated Total Size (MB): 938.49\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model1, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, trainloader, log_interval = 10, device = torch.device(\"cuda:0\")):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(model.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "        return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device = torch.device(\"cuda:0\")):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.4222, Accuracy: 690/10000 (7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.412163\n",
      "\n",
      "Test set: Avg. loss: 2.6609, Accuracy: 2143/10000 (21%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.562776\n",
      "\n",
      "Test set: Avg. loss: 3.4248, Accuracy: 2644/10000 (26%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 3.454217\n",
      "\n",
      "Test set: Avg. loss: 4.7321, Accuracy: 1430/10000 (14%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 5.074128\n",
      "\n",
      "Test set: Avg. loss: 7.1805, Accuracy: 2823/10000 (28%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 6.623729\n",
      "\n",
      "Test set: Avg. loss: 10.1754, Accuracy: 2031/10000 (20%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 8.724866\n",
      "\n",
      "Test set: Avg. loss: 13.4504, Accuracy: 2668/10000 (27%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 15.616645\n",
      "\n",
      "Test set: Avg. loss: 14.2432, Accuracy: 2633/10000 (26%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 13.033466\n",
      "\n",
      "Test set: Avg. loss: 12.9065, Accuracy: 3808/10000 (38%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 11.010694\n",
      "\n",
      "Test set: Avg. loss: 14.2978, Accuracy: 1988/10000 (20%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 10.555153\n",
      "\n",
      "Test set: Avg. loss: 14.5664, Accuracy: 3068/10000 (31%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 12.034454\n",
      "\n",
      "Test set: Avg. loss: 12.8872, Accuracy: 2770/10000 (28%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 11.298950\n",
      "\n",
      "Test set: Avg. loss: 11.6264, Accuracy: 3134/10000 (31%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 13.743171\n",
      "\n",
      "Test set: Avg. loss: 10.0248, Accuracy: 4633/10000 (46%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 11.912468\n",
      "\n",
      "Test set: Avg. loss: 7.7307, Accuracy: 4568/10000 (46%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 7.306695\n",
      "\n",
      "Test set: Avg. loss: 5.1881, Accuracy: 4523/10000 (45%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 5.699134\n",
      "\n",
      "Test set: Avg. loss: 3.3502, Accuracy: 5944/10000 (59%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 3.838625\n",
      "\n",
      "Test set: Avg. loss: 2.0235, Accuracy: 7083/10000 (71%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 2.726627\n",
      "\n",
      "Test set: Avg. loss: 1.5170, Accuracy: 6334/10000 (63%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.223372\n",
      "\n",
      "Test set: Avg. loss: 1.3796, Accuracy: 6543/10000 (65%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.544272\n",
      "\n",
      "Test set: Avg. loss: 1.2062, Accuracy: 7143/10000 (71%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 1.665075\n",
      "\n",
      "Test set: Avg. loss: 0.8225, Accuracy: 7889/10000 (79%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.722648\n",
      "\n",
      "Test set: Avg. loss: 0.9425, Accuracy: 7657/10000 (77%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 1.070205\n",
      "\n",
      "Test set: Avg. loss: 0.6380, Accuracy: 8166/10000 (82%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.715764\n",
      "\n",
      "Test set: Avg. loss: 0.7705, Accuracy: 7841/10000 (78%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.674406\n",
      "\n",
      "Test set: Avg. loss: 0.7003, Accuracy: 7971/10000 (80%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.630523\n",
      "\n",
      "Test set: Avg. loss: 0.5454, Accuracy: 8415/10000 (84%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.318936\n",
      "\n",
      "Test set: Avg. loss: 0.6060, Accuracy: 8277/10000 (83%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.532674\n",
      "\n",
      "Test set: Avg. loss: 0.6009, Accuracy: 8235/10000 (82%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.531080\n",
      "\n",
      "Test set: Avg. loss: 0.5706, Accuracy: 8284/10000 (83%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.397874\n",
      "\n",
      "Test set: Avg. loss: 0.5062, Accuracy: 8483/10000 (85%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.400314\n",
      "\n",
      "Test set: Avg. loss: 0.5578, Accuracy: 8390/10000 (84%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.692474\n",
      "\n",
      "Test set: Avg. loss: 0.5178, Accuracy: 8500/10000 (85%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.451481\n",
      "\n",
      "Test set: Avg. loss: 0.5819, Accuracy: 8313/10000 (83%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.675826\n",
      "\n",
      "Test set: Avg. loss: 0.4890, Accuracy: 8586/10000 (86%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.461314\n",
      "\n",
      "Test set: Avg. loss: 0.6884, Accuracy: 8083/10000 (81%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.912335\n",
      "\n",
      "Test set: Avg. loss: 0.5286, Accuracy: 8426/10000 (84%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.468940\n",
      "\n",
      "Test set: Avg. loss: 0.6523, Accuracy: 8196/10000 (82%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.597983\n",
      "\n",
      "Test set: Avg. loss: 0.8027, Accuracy: 7838/10000 (78%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.899252\n",
      "\n",
      "Test set: Avg. loss: 0.5546, Accuracy: 8415/10000 (84%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.963427\n",
      "\n",
      "Test set: Avg. loss: 0.6722, Accuracy: 8167/10000 (82%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 1.032758\n",
      "\n",
      "Test set: Avg. loss: 0.4928, Accuracy: 8567/10000 (86%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.319083\n",
      "\n",
      "Test set: Avg. loss: 0.6024, Accuracy: 8172/10000 (82%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.883901\n",
      "\n",
      "Test set: Avg. loss: 0.5421, Accuracy: 8405/10000 (84%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.984022\n",
      "\n",
      "Test set: Avg. loss: 0.7697, Accuracy: 7771/10000 (78%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 1.427539\n",
      "\n",
      "Test set: Avg. loss: 0.5610, Accuracy: 8350/10000 (84%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.640640\n",
      "\n",
      "Test set: Avg. loss: 0.5619, Accuracy: 8347/10000 (83%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.905722\n",
      "\n",
      "Test set: Avg. loss: 0.5612, Accuracy: 8389/10000 (84%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.537860\n",
      "\n",
      "Test set: Avg. loss: 0.5118, Accuracy: 8498/10000 (85%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.646544\n",
      "\n",
      "Test set: Avg. loss: 0.4446, Accuracy: 8649/10000 (86%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.639494\n",
      "\n",
      "Test set: Avg. loss: 0.5410, Accuracy: 8448/10000 (84%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.341368\n",
      "\n",
      "Test set: Avg. loss: 0.5488, Accuracy: 8437/10000 (84%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.351659\n",
      "\n",
      "Test set: Avg. loss: 0.4078, Accuracy: 8792/10000 (88%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.229238\n",
      "\n",
      "Test set: Avg. loss: 0.4459, Accuracy: 8701/10000 (87%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.225341\n",
      "\n",
      "Test set: Avg. loss: 0.5030, Accuracy: 8528/10000 (85%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.195211\n",
      "\n",
      "Test set: Avg. loss: 0.5713, Accuracy: 8304/10000 (83%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.603898\n",
      "\n",
      "Test set: Avg. loss: 0.5623, Accuracy: 8282/10000 (83%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.575950\n",
      "\n",
      "Test set: Avg. loss: 0.4895, Accuracy: 8612/10000 (86%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.660660\n",
      "\n",
      "Test set: Avg. loss: 0.4228, Accuracy: 8734/10000 (87%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.313342\n",
      "\n",
      "Test set: Avg. loss: 0.5323, Accuracy: 8353/10000 (84%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.271491\n",
      "\n",
      "Test set: Avg. loss: 0.4092, Accuracy: 8788/10000 (88%)\n",
      "\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.343449\n",
      "\n",
      "Test set: Avg. loss: 0.4937, Accuracy: 8539/10000 (85%)\n",
      "\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.559125\n",
      "\n",
      "Test set: Avg. loss: 0.5555, Accuracy: 8356/10000 (84%)\n",
      "\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.677227\n",
      "\n",
      "Test set: Avg. loss: 0.5369, Accuracy: 8435/10000 (84%)\n",
      "\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.554787\n",
      "\n",
      "Test set: Avg. loss: 0.5680, Accuracy: 8292/10000 (83%)\n",
      "\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.868723\n",
      "\n",
      "Test set: Avg. loss: 0.4459, Accuracy: 8663/10000 (87%)\n",
      "\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.691236\n",
      "\n",
      "Test set: Avg. loss: 0.4551, Accuracy: 8595/10000 (86%)\n",
      "\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.334902\n",
      "\n",
      "Test set: Avg. loss: 0.4901, Accuracy: 8480/10000 (85%)\n",
      "\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.630706\n",
      "\n",
      "Test set: Avg. loss: 0.5652, Accuracy: 8235/10000 (82%)\n",
      "\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.544521\n",
      "\n",
      "Test set: Avg. loss: 0.4852, Accuracy: 8483/10000 (85%)\n",
      "\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.386202\n",
      "\n",
      "Test set: Avg. loss: 0.5180, Accuracy: 8515/10000 (85%)\n",
      "\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.382849\n",
      "\n",
      "Test set: Avg. loss: 0.4541, Accuracy: 8621/10000 (86%)\n",
      "\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.624782\n",
      "\n",
      "Test set: Avg. loss: 0.4476, Accuracy: 8652/10000 (87%)\n",
      "\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.625119\n",
      "\n",
      "Test set: Avg. loss: 0.6077, Accuracy: 8207/10000 (82%)\n",
      "\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.512331\n",
      "\n",
      "Test set: Avg. loss: 0.4350, Accuracy: 8723/10000 (87%)\n",
      "\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.332542\n",
      "\n",
      "Test set: Avg. loss: 0.4089, Accuracy: 8788/10000 (88%)\n",
      "\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.656516\n",
      "\n",
      "Test set: Avg. loss: 0.4858, Accuracy: 8581/10000 (86%)\n",
      "\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.730224\n",
      "\n",
      "Test set: Avg. loss: 0.4977, Accuracy: 8468/10000 (85%)\n",
      "\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.598364\n",
      "\n",
      "Test set: Avg. loss: 0.4003, Accuracy: 8800/10000 (88%)\n",
      "\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.394864\n",
      "\n",
      "Test set: Avg. loss: 0.4400, Accuracy: 8629/10000 (86%)\n",
      "\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.311904\n",
      "\n",
      "Test set: Avg. loss: 0.4108, Accuracy: 8730/10000 (87%)\n",
      "\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.307225\n",
      "\n",
      "Test set: Avg. loss: 0.4285, Accuracy: 8683/10000 (87%)\n",
      "\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.202410\n",
      "\n",
      "Test set: Avg. loss: 0.3985, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.341554\n",
      "\n",
      "Test set: Avg. loss: 0.3803, Accuracy: 8864/10000 (89%)\n",
      "\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.467789\n",
      "\n",
      "Test set: Avg. loss: 0.3794, Accuracy: 8890/10000 (89%)\n",
      "\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.617424\n",
      "\n",
      "Test set: Avg. loss: 0.4007, Accuracy: 8787/10000 (88%)\n",
      "\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.269969\n",
      "\n",
      "Test set: Avg. loss: 0.4710, Accuracy: 8622/10000 (86%)\n",
      "\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.376799\n",
      "\n",
      "Test set: Avg. loss: 0.4344, Accuracy: 8677/10000 (87%)\n",
      "\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.216956\n",
      "\n",
      "Test set: Avg. loss: 0.4910, Accuracy: 8498/10000 (85%)\n",
      "\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.724093\n",
      "\n",
      "Test set: Avg. loss: 0.8512, Accuracy: 7883/10000 (79%)\n",
      "\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.581005\n",
      "\n",
      "Test set: Avg. loss: 0.8261, Accuracy: 7905/10000 (79%)\n",
      "\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.653988\n",
      "\n",
      "Test set: Avg. loss: 0.6476, Accuracy: 8217/10000 (82%)\n",
      "\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.481516\n",
      "\n",
      "Test set: Avg. loss: 0.5533, Accuracy: 8365/10000 (84%)\n",
      "\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.761595\n",
      "\n",
      "Test set: Avg. loss: 1.0265, Accuracy: 7016/10000 (70%)\n",
      "\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 1.276830\n",
      "\n",
      "Test set: Avg. loss: 0.9879, Accuracy: 8045/10000 (80%)\n",
      "\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 1.420876\n",
      "\n",
      "Test set: Avg. loss: 1.0846, Accuracy: 8118/10000 (81%)\n",
      "\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 1.178113\n",
      "\n",
      "Test set: Avg. loss: 0.5389, Accuracy: 8471/10000 (85%)\n",
      "\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.377220\n",
      "\n",
      "Test set: Avg. loss: 0.6574, Accuracy: 8065/10000 (81%)\n",
      "\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.432821\n",
      "\n",
      "Test set: Avg. loss: 0.4035, Accuracy: 8835/10000 (88%)\n",
      "\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.430357\n",
      "\n",
      "Test set: Avg. loss: 0.4601, Accuracy: 8633/10000 (86%)\n",
      "\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.495617\n",
      "\n",
      "Test set: Avg. loss: 0.4535, Accuracy: 8643/10000 (86%)\n",
      "\n",
      "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.413606\n",
      "\n",
      "Test set: Avg. loss: 0.3653, Accuracy: 8932/10000 (89%)\n",
      "\n",
      "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.264967\n",
      "\n",
      "Test set: Avg. loss: 0.4015, Accuracy: 8804/10000 (88%)\n",
      "\n",
      "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.680724\n",
      "\n",
      "Test set: Avg. loss: 0.4718, Accuracy: 8561/10000 (86%)\n",
      "\n",
      "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.475619\n",
      "\n",
      "Test set: Avg. loss: 0.3689, Accuracy: 8876/10000 (89%)\n",
      "\n",
      "Train Epoch: 105 [0/60000 (0%)]\tLoss: 0.434243\n",
      "\n",
      "Test set: Avg. loss: 0.4773, Accuracy: 8576/10000 (86%)\n",
      "\n",
      "Train Epoch: 106 [0/60000 (0%)]\tLoss: 0.450830\n",
      "\n",
      "Test set: Avg. loss: 0.3862, Accuracy: 8864/10000 (89%)\n",
      "\n",
      "Train Epoch: 107 [0/60000 (0%)]\tLoss: 0.276055\n",
      "\n",
      "Test set: Avg. loss: 0.3873, Accuracy: 8864/10000 (89%)\n",
      "\n",
      "Train Epoch: 108 [0/60000 (0%)]\tLoss: 0.356297\n",
      "\n",
      "Test set: Avg. loss: 0.4527, Accuracy: 8637/10000 (86%)\n",
      "\n",
      "Train Epoch: 109 [0/60000 (0%)]\tLoss: 0.318857\n",
      "\n",
      "Test set: Avg. loss: 0.4037, Accuracy: 8809/10000 (88%)\n",
      "\n",
      "Train Epoch: 110 [0/60000 (0%)]\tLoss: 0.498658\n",
      "\n",
      "Test set: Avg. loss: 0.3733, Accuracy: 8863/10000 (89%)\n",
      "\n",
      "Train Epoch: 111 [0/60000 (0%)]\tLoss: 0.376174\n",
      "\n",
      "Test set: Avg. loss: 0.3431, Accuracy: 8996/10000 (90%)\n",
      "\n",
      "Train Epoch: 112 [0/60000 (0%)]\tLoss: 0.376348\n",
      "\n",
      "Test set: Avg. loss: 0.4494, Accuracy: 8678/10000 (87%)\n",
      "\n",
      "Train Epoch: 113 [0/60000 (0%)]\tLoss: 0.286613\n",
      "\n",
      "Test set: Avg. loss: 0.4447, Accuracy: 8734/10000 (87%)\n",
      "\n",
      "Train Epoch: 114 [0/60000 (0%)]\tLoss: 0.690160\n",
      "\n",
      "Test set: Avg. loss: 0.5049, Accuracy: 8512/10000 (85%)\n",
      "\n",
      "Train Epoch: 115 [0/60000 (0%)]\tLoss: 0.624935\n",
      "\n",
      "Test set: Avg. loss: 0.3988, Accuracy: 8838/10000 (88%)\n",
      "\n",
      "Train Epoch: 116 [0/60000 (0%)]\tLoss: 0.395713\n",
      "\n",
      "Test set: Avg. loss: 0.4619, Accuracy: 8616/10000 (86%)\n",
      "\n",
      "Train Epoch: 117 [0/60000 (0%)]\tLoss: 0.735248\n",
      "\n",
      "Test set: Avg. loss: 0.3383, Accuracy: 8995/10000 (90%)\n",
      "\n",
      "Train Epoch: 118 [0/60000 (0%)]\tLoss: 0.440014\n",
      "\n",
      "Test set: Avg. loss: 0.4083, Accuracy: 8805/10000 (88%)\n",
      "\n",
      "Train Epoch: 119 [0/60000 (0%)]\tLoss: 0.797010\n",
      "\n",
      "Test set: Avg. loss: 0.3599, Accuracy: 8941/10000 (89%)\n",
      "\n",
      "Train Epoch: 120 [0/60000 (0%)]\tLoss: 0.311673\n",
      "\n",
      "Test set: Avg. loss: 0.4389, Accuracy: 8681/10000 (87%)\n",
      "\n",
      "Train Epoch: 121 [0/60000 (0%)]\tLoss: 0.628064\n",
      "\n",
      "Test set: Avg. loss: 0.4202, Accuracy: 8758/10000 (88%)\n",
      "\n",
      "Train Epoch: 122 [0/60000 (0%)]\tLoss: 0.588320\n",
      "\n",
      "Test set: Avg. loss: 0.4517, Accuracy: 8632/10000 (86%)\n",
      "\n",
      "Train Epoch: 123 [0/60000 (0%)]\tLoss: 0.394381\n",
      "\n",
      "Test set: Avg. loss: 0.3750, Accuracy: 8866/10000 (89%)\n",
      "\n",
      "Train Epoch: 124 [0/60000 (0%)]\tLoss: 0.298655\n",
      "\n",
      "Test set: Avg. loss: 0.4488, Accuracy: 8640/10000 (86%)\n",
      "\n",
      "Train Epoch: 125 [0/60000 (0%)]\tLoss: 0.406935\n",
      "\n",
      "Test set: Avg. loss: 0.3888, Accuracy: 8840/10000 (88%)\n",
      "\n",
      "Train Epoch: 126 [0/60000 (0%)]\tLoss: 0.398189\n",
      "\n",
      "Test set: Avg. loss: 0.4045, Accuracy: 8793/10000 (88%)\n",
      "\n",
      "Train Epoch: 127 [0/60000 (0%)]\tLoss: 0.291936\n",
      "\n",
      "Test set: Avg. loss: 0.3674, Accuracy: 8886/10000 (89%)\n",
      "\n",
      "Train Epoch: 128 [0/60000 (0%)]\tLoss: 0.495209\n",
      "\n",
      "Test set: Avg. loss: 0.3577, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 129 [0/60000 (0%)]\tLoss: 0.312825\n",
      "\n",
      "Test set: Avg. loss: 0.3657, Accuracy: 8916/10000 (89%)\n",
      "\n",
      "Train Epoch: 130 [0/60000 (0%)]\tLoss: 0.313031\n",
      "\n",
      "Test set: Avg. loss: 0.3853, Accuracy: 8839/10000 (88%)\n",
      "\n",
      "Train Epoch: 131 [0/60000 (0%)]\tLoss: 0.219093\n",
      "\n",
      "Test set: Avg. loss: 0.3302, Accuracy: 9026/10000 (90%)\n",
      "\n",
      "Train Epoch: 132 [0/60000 (0%)]\tLoss: 0.164497\n",
      "\n",
      "Test set: Avg. loss: 0.3306, Accuracy: 9064/10000 (91%)\n",
      "\n",
      "Train Epoch: 133 [0/60000 (0%)]\tLoss: 0.326016\n",
      "\n",
      "Test set: Avg. loss: 0.3702, Accuracy: 8911/10000 (89%)\n",
      "\n",
      "Train Epoch: 134 [0/60000 (0%)]\tLoss: 0.181445\n",
      "\n",
      "Test set: Avg. loss: 0.4328, Accuracy: 8708/10000 (87%)\n",
      "\n",
      "Train Epoch: 135 [0/60000 (0%)]\tLoss: 0.511786\n",
      "\n",
      "Test set: Avg. loss: 0.3753, Accuracy: 8892/10000 (89%)\n",
      "\n",
      "Train Epoch: 136 [0/60000 (0%)]\tLoss: 0.450063\n",
      "\n",
      "Test set: Avg. loss: 0.3931, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "Train Epoch: 137 [0/60000 (0%)]\tLoss: 0.174172\n",
      "\n",
      "Test set: Avg. loss: 0.3790, Accuracy: 8860/10000 (89%)\n",
      "\n",
      "Train Epoch: 138 [0/60000 (0%)]\tLoss: 0.410272\n",
      "\n",
      "Test set: Avg. loss: 0.3286, Accuracy: 9019/10000 (90%)\n",
      "\n",
      "Train Epoch: 139 [0/60000 (0%)]\tLoss: 0.211662\n",
      "\n",
      "Test set: Avg. loss: 0.3577, Accuracy: 8923/10000 (89%)\n",
      "\n",
      "Train Epoch: 140 [0/60000 (0%)]\tLoss: 0.400439\n",
      "\n",
      "Test set: Avg. loss: 0.3217, Accuracy: 9035/10000 (90%)\n",
      "\n",
      "Train Epoch: 141 [0/60000 (0%)]\tLoss: 0.210090\n",
      "\n",
      "Test set: Avg. loss: 0.3239, Accuracy: 9042/10000 (90%)\n",
      "\n",
      "Train Epoch: 142 [0/60000 (0%)]\tLoss: 0.207449\n",
      "\n",
      "Test set: Avg. loss: 0.3350, Accuracy: 9009/10000 (90%)\n",
      "\n",
      "Train Epoch: 143 [0/60000 (0%)]\tLoss: 0.192077\n",
      "\n",
      "Test set: Avg. loss: 0.3703, Accuracy: 8886/10000 (89%)\n",
      "\n",
      "Train Epoch: 144 [0/60000 (0%)]\tLoss: 0.547317\n",
      "\n",
      "Test set: Avg. loss: 0.4414, Accuracy: 8709/10000 (87%)\n",
      "\n",
      "Train Epoch: 145 [0/60000 (0%)]\tLoss: 0.402912\n",
      "\n",
      "Test set: Avg. loss: 0.3307, Accuracy: 9035/10000 (90%)\n",
      "\n",
      "Train Epoch: 146 [0/60000 (0%)]\tLoss: 0.343310\n",
      "\n",
      "Test set: Avg. loss: 0.4048, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "Train Epoch: 147 [0/60000 (0%)]\tLoss: 0.370730\n",
      "\n",
      "Test set: Avg. loss: 0.4190, Accuracy: 8735/10000 (87%)\n",
      "\n",
      "Train Epoch: 148 [0/60000 (0%)]\tLoss: 0.243841\n",
      "\n",
      "Test set: Avg. loss: 0.3614, Accuracy: 8937/10000 (89%)\n",
      "\n",
      "Train Epoch: 149 [0/60000 (0%)]\tLoss: 0.143564\n",
      "\n",
      "Test set: Avg. loss: 0.3525, Accuracy: 8974/10000 (90%)\n",
      "\n",
      "Train Epoch: 150 [0/60000 (0%)]\tLoss: 0.283798\n",
      "\n",
      "Test set: Avg. loss: 0.3194, Accuracy: 9062/10000 (91%)\n",
      "\n",
      "Train Epoch: 151 [0/60000 (0%)]\tLoss: 0.320420\n",
      "\n",
      "Test set: Avg. loss: 0.4174, Accuracy: 8683/10000 (87%)\n",
      "\n",
      "Train Epoch: 152 [0/60000 (0%)]\tLoss: 0.226761\n",
      "\n",
      "Test set: Avg. loss: 0.3325, Accuracy: 9010/10000 (90%)\n",
      "\n",
      "Train Epoch: 153 [0/60000 (0%)]\tLoss: 0.487356\n",
      "\n",
      "Test set: Avg. loss: 0.3166, Accuracy: 9094/10000 (91%)\n",
      "\n",
      "Train Epoch: 154 [0/60000 (0%)]\tLoss: 0.474567\n",
      "\n",
      "Test set: Avg. loss: 0.3117, Accuracy: 9083/10000 (91%)\n",
      "\n",
      "Train Epoch: 155 [0/60000 (0%)]\tLoss: 0.381152\n",
      "\n",
      "Test set: Avg. loss: 0.3453, Accuracy: 8967/10000 (90%)\n",
      "\n",
      "Train Epoch: 156 [0/60000 (0%)]\tLoss: 0.361261\n",
      "\n",
      "Test set: Avg. loss: 0.3330, Accuracy: 9003/10000 (90%)\n",
      "\n",
      "Train Epoch: 157 [0/60000 (0%)]\tLoss: 0.323817\n",
      "\n",
      "Test set: Avg. loss: 0.3155, Accuracy: 9045/10000 (90%)\n",
      "\n",
      "Train Epoch: 158 [0/60000 (0%)]\tLoss: 0.647009\n",
      "\n",
      "Test set: Avg. loss: 0.3972, Accuracy: 8739/10000 (87%)\n",
      "\n",
      "Train Epoch: 159 [0/60000 (0%)]\tLoss: 0.319425\n",
      "\n",
      "Test set: Avg. loss: 0.4736, Accuracy: 8509/10000 (85%)\n",
      "\n",
      "Train Epoch: 160 [0/60000 (0%)]\tLoss: 0.378616\n",
      "\n",
      "Test set: Avg. loss: 0.3206, Accuracy: 9054/10000 (91%)\n",
      "\n",
      "Train Epoch: 161 [0/60000 (0%)]\tLoss: 0.264797\n",
      "\n",
      "Test set: Avg. loss: 0.3322, Accuracy: 9010/10000 (90%)\n",
      "\n",
      "Train Epoch: 162 [0/60000 (0%)]\tLoss: 0.508322\n",
      "\n",
      "Test set: Avg. loss: 0.3851, Accuracy: 8859/10000 (89%)\n",
      "\n",
      "Train Epoch: 163 [0/60000 (0%)]\tLoss: 0.335810\n",
      "\n",
      "Test set: Avg. loss: 0.3361, Accuracy: 9009/10000 (90%)\n",
      "\n",
      "Train Epoch: 164 [0/60000 (0%)]\tLoss: 0.178457\n",
      "\n",
      "Test set: Avg. loss: 0.3824, Accuracy: 8899/10000 (89%)\n",
      "\n",
      "Train Epoch: 165 [0/60000 (0%)]\tLoss: 0.242391\n",
      "\n",
      "Test set: Avg. loss: 0.3618, Accuracy: 8976/10000 (90%)\n",
      "\n",
      "Train Epoch: 166 [0/60000 (0%)]\tLoss: 0.961683\n",
      "\n",
      "Test set: Avg. loss: 0.3651, Accuracy: 8930/10000 (89%)\n",
      "\n",
      "Train Epoch: 167 [0/60000 (0%)]\tLoss: 0.552840\n",
      "\n",
      "Test set: Avg. loss: 0.4042, Accuracy: 8805/10000 (88%)\n",
      "\n",
      "Train Epoch: 168 [0/60000 (0%)]\tLoss: 0.344722\n",
      "\n",
      "Test set: Avg. loss: 0.3691, Accuracy: 8894/10000 (89%)\n",
      "\n",
      "Train Epoch: 169 [0/60000 (0%)]\tLoss: 0.337702\n",
      "\n",
      "Test set: Avg. loss: 0.4016, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 170 [0/60000 (0%)]\tLoss: 0.295387\n",
      "\n",
      "Test set: Avg. loss: 0.3744, Accuracy: 8859/10000 (89%)\n",
      "\n",
      "Train Epoch: 171 [0/60000 (0%)]\tLoss: 0.345802\n",
      "\n",
      "Test set: Avg. loss: 0.3460, Accuracy: 8991/10000 (90%)\n",
      "\n",
      "Train Epoch: 172 [0/60000 (0%)]\tLoss: 0.307291\n",
      "\n",
      "Test set: Avg. loss: 0.3785, Accuracy: 8840/10000 (88%)\n",
      "\n",
      "Train Epoch: 173 [0/60000 (0%)]\tLoss: 0.439951\n",
      "\n",
      "Test set: Avg. loss: 0.3328, Accuracy: 9037/10000 (90%)\n",
      "\n",
      "Train Epoch: 174 [0/60000 (0%)]\tLoss: 0.691301\n",
      "\n",
      "Test set: Avg. loss: 0.3507, Accuracy: 8948/10000 (89%)\n",
      "\n",
      "Train Epoch: 175 [0/60000 (0%)]\tLoss: 0.393601\n",
      "\n",
      "Test set: Avg. loss: 0.3112, Accuracy: 9066/10000 (91%)\n",
      "\n",
      "Train Epoch: 176 [0/60000 (0%)]\tLoss: 0.268294\n",
      "\n",
      "Test set: Avg. loss: 0.3995, Accuracy: 8753/10000 (88%)\n",
      "\n",
      "Train Epoch: 177 [0/60000 (0%)]\tLoss: 0.420527\n",
      "\n",
      "Test set: Avg. loss: 0.3284, Accuracy: 9015/10000 (90%)\n",
      "\n",
      "Train Epoch: 178 [0/60000 (0%)]\tLoss: 0.207073\n",
      "\n",
      "Test set: Avg. loss: 0.3613, Accuracy: 8925/10000 (89%)\n",
      "\n",
      "Train Epoch: 179 [0/60000 (0%)]\tLoss: 0.566177\n",
      "\n",
      "Test set: Avg. loss: 0.3367, Accuracy: 9011/10000 (90%)\n",
      "\n",
      "Train Epoch: 180 [0/60000 (0%)]\tLoss: 0.324592\n",
      "\n",
      "Test set: Avg. loss: 0.3008, Accuracy: 9112/10000 (91%)\n",
      "\n",
      "Train Epoch: 181 [0/60000 (0%)]\tLoss: 0.127667\n",
      "\n",
      "Test set: Avg. loss: 0.2969, Accuracy: 9138/10000 (91%)\n",
      "\n",
      "Train Epoch: 182 [0/60000 (0%)]\tLoss: 0.224043\n",
      "\n",
      "Test set: Avg. loss: 0.3602, Accuracy: 8930/10000 (89%)\n",
      "\n",
      "Train Epoch: 183 [0/60000 (0%)]\tLoss: 0.280415\n",
      "\n",
      "Test set: Avg. loss: 0.3114, Accuracy: 9088/10000 (91%)\n",
      "\n",
      "Train Epoch: 184 [0/60000 (0%)]\tLoss: 0.636955\n",
      "\n",
      "Test set: Avg. loss: 0.5793, Accuracy: 8153/10000 (82%)\n",
      "\n",
      "Train Epoch: 185 [0/60000 (0%)]\tLoss: 0.744827\n",
      "\n",
      "Test set: Avg. loss: 0.3548, Accuracy: 8921/10000 (89%)\n",
      "\n",
      "Train Epoch: 186 [0/60000 (0%)]\tLoss: 0.262280\n",
      "\n",
      "Test set: Avg. loss: 0.4620, Accuracy: 8584/10000 (86%)\n",
      "\n",
      "Train Epoch: 187 [0/60000 (0%)]\tLoss: 0.402493\n",
      "\n",
      "Test set: Avg. loss: 0.3279, Accuracy: 9034/10000 (90%)\n",
      "\n",
      "Train Epoch: 188 [0/60000 (0%)]\tLoss: 0.472472\n",
      "\n",
      "Test set: Avg. loss: 0.3175, Accuracy: 9005/10000 (90%)\n",
      "\n",
      "Train Epoch: 189 [0/60000 (0%)]\tLoss: 0.317169\n",
      "\n",
      "Test set: Avg. loss: 0.3494, Accuracy: 8902/10000 (89%)\n",
      "\n",
      "Train Epoch: 190 [0/60000 (0%)]\tLoss: 0.181922\n",
      "\n",
      "Test set: Avg. loss: 0.3149, Accuracy: 9040/10000 (90%)\n",
      "\n",
      "Train Epoch: 191 [0/60000 (0%)]\tLoss: 0.432188\n",
      "\n",
      "Test set: Avg. loss: 0.3235, Accuracy: 8998/10000 (90%)\n",
      "\n",
      "Train Epoch: 192 [0/60000 (0%)]\tLoss: 0.446630\n",
      "\n",
      "Test set: Avg. loss: 0.3868, Accuracy: 8803/10000 (88%)\n",
      "\n",
      "Train Epoch: 193 [0/60000 (0%)]\tLoss: 0.517289\n",
      "\n",
      "Test set: Avg. loss: 0.3144, Accuracy: 9048/10000 (90%)\n",
      "\n",
      "Train Epoch: 194 [0/60000 (0%)]\tLoss: 0.353327\n",
      "\n",
      "Test set: Avg. loss: 0.3451, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 195 [0/60000 (0%)]\tLoss: 0.225050\n",
      "\n",
      "Test set: Avg. loss: 0.3213, Accuracy: 9056/10000 (91%)\n",
      "\n",
      "Train Epoch: 196 [0/60000 (0%)]\tLoss: 0.448787\n",
      "\n",
      "Test set: Avg. loss: 0.4037, Accuracy: 8820/10000 (88%)\n",
      "\n",
      "Train Epoch: 197 [0/60000 (0%)]\tLoss: 0.604269\n",
      "\n",
      "Test set: Avg. loss: 0.4095, Accuracy: 8775/10000 (88%)\n",
      "\n",
      "Train Epoch: 198 [0/60000 (0%)]\tLoss: 0.447434\n",
      "\n",
      "Test set: Avg. loss: 0.3519, Accuracy: 8956/10000 (90%)\n",
      "\n",
      "Train Epoch: 199 [0/60000 (0%)]\tLoss: 0.425376\n",
      "\n",
      "Test set: Avg. loss: 0.3558, Accuracy: 8893/10000 (89%)\n",
      "\n",
      "Train Epoch: 200 [0/60000 (0%)]\tLoss: 0.346775\n",
      "\n",
      "Test set: Avg. loss: 0.5498, Accuracy: 8345/10000 (83%)\n",
      "\n",
      "Train Epoch: 201 [0/60000 (0%)]\tLoss: 0.411903\n",
      "\n",
      "Test set: Avg. loss: 0.3069, Accuracy: 9081/10000 (91%)\n",
      "\n",
      "Train Epoch: 202 [0/60000 (0%)]\tLoss: 0.372748\n",
      "\n",
      "Test set: Avg. loss: 0.3380, Accuracy: 8945/10000 (89%)\n",
      "\n",
      "Train Epoch: 203 [0/60000 (0%)]\tLoss: 0.221758\n",
      "\n",
      "Test set: Avg. loss: 0.3908, Accuracy: 8762/10000 (88%)\n",
      "\n",
      "Train Epoch: 204 [0/60000 (0%)]\tLoss: 0.381099\n",
      "\n",
      "Test set: Avg. loss: 0.3207, Accuracy: 9038/10000 (90%)\n",
      "\n",
      "Train Epoch: 205 [0/60000 (0%)]\tLoss: 0.138018\n",
      "\n",
      "Test set: Avg. loss: 0.4258, Accuracy: 8724/10000 (87%)\n",
      "\n",
      "Train Epoch: 206 [0/60000 (0%)]\tLoss: 0.514151\n",
      "\n",
      "Test set: Avg. loss: 0.3183, Accuracy: 9072/10000 (91%)\n",
      "\n",
      "Train Epoch: 207 [0/60000 (0%)]\tLoss: 0.284603\n",
      "\n",
      "Test set: Avg. loss: 0.4033, Accuracy: 8770/10000 (88%)\n",
      "\n",
      "Train Epoch: 208 [0/60000 (0%)]\tLoss: 0.710354\n",
      "\n",
      "Test set: Avg. loss: 0.3230, Accuracy: 9068/10000 (91%)\n",
      "\n",
      "Train Epoch: 209 [0/60000 (0%)]\tLoss: 0.244615\n",
      "\n",
      "Test set: Avg. loss: 0.3416, Accuracy: 8963/10000 (90%)\n",
      "\n",
      "Train Epoch: 210 [0/60000 (0%)]\tLoss: 0.367445\n",
      "\n",
      "Test set: Avg. loss: 0.3538, Accuracy: 8944/10000 (89%)\n",
      "\n",
      "Train Epoch: 211 [0/60000 (0%)]\tLoss: 0.334978\n",
      "\n",
      "Test set: Avg. loss: 0.3044, Accuracy: 9090/10000 (91%)\n",
      "\n",
      "Train Epoch: 212 [0/60000 (0%)]\tLoss: 0.291920\n",
      "\n",
      "Test set: Avg. loss: 0.2969, Accuracy: 9140/10000 (91%)\n",
      "\n",
      "Train Epoch: 213 [0/60000 (0%)]\tLoss: 0.279091\n",
      "\n",
      "Test set: Avg. loss: 0.3121, Accuracy: 9072/10000 (91%)\n",
      "\n",
      "Train Epoch: 214 [0/60000 (0%)]\tLoss: 0.603966\n",
      "\n",
      "Test set: Avg. loss: 0.3163, Accuracy: 9058/10000 (91%)\n",
      "\n",
      "Train Epoch: 215 [0/60000 (0%)]\tLoss: 0.332097\n",
      "\n",
      "Test set: Avg. loss: 0.4402, Accuracy: 8670/10000 (87%)\n",
      "\n",
      "Train Epoch: 216 [0/60000 (0%)]\tLoss: 0.358496\n",
      "\n",
      "Test set: Avg. loss: 0.3311, Accuracy: 8957/10000 (90%)\n",
      "\n",
      "Train Epoch: 217 [0/60000 (0%)]\tLoss: 0.331463\n",
      "\n",
      "Test set: Avg. loss: 0.3017, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 218 [0/60000 (0%)]\tLoss: 0.216318\n",
      "\n",
      "Test set: Avg. loss: 0.3111, Accuracy: 9073/10000 (91%)\n",
      "\n",
      "Train Epoch: 219 [0/60000 (0%)]\tLoss: 0.257209\n",
      "\n",
      "Test set: Avg. loss: 0.3146, Accuracy: 9065/10000 (91%)\n",
      "\n",
      "Train Epoch: 220 [0/60000 (0%)]\tLoss: 0.385008\n",
      "\n",
      "Test set: Avg. loss: 0.2744, Accuracy: 9198/10000 (92%)\n",
      "\n",
      "Train Epoch: 221 [0/60000 (0%)]\tLoss: 0.408832\n",
      "\n",
      "Test set: Avg. loss: 0.3124, Accuracy: 9065/10000 (91%)\n",
      "\n",
      "Train Epoch: 222 [0/60000 (0%)]\tLoss: 0.467957\n",
      "\n",
      "Test set: Avg. loss: 0.3021, Accuracy: 9065/10000 (91%)\n",
      "\n",
      "Train Epoch: 223 [0/60000 (0%)]\tLoss: 0.347680\n",
      "\n",
      "Test set: Avg. loss: 0.3474, Accuracy: 8926/10000 (89%)\n",
      "\n",
      "Train Epoch: 224 [0/60000 (0%)]\tLoss: 0.261291\n",
      "\n",
      "Test set: Avg. loss: 0.3912, Accuracy: 8801/10000 (88%)\n",
      "\n",
      "Train Epoch: 225 [0/60000 (0%)]\tLoss: 0.605496\n",
      "\n",
      "Test set: Avg. loss: 0.3510, Accuracy: 8918/10000 (89%)\n",
      "\n",
      "Train Epoch: 226 [0/60000 (0%)]\tLoss: 0.216959\n",
      "\n",
      "Test set: Avg. loss: 0.3271, Accuracy: 9032/10000 (90%)\n",
      "\n",
      "Train Epoch: 227 [0/60000 (0%)]\tLoss: 0.165653\n",
      "\n",
      "Test set: Avg. loss: 0.3300, Accuracy: 9035/10000 (90%)\n",
      "\n",
      "Train Epoch: 228 [0/60000 (0%)]\tLoss: 0.448183\n",
      "\n",
      "Test set: Avg. loss: 0.3685, Accuracy: 8858/10000 (89%)\n",
      "\n",
      "Train Epoch: 229 [0/60000 (0%)]\tLoss: 0.154757\n",
      "\n",
      "Test set: Avg. loss: 0.3926, Accuracy: 8771/10000 (88%)\n",
      "\n",
      "Train Epoch: 230 [0/60000 (0%)]\tLoss: 0.368487\n",
      "\n",
      "Test set: Avg. loss: 0.2889, Accuracy: 9132/10000 (91%)\n",
      "\n",
      "Train Epoch: 231 [0/60000 (0%)]\tLoss: 0.442920\n",
      "\n",
      "Test set: Avg. loss: 0.3962, Accuracy: 8775/10000 (88%)\n",
      "\n",
      "Train Epoch: 232 [0/60000 (0%)]\tLoss: 0.501054\n",
      "\n",
      "Test set: Avg. loss: 0.3508, Accuracy: 8916/10000 (89%)\n",
      "\n",
      "Train Epoch: 233 [0/60000 (0%)]\tLoss: 0.380983\n",
      "\n",
      "Test set: Avg. loss: 0.3127, Accuracy: 9051/10000 (91%)\n",
      "\n",
      "Train Epoch: 234 [0/60000 (0%)]\tLoss: 0.344963\n",
      "\n",
      "Test set: Avg. loss: 0.2906, Accuracy: 9153/10000 (92%)\n",
      "\n",
      "Train Epoch: 235 [0/60000 (0%)]\tLoss: 0.243356\n",
      "\n",
      "Test set: Avg. loss: 0.3362, Accuracy: 9003/10000 (90%)\n",
      "\n",
      "Train Epoch: 236 [0/60000 (0%)]\tLoss: 0.189272\n",
      "\n",
      "Test set: Avg. loss: 0.3793, Accuracy: 8865/10000 (89%)\n",
      "\n",
      "Train Epoch: 237 [0/60000 (0%)]\tLoss: 0.267195\n",
      "\n",
      "Test set: Avg. loss: 0.3443, Accuracy: 8931/10000 (89%)\n",
      "\n",
      "Train Epoch: 238 [0/60000 (0%)]\tLoss: 0.264777\n",
      "\n",
      "Test set: Avg. loss: 0.4178, Accuracy: 8743/10000 (87%)\n",
      "\n",
      "Train Epoch: 239 [0/60000 (0%)]\tLoss: 0.474054\n",
      "\n",
      "Test set: Avg. loss: 0.4011, Accuracy: 8800/10000 (88%)\n",
      "\n",
      "Train Epoch: 240 [0/60000 (0%)]\tLoss: 0.296130\n",
      "\n",
      "Test set: Avg. loss: 0.3735, Accuracy: 8827/10000 (88%)\n",
      "\n",
      "Train Epoch: 241 [0/60000 (0%)]\tLoss: 0.310817\n",
      "\n",
      "Test set: Avg. loss: 0.3653, Accuracy: 8888/10000 (89%)\n",
      "\n",
      "Train Epoch: 242 [0/60000 (0%)]\tLoss: 0.545754\n",
      "\n",
      "Test set: Avg. loss: 0.3821, Accuracy: 8847/10000 (88%)\n",
      "\n",
      "Train Epoch: 243 [0/60000 (0%)]\tLoss: 0.413918\n",
      "\n",
      "Test set: Avg. loss: 0.2869, Accuracy: 9146/10000 (91%)\n",
      "\n",
      "Train Epoch: 244 [0/60000 (0%)]\tLoss: 0.224993\n",
      "\n",
      "Test set: Avg. loss: 0.2987, Accuracy: 9096/10000 (91%)\n",
      "\n",
      "Train Epoch: 245 [0/60000 (0%)]\tLoss: 0.293327\n",
      "\n",
      "Test set: Avg. loss: 0.3874, Accuracy: 8801/10000 (88%)\n",
      "\n",
      "Train Epoch: 246 [0/60000 (0%)]\tLoss: 0.438327\n",
      "\n",
      "Test set: Avg. loss: 0.2775, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Train Epoch: 247 [0/60000 (0%)]\tLoss: 0.326215\n",
      "\n",
      "Test set: Avg. loss: 0.3060, Accuracy: 9091/10000 (91%)\n",
      "\n",
      "Train Epoch: 248 [0/60000 (0%)]\tLoss: 0.208646\n",
      "\n",
      "Test set: Avg. loss: 0.3229, Accuracy: 9074/10000 (91%)\n",
      "\n",
      "Train Epoch: 249 [0/60000 (0%)]\tLoss: 0.192248\n",
      "\n",
      "Test set: Avg. loss: 0.2775, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Train Epoch: 250 [0/60000 (0%)]\tLoss: 0.182857\n",
      "\n",
      "Test set: Avg. loss: 0.2782, Accuracy: 9184/10000 (92%)\n",
      "\n",
      "Train Epoch: 251 [0/60000 (0%)]\tLoss: 0.195787\n",
      "\n",
      "Test set: Avg. loss: 0.2784, Accuracy: 9163/10000 (92%)\n",
      "\n",
      "Train Epoch: 252 [0/60000 (0%)]\tLoss: 0.393296\n",
      "\n",
      "Test set: Avg. loss: 0.2832, Accuracy: 9187/10000 (92%)\n",
      "\n",
      "Train Epoch: 253 [0/60000 (0%)]\tLoss: 0.229370\n",
      "\n",
      "Test set: Avg. loss: 0.2790, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Train Epoch: 254 [0/60000 (0%)]\tLoss: 0.206624\n",
      "\n",
      "Test set: Avg. loss: 0.2968, Accuracy: 9119/10000 (91%)\n",
      "\n",
      "Train Epoch: 255 [0/60000 (0%)]\tLoss: 0.270897\n",
      "\n",
      "Test set: Avg. loss: 0.2837, Accuracy: 9164/10000 (92%)\n",
      "\n",
      "Train Epoch: 256 [0/60000 (0%)]\tLoss: 0.214801\n",
      "\n",
      "Test set: Avg. loss: 0.2865, Accuracy: 9155/10000 (92%)\n",
      "\n",
      "Train Epoch: 257 [0/60000 (0%)]\tLoss: 0.188140\n",
      "\n",
      "Test set: Avg. loss: 0.2895, Accuracy: 9121/10000 (91%)\n",
      "\n",
      "Train Epoch: 258 [0/60000 (0%)]\tLoss: 0.324234\n",
      "\n",
      "Test set: Avg. loss: 0.2803, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Train Epoch: 259 [0/60000 (0%)]\tLoss: 0.325490\n",
      "\n",
      "Test set: Avg. loss: 0.3566, Accuracy: 8919/10000 (89%)\n",
      "\n",
      "Train Epoch: 260 [0/60000 (0%)]\tLoss: 0.363182\n",
      "\n",
      "Test set: Avg. loss: 0.3073, Accuracy: 9068/10000 (91%)\n",
      "\n",
      "Train Epoch: 261 [0/60000 (0%)]\tLoss: 0.215141\n",
      "\n",
      "Test set: Avg. loss: 0.3023, Accuracy: 9136/10000 (91%)\n",
      "\n",
      "Train Epoch: 262 [0/60000 (0%)]\tLoss: 0.204503\n",
      "\n",
      "Test set: Avg. loss: 0.2827, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Train Epoch: 263 [0/60000 (0%)]\tLoss: 0.227831\n",
      "\n",
      "Test set: Avg. loss: 0.3182, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 264 [0/60000 (0%)]\tLoss: 0.162842\n",
      "\n",
      "Test set: Avg. loss: 0.3550, Accuracy: 8943/10000 (89%)\n",
      "\n",
      "Train Epoch: 265 [0/60000 (0%)]\tLoss: 0.287049\n",
      "\n",
      "Test set: Avg. loss: 0.3493, Accuracy: 8998/10000 (90%)\n",
      "\n",
      "Train Epoch: 266 [0/60000 (0%)]\tLoss: 0.594143\n",
      "\n",
      "Test set: Avg. loss: 0.3277, Accuracy: 9037/10000 (90%)\n",
      "\n",
      "Train Epoch: 267 [0/60000 (0%)]\tLoss: 0.356429\n",
      "\n",
      "Test set: Avg. loss: 0.3261, Accuracy: 9032/10000 (90%)\n",
      "\n",
      "Train Epoch: 268 [0/60000 (0%)]\tLoss: 0.471944\n",
      "\n",
      "Test set: Avg. loss: 0.2928, Accuracy: 9178/10000 (92%)\n",
      "\n",
      "Train Epoch: 269 [0/60000 (0%)]\tLoss: 0.298543\n",
      "\n",
      "Test set: Avg. loss: 0.3412, Accuracy: 9014/10000 (90%)\n",
      "\n",
      "Train Epoch: 270 [0/60000 (0%)]\tLoss: 0.435963\n",
      "\n",
      "Test set: Avg. loss: 0.3653, Accuracy: 8933/10000 (89%)\n",
      "\n",
      "Train Epoch: 271 [0/60000 (0%)]\tLoss: 0.419285\n",
      "\n",
      "Test set: Avg. loss: 0.3626, Accuracy: 8918/10000 (89%)\n",
      "\n",
      "Train Epoch: 272 [0/60000 (0%)]\tLoss: 0.358076\n",
      "\n",
      "Test set: Avg. loss: 0.2947, Accuracy: 9124/10000 (91%)\n",
      "\n",
      "Train Epoch: 273 [0/60000 (0%)]\tLoss: 0.278580\n",
      "\n",
      "Test set: Avg. loss: 0.2756, Accuracy: 9178/10000 (92%)\n",
      "\n",
      "Train Epoch: 274 [0/60000 (0%)]\tLoss: 0.459857\n",
      "\n",
      "Test set: Avg. loss: 0.3222, Accuracy: 9009/10000 (90%)\n",
      "\n",
      "Train Epoch: 275 [0/60000 (0%)]\tLoss: 0.422925\n",
      "\n",
      "Test set: Avg. loss: 0.2867, Accuracy: 9138/10000 (91%)\n",
      "\n",
      "Train Epoch: 276 [0/60000 (0%)]\tLoss: 0.124564\n",
      "\n",
      "Test set: Avg. loss: 0.2945, Accuracy: 9146/10000 (91%)\n",
      "\n",
      "Train Epoch: 277 [0/60000 (0%)]\tLoss: 0.152983\n",
      "\n",
      "Test set: Avg. loss: 0.3044, Accuracy: 9092/10000 (91%)\n",
      "\n",
      "Train Epoch: 278 [0/60000 (0%)]\tLoss: 0.486979\n",
      "\n",
      "Test set: Avg. loss: 0.3704, Accuracy: 8880/10000 (89%)\n",
      "\n",
      "Train Epoch: 279 [0/60000 (0%)]\tLoss: 0.335946\n",
      "\n",
      "Test set: Avg. loss: 0.2851, Accuracy: 9171/10000 (92%)\n",
      "\n",
      "Train Epoch: 280 [0/60000 (0%)]\tLoss: 0.444218\n",
      "\n",
      "Test set: Avg. loss: 0.3022, Accuracy: 9134/10000 (91%)\n",
      "\n",
      "Train Epoch: 281 [0/60000 (0%)]\tLoss: 0.192938\n",
      "\n",
      "Test set: Avg. loss: 0.3223, Accuracy: 9043/10000 (90%)\n",
      "\n",
      "Train Epoch: 282 [0/60000 (0%)]\tLoss: 0.340862\n",
      "\n",
      "Test set: Avg. loss: 0.2635, Accuracy: 9212/10000 (92%)\n",
      "\n",
      "Train Epoch: 283 [0/60000 (0%)]\tLoss: 0.189491\n",
      "\n",
      "Test set: Avg. loss: 0.2817, Accuracy: 9167/10000 (92%)\n",
      "\n",
      "Train Epoch: 284 [0/60000 (0%)]\tLoss: 0.397837\n",
      "\n",
      "Test set: Avg. loss: 0.2949, Accuracy: 9119/10000 (91%)\n",
      "\n",
      "Train Epoch: 285 [0/60000 (0%)]\tLoss: 0.285687\n",
      "\n",
      "Test set: Avg. loss: 0.2617, Accuracy: 9224/10000 (92%)\n",
      "\n",
      "Train Epoch: 286 [0/60000 (0%)]\tLoss: 0.350657\n",
      "\n",
      "Test set: Avg. loss: 0.3490, Accuracy: 8988/10000 (90%)\n",
      "\n",
      "Train Epoch: 287 [0/60000 (0%)]\tLoss: 0.386584\n",
      "\n",
      "Test set: Avg. loss: 0.3322, Accuracy: 9045/10000 (90%)\n",
      "\n",
      "Train Epoch: 288 [0/60000 (0%)]\tLoss: 0.262427\n",
      "\n",
      "Test set: Avg. loss: 0.2862, Accuracy: 9158/10000 (92%)\n",
      "\n",
      "Train Epoch: 289 [0/60000 (0%)]\tLoss: 0.103215\n",
      "\n",
      "Test set: Avg. loss: 0.2825, Accuracy: 9163/10000 (92%)\n",
      "\n",
      "Train Epoch: 290 [0/60000 (0%)]\tLoss: 0.164198\n",
      "\n",
      "Test set: Avg. loss: 0.2612, Accuracy: 9249/10000 (92%)\n",
      "\n",
      "Train Epoch: 291 [0/60000 (0%)]\tLoss: 0.391348\n",
      "\n",
      "Test set: Avg. loss: 0.3598, Accuracy: 8889/10000 (89%)\n",
      "\n",
      "Train Epoch: 292 [0/60000 (0%)]\tLoss: 0.242848\n",
      "\n",
      "Test set: Avg. loss: 0.3797, Accuracy: 8792/10000 (88%)\n",
      "\n",
      "Train Epoch: 293 [0/60000 (0%)]\tLoss: 0.465605\n",
      "\n",
      "Test set: Avg. loss: 0.2972, Accuracy: 9096/10000 (91%)\n",
      "\n",
      "Train Epoch: 294 [0/60000 (0%)]\tLoss: 0.375873\n",
      "\n",
      "Test set: Avg. loss: 0.2790, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Train Epoch: 295 [0/60000 (0%)]\tLoss: 0.172853\n",
      "\n",
      "Test set: Avg. loss: 0.3592, Accuracy: 8966/10000 (90%)\n",
      "\n",
      "Train Epoch: 296 [0/60000 (0%)]\tLoss: 0.344891\n",
      "\n",
      "Test set: Avg. loss: 0.3060, Accuracy: 9118/10000 (91%)\n",
      "\n",
      "Train Epoch: 297 [0/60000 (0%)]\tLoss: 0.384552\n",
      "\n",
      "Test set: Avg. loss: 0.2888, Accuracy: 9145/10000 (91%)\n",
      "\n",
      "Train Epoch: 298 [0/60000 (0%)]\tLoss: 0.284395\n",
      "\n",
      "Test set: Avg. loss: 0.3445, Accuracy: 8938/10000 (89%)\n",
      "\n",
      "Train Epoch: 299 [0/60000 (0%)]\tLoss: 0.153280\n",
      "\n",
      "Test set: Avg. loss: 0.3214, Accuracy: 9033/10000 (90%)\n",
      "\n",
      "Train Epoch: 300 [0/60000 (0%)]\tLoss: 0.576045\n",
      "\n",
      "Test set: Avg. loss: 0.3028, Accuracy: 9088/10000 (91%)\n",
      "\n",
      "Train Epoch: 301 [0/60000 (0%)]\tLoss: 0.128981\n",
      "\n",
      "Test set: Avg. loss: 0.3215, Accuracy: 9050/10000 (90%)\n",
      "\n",
      "Train Epoch: 302 [0/60000 (0%)]\tLoss: 0.259341\n",
      "\n",
      "Test set: Avg. loss: 0.3026, Accuracy: 9105/10000 (91%)\n",
      "\n",
      "Train Epoch: 303 [0/60000 (0%)]\tLoss: 0.455476\n",
      "\n",
      "Test set: Avg. loss: 0.2834, Accuracy: 9117/10000 (91%)\n",
      "\n",
      "Train Epoch: 304 [0/60000 (0%)]\tLoss: 0.300173\n",
      "\n",
      "Test set: Avg. loss: 0.3175, Accuracy: 9056/10000 (91%)\n",
      "\n",
      "Train Epoch: 305 [0/60000 (0%)]\tLoss: 0.195065\n",
      "\n",
      "Test set: Avg. loss: 0.3034, Accuracy: 9105/10000 (91%)\n",
      "\n",
      "Train Epoch: 306 [0/60000 (0%)]\tLoss: 0.210393\n",
      "\n",
      "Test set: Avg. loss: 0.2733, Accuracy: 9186/10000 (92%)\n",
      "\n",
      "Train Epoch: 307 [0/60000 (0%)]\tLoss: 0.249965\n",
      "\n",
      "Test set: Avg. loss: 0.2830, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Train Epoch: 308 [0/60000 (0%)]\tLoss: 0.452886\n",
      "\n",
      "Test set: Avg. loss: 0.2667, Accuracy: 9208/10000 (92%)\n",
      "\n",
      "Train Epoch: 309 [0/60000 (0%)]\tLoss: 0.246642\n",
      "\n",
      "Test set: Avg. loss: 0.3057, Accuracy: 9057/10000 (91%)\n",
      "\n",
      "Train Epoch: 310 [0/60000 (0%)]\tLoss: 0.242906\n",
      "\n",
      "Test set: Avg. loss: 0.2663, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Train Epoch: 311 [0/60000 (0%)]\tLoss: 0.207625\n",
      "\n",
      "Test set: Avg. loss: 0.2974, Accuracy: 9122/10000 (91%)\n",
      "\n",
      "Train Epoch: 312 [0/60000 (0%)]\tLoss: 0.266855\n",
      "\n",
      "Test set: Avg. loss: 0.2527, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "Train Epoch: 313 [0/60000 (0%)]\tLoss: 0.272698\n",
      "\n",
      "Test set: Avg. loss: 0.2792, Accuracy: 9185/10000 (92%)\n",
      "\n",
      "Train Epoch: 314 [0/60000 (0%)]\tLoss: 0.142041\n",
      "\n",
      "Test set: Avg. loss: 0.2992, Accuracy: 9093/10000 (91%)\n",
      "\n",
      "Train Epoch: 315 [0/60000 (0%)]\tLoss: 0.246639\n",
      "\n",
      "Test set: Avg. loss: 0.2894, Accuracy: 9123/10000 (91%)\n",
      "\n",
      "Train Epoch: 316 [0/60000 (0%)]\tLoss: 0.376393\n",
      "\n",
      "Test set: Avg. loss: 0.2740, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "Train Epoch: 317 [0/60000 (0%)]\tLoss: 0.257429\n",
      "\n",
      "Test set: Avg. loss: 0.2706, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Train Epoch: 318 [0/60000 (0%)]\tLoss: 0.211472\n",
      "\n",
      "Test set: Avg. loss: 0.2682, Accuracy: 9216/10000 (92%)\n",
      "\n",
      "Train Epoch: 319 [0/60000 (0%)]\tLoss: 0.344234\n",
      "\n",
      "Test set: Avg. loss: 0.2664, Accuracy: 9198/10000 (92%)\n",
      "\n",
      "Train Epoch: 320 [0/60000 (0%)]\tLoss: 0.197711\n",
      "\n",
      "Test set: Avg. loss: 0.3050, Accuracy: 9083/10000 (91%)\n",
      "\n",
      "Train Epoch: 321 [0/60000 (0%)]\tLoss: 0.312049\n",
      "\n",
      "Test set: Avg. loss: 0.2469, Accuracy: 9267/10000 (93%)\n",
      "\n",
      "Train Epoch: 322 [0/60000 (0%)]\tLoss: 0.176836\n",
      "\n",
      "Test set: Avg. loss: 0.2584, Accuracy: 9233/10000 (92%)\n",
      "\n",
      "Train Epoch: 323 [0/60000 (0%)]\tLoss: 0.192265\n",
      "\n",
      "Test set: Avg. loss: 0.3032, Accuracy: 9089/10000 (91%)\n",
      "\n",
      "Train Epoch: 324 [0/60000 (0%)]\tLoss: 0.272169\n",
      "\n",
      "Test set: Avg. loss: 0.2797, Accuracy: 9166/10000 (92%)\n",
      "\n",
      "Train Epoch: 325 [0/60000 (0%)]\tLoss: 0.371712\n",
      "\n",
      "Test set: Avg. loss: 0.2500, Accuracy: 9265/10000 (93%)\n",
      "\n",
      "Train Epoch: 326 [0/60000 (0%)]\tLoss: 0.365750\n",
      "\n",
      "Test set: Avg. loss: 0.2812, Accuracy: 9173/10000 (92%)\n",
      "\n",
      "Train Epoch: 327 [0/60000 (0%)]\tLoss: 0.190935\n",
      "\n",
      "Test set: Avg. loss: 0.3429, Accuracy: 8978/10000 (90%)\n",
      "\n",
      "Train Epoch: 328 [0/60000 (0%)]\tLoss: 0.303626\n",
      "\n",
      "Test set: Avg. loss: 0.2834, Accuracy: 9142/10000 (91%)\n",
      "\n",
      "Train Epoch: 329 [0/60000 (0%)]\tLoss: 0.233785\n",
      "\n",
      "Test set: Avg. loss: 0.2804, Accuracy: 9148/10000 (91%)\n",
      "\n",
      "Train Epoch: 330 [0/60000 (0%)]\tLoss: 0.211374\n",
      "\n",
      "Test set: Avg. loss: 0.3116, Accuracy: 9049/10000 (90%)\n",
      "\n",
      "Train Epoch: 331 [0/60000 (0%)]\tLoss: 0.193956\n",
      "\n",
      "Test set: Avg. loss: 0.3409, Accuracy: 8914/10000 (89%)\n",
      "\n",
      "Train Epoch: 332 [0/60000 (0%)]\tLoss: 0.377968\n",
      "\n",
      "Test set: Avg. loss: 0.3279, Accuracy: 8970/10000 (90%)\n",
      "\n",
      "Train Epoch: 333 [0/60000 (0%)]\tLoss: 0.382598\n",
      "\n",
      "Test set: Avg. loss: 0.2485, Accuracy: 9261/10000 (93%)\n",
      "\n",
      "Train Epoch: 334 [0/60000 (0%)]\tLoss: 0.217176\n",
      "\n",
      "Test set: Avg. loss: 0.2499, Accuracy: 9254/10000 (93%)\n",
      "\n",
      "Train Epoch: 335 [0/60000 (0%)]\tLoss: 0.151737\n",
      "\n",
      "Test set: Avg. loss: 0.2541, Accuracy: 9221/10000 (92%)\n",
      "\n",
      "Train Epoch: 336 [0/60000 (0%)]\tLoss: 0.244125\n",
      "\n",
      "Test set: Avg. loss: 0.2580, Accuracy: 9222/10000 (92%)\n",
      "\n",
      "Train Epoch: 337 [0/60000 (0%)]\tLoss: 0.206601\n",
      "\n",
      "Test set: Avg. loss: 0.2583, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "Train Epoch: 338 [0/60000 (0%)]\tLoss: 0.276227\n",
      "\n",
      "Test set: Avg. loss: 0.2664, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Train Epoch: 339 [0/60000 (0%)]\tLoss: 0.303859\n",
      "\n",
      "Test set: Avg. loss: 0.2493, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "Train Epoch: 340 [0/60000 (0%)]\tLoss: 0.241827\n",
      "\n",
      "Test set: Avg. loss: 0.2502, Accuracy: 9262/10000 (93%)\n",
      "\n",
      "Train Epoch: 341 [0/60000 (0%)]\tLoss: 0.229868\n",
      "\n",
      "Test set: Avg. loss: 0.2671, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Train Epoch: 342 [0/60000 (0%)]\tLoss: 0.294983\n",
      "\n",
      "Test set: Avg. loss: 0.2554, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "Train Epoch: 343 [0/60000 (0%)]\tLoss: 0.290417\n",
      "\n",
      "Test set: Avg. loss: 0.3152, Accuracy: 9014/10000 (90%)\n",
      "\n",
      "Train Epoch: 344 [0/60000 (0%)]\tLoss: 0.386900\n",
      "\n",
      "Test set: Avg. loss: 0.2785, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Train Epoch: 345 [0/60000 (0%)]\tLoss: 0.290636\n",
      "\n",
      "Test set: Avg. loss: 0.3344, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 346 [0/60000 (0%)]\tLoss: 0.330979\n",
      "\n",
      "Test set: Avg. loss: 0.2472, Accuracy: 9281/10000 (93%)\n",
      "\n",
      "Train Epoch: 347 [0/60000 (0%)]\tLoss: 0.202074\n",
      "\n",
      "Test set: Avg. loss: 0.2677, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Train Epoch: 348 [0/60000 (0%)]\tLoss: 0.180366\n",
      "\n",
      "Test set: Avg. loss: 0.2464, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "Train Epoch: 349 [0/60000 (0%)]\tLoss: 0.440428\n",
      "\n",
      "Test set: Avg. loss: 0.2687, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Train Epoch: 350 [0/60000 (0%)]\tLoss: 0.188315\n",
      "\n",
      "Test set: Avg. loss: 0.3261, Accuracy: 8992/10000 (90%)\n",
      "\n",
      "Train Epoch: 351 [0/60000 (0%)]\tLoss: 0.324801\n",
      "\n",
      "Test set: Avg. loss: 0.3630, Accuracy: 8906/10000 (89%)\n",
      "\n",
      "Train Epoch: 352 [0/60000 (0%)]\tLoss: 0.422632\n",
      "\n",
      "Test set: Avg. loss: 0.3463, Accuracy: 8946/10000 (89%)\n",
      "\n",
      "Train Epoch: 353 [0/60000 (0%)]\tLoss: 0.424388\n",
      "\n",
      "Test set: Avg. loss: 0.2873, Accuracy: 9118/10000 (91%)\n",
      "\n",
      "Train Epoch: 354 [0/60000 (0%)]\tLoss: 0.184579\n",
      "\n",
      "Test set: Avg. loss: 0.2986, Accuracy: 9087/10000 (91%)\n",
      "\n",
      "Train Epoch: 355 [0/60000 (0%)]\tLoss: 0.425484\n",
      "\n",
      "Test set: Avg. loss: 0.2857, Accuracy: 9151/10000 (92%)\n",
      "\n",
      "Train Epoch: 356 [0/60000 (0%)]\tLoss: 0.248282\n",
      "\n",
      "Test set: Avg. loss: 0.2929, Accuracy: 9084/10000 (91%)\n",
      "\n",
      "Train Epoch: 357 [0/60000 (0%)]\tLoss: 0.243579\n",
      "\n",
      "Test set: Avg. loss: 0.2836, Accuracy: 9132/10000 (91%)\n",
      "\n",
      "Train Epoch: 358 [0/60000 (0%)]\tLoss: 0.162022\n",
      "\n",
      "Test set: Avg. loss: 0.2749, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Train Epoch: 359 [0/60000 (0%)]\tLoss: 0.394629\n",
      "\n",
      "Test set: Avg. loss: 0.2742, Accuracy: 9180/10000 (92%)\n",
      "\n",
      "Train Epoch: 360 [0/60000 (0%)]\tLoss: 0.143921\n",
      "\n",
      "Test set: Avg. loss: 0.2613, Accuracy: 9239/10000 (92%)\n",
      "\n",
      "Train Epoch: 361 [0/60000 (0%)]\tLoss: 0.217134\n",
      "\n",
      "Test set: Avg. loss: 0.2497, Accuracy: 9265/10000 (93%)\n",
      "\n",
      "Train Epoch: 362 [0/60000 (0%)]\tLoss: 0.174896\n",
      "\n",
      "Test set: Avg. loss: 0.3053, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "Train Epoch: 363 [0/60000 (0%)]\tLoss: 0.316700\n",
      "\n",
      "Test set: Avg. loss: 0.2762, Accuracy: 9163/10000 (92%)\n",
      "\n",
      "Train Epoch: 364 [0/60000 (0%)]\tLoss: 0.482626\n",
      "\n",
      "Test set: Avg. loss: 0.2650, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Train Epoch: 365 [0/60000 (0%)]\tLoss: 0.195178\n",
      "\n",
      "Test set: Avg. loss: 0.2520, Accuracy: 9248/10000 (92%)\n",
      "\n",
      "Train Epoch: 366 [0/60000 (0%)]\tLoss: 0.196503\n",
      "\n",
      "Test set: Avg. loss: 0.2629, Accuracy: 9221/10000 (92%)\n",
      "\n",
      "Train Epoch: 367 [0/60000 (0%)]\tLoss: 0.276387\n",
      "\n",
      "Test set: Avg. loss: 0.3072, Accuracy: 9058/10000 (91%)\n",
      "\n",
      "Train Epoch: 368 [0/60000 (0%)]\tLoss: 0.185707\n",
      "\n",
      "Test set: Avg. loss: 0.3096, Accuracy: 9060/10000 (91%)\n",
      "\n",
      "Train Epoch: 369 [0/60000 (0%)]\tLoss: 0.270917\n",
      "\n",
      "Test set: Avg. loss: 0.2602, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Train Epoch: 370 [0/60000 (0%)]\tLoss: 0.428207\n",
      "\n",
      "Test set: Avg. loss: 0.2869, Accuracy: 9160/10000 (92%)\n",
      "\n",
      "Train Epoch: 371 [0/60000 (0%)]\tLoss: 0.381913\n",
      "\n",
      "Test set: Avg. loss: 0.2804, Accuracy: 9167/10000 (92%)\n",
      "\n",
      "Train Epoch: 372 [0/60000 (0%)]\tLoss: 0.193762\n",
      "\n",
      "Test set: Avg. loss: 0.2606, Accuracy: 9256/10000 (93%)\n",
      "\n",
      "Train Epoch: 373 [0/60000 (0%)]\tLoss: 0.105846\n",
      "\n",
      "Test set: Avg. loss: 0.2707, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Train Epoch: 374 [0/60000 (0%)]\tLoss: 0.263712\n",
      "\n",
      "Test set: Avg. loss: 0.2882, Accuracy: 9110/10000 (91%)\n",
      "\n",
      "Train Epoch: 375 [0/60000 (0%)]\tLoss: 0.214059\n",
      "\n",
      "Test set: Avg. loss: 0.2467, Accuracy: 9241/10000 (92%)\n",
      "\n",
      "Train Epoch: 376 [0/60000 (0%)]\tLoss: 0.305190\n",
      "\n",
      "Test set: Avg. loss: 0.2695, Accuracy: 9186/10000 (92%)\n",
      "\n",
      "Train Epoch: 377 [0/60000 (0%)]\tLoss: 0.355745\n",
      "\n",
      "Test set: Avg. loss: 0.2553, Accuracy: 9235/10000 (92%)\n",
      "\n",
      "Train Epoch: 378 [0/60000 (0%)]\tLoss: 0.172742\n",
      "\n",
      "Test set: Avg. loss: 0.3733, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 379 [0/60000 (0%)]\tLoss: 0.258830\n",
      "\n",
      "Test set: Avg. loss: 0.2429, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train Epoch: 380 [0/60000 (0%)]\tLoss: 0.177046\n",
      "\n",
      "Test set: Avg. loss: 0.2543, Accuracy: 9251/10000 (93%)\n",
      "\n",
      "Train Epoch: 381 [0/60000 (0%)]\tLoss: 0.232268\n",
      "\n",
      "Test set: Avg. loss: 0.2517, Accuracy: 9231/10000 (92%)\n",
      "\n",
      "Train Epoch: 382 [0/60000 (0%)]\tLoss: 0.167281\n",
      "\n",
      "Test set: Avg. loss: 0.3627, Accuracy: 8874/10000 (89%)\n",
      "\n",
      "Train Epoch: 383 [0/60000 (0%)]\tLoss: 0.470989\n",
      "\n",
      "Test set: Avg. loss: 0.2456, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "Train Epoch: 384 [0/60000 (0%)]\tLoss: 0.160799\n",
      "\n",
      "Test set: Avg. loss: 0.3172, Accuracy: 9010/10000 (90%)\n",
      "\n",
      "Train Epoch: 385 [0/60000 (0%)]\tLoss: 0.245227\n",
      "\n",
      "Test set: Avg. loss: 0.3028, Accuracy: 9104/10000 (91%)\n",
      "\n",
      "Train Epoch: 386 [0/60000 (0%)]\tLoss: 0.204926\n",
      "\n",
      "Test set: Avg. loss: 0.2558, Accuracy: 9243/10000 (92%)\n",
      "\n",
      "Train Epoch: 387 [0/60000 (0%)]\tLoss: 0.163138\n",
      "\n",
      "Test set: Avg. loss: 0.2827, Accuracy: 9156/10000 (92%)\n",
      "\n",
      "Train Epoch: 388 [0/60000 (0%)]\tLoss: 0.281187\n",
      "\n",
      "Test set: Avg. loss: 0.2696, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Train Epoch: 389 [0/60000 (0%)]\tLoss: 0.080481\n",
      "\n",
      "Test set: Avg. loss: 0.3582, Accuracy: 8865/10000 (89%)\n",
      "\n",
      "Train Epoch: 390 [0/60000 (0%)]\tLoss: 0.368136\n",
      "\n",
      "Test set: Avg. loss: 0.2712, Accuracy: 9216/10000 (92%)\n",
      "\n",
      "Train Epoch: 391 [0/60000 (0%)]\tLoss: 0.463082\n",
      "\n",
      "Test set: Avg. loss: 0.3068, Accuracy: 9091/10000 (91%)\n",
      "\n",
      "Train Epoch: 392 [0/60000 (0%)]\tLoss: 0.381365\n",
      "\n",
      "Test set: Avg. loss: 0.3124, Accuracy: 9064/10000 (91%)\n",
      "\n",
      "Train Epoch: 393 [0/60000 (0%)]\tLoss: 0.357093\n",
      "\n",
      "Test set: Avg. loss: 0.3014, Accuracy: 9109/10000 (91%)\n",
      "\n",
      "Train Epoch: 394 [0/60000 (0%)]\tLoss: 0.324408\n",
      "\n",
      "Test set: Avg. loss: 0.2876, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Train Epoch: 395 [0/60000 (0%)]\tLoss: 0.248469\n",
      "\n",
      "Test set: Avg. loss: 0.2820, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Train Epoch: 396 [0/60000 (0%)]\tLoss: 0.332772\n",
      "\n",
      "Test set: Avg. loss: 0.2718, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Train Epoch: 397 [0/60000 (0%)]\tLoss: 0.211660\n",
      "\n",
      "Test set: Avg. loss: 0.2816, Accuracy: 9142/10000 (91%)\n",
      "\n",
      "Train Epoch: 398 [0/60000 (0%)]\tLoss: 0.412545\n",
      "\n",
      "Test set: Avg. loss: 0.2443, Accuracy: 9275/10000 (93%)\n",
      "\n",
      "Train Epoch: 399 [0/60000 (0%)]\tLoss: 0.315770\n",
      "\n",
      "Test set: Avg. loss: 0.2753, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Train Epoch: 400 [0/60000 (0%)]\tLoss: 0.305765\n",
      "\n",
      "Test set: Avg. loss: 0.3140, Accuracy: 9086/10000 (91%)\n",
      "\n",
      "Train Epoch: 401 [0/60000 (0%)]\tLoss: 0.175083\n",
      "\n",
      "Test set: Avg. loss: 0.2774, Accuracy: 9189/10000 (92%)\n",
      "\n",
      "Train Epoch: 402 [0/60000 (0%)]\tLoss: 0.266212\n",
      "\n",
      "Test set: Avg. loss: 0.2349, Accuracy: 9318/10000 (93%)\n",
      "\n",
      "Train Epoch: 403 [0/60000 (0%)]\tLoss: 0.347068\n",
      "\n",
      "Test set: Avg. loss: 0.2811, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "Train Epoch: 404 [0/60000 (0%)]\tLoss: 0.184134\n",
      "\n",
      "Test set: Avg. loss: 0.2528, Accuracy: 9268/10000 (93%)\n",
      "\n",
      "Train Epoch: 405 [0/60000 (0%)]\tLoss: 0.285585\n",
      "\n",
      "Test set: Avg. loss: 0.2558, Accuracy: 9249/10000 (92%)\n",
      "\n",
      "Train Epoch: 406 [0/60000 (0%)]\tLoss: 0.282894\n",
      "\n",
      "Test set: Avg. loss: 0.2531, Accuracy: 9241/10000 (92%)\n",
      "\n",
      "Train Epoch: 407 [0/60000 (0%)]\tLoss: 0.206704\n",
      "\n",
      "Test set: Avg. loss: 0.3124, Accuracy: 9040/10000 (90%)\n",
      "\n",
      "Train Epoch: 408 [0/60000 (0%)]\tLoss: 0.373906\n",
      "\n",
      "Test set: Avg. loss: 0.2533, Accuracy: 9260/10000 (93%)\n",
      "\n",
      "Train Epoch: 409 [0/60000 (0%)]\tLoss: 0.313228\n",
      "\n",
      "Test set: Avg. loss: 0.3171, Accuracy: 9035/10000 (90%)\n",
      "\n",
      "Train Epoch: 410 [0/60000 (0%)]\tLoss: 0.074316\n",
      "\n",
      "Test set: Avg. loss: 0.3724, Accuracy: 8871/10000 (89%)\n",
      "\n",
      "Train Epoch: 411 [0/60000 (0%)]\tLoss: 0.545481\n",
      "\n",
      "Test set: Avg. loss: 0.3444, Accuracy: 8971/10000 (90%)\n",
      "\n",
      "Train Epoch: 412 [0/60000 (0%)]\tLoss: 0.200454\n",
      "\n",
      "Test set: Avg. loss: 0.3718, Accuracy: 8882/10000 (89%)\n",
      "\n",
      "Train Epoch: 413 [0/60000 (0%)]\tLoss: 0.167847\n",
      "\n",
      "Test set: Avg. loss: 0.2773, Accuracy: 9158/10000 (92%)\n",
      "\n",
      "Train Epoch: 414 [0/60000 (0%)]\tLoss: 0.445825\n",
      "\n",
      "Test set: Avg. loss: 0.2647, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Train Epoch: 415 [0/60000 (0%)]\tLoss: 0.308481\n",
      "\n",
      "Test set: Avg. loss: 0.2759, Accuracy: 9180/10000 (92%)\n",
      "\n",
      "Train Epoch: 416 [0/60000 (0%)]\tLoss: 0.261100\n",
      "\n",
      "Test set: Avg. loss: 0.2613, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "Train Epoch: 417 [0/60000 (0%)]\tLoss: 0.255500\n",
      "\n",
      "Test set: Avg. loss: 0.2862, Accuracy: 9135/10000 (91%)\n",
      "\n",
      "Train Epoch: 418 [0/60000 (0%)]\tLoss: 0.447999\n",
      "\n",
      "Test set: Avg. loss: 0.2732, Accuracy: 9185/10000 (92%)\n",
      "\n",
      "Train Epoch: 419 [0/60000 (0%)]\tLoss: 0.222019\n",
      "\n",
      "Test set: Avg. loss: 0.3968, Accuracy: 8793/10000 (88%)\n",
      "\n",
      "Train Epoch: 420 [0/60000 (0%)]\tLoss: 0.374573\n",
      "\n",
      "Test set: Avg. loss: 0.3981, Accuracy: 8796/10000 (88%)\n",
      "\n",
      "Train Epoch: 421 [0/60000 (0%)]\tLoss: 0.439738\n",
      "\n",
      "Test set: Avg. loss: 0.2996, Accuracy: 9102/10000 (91%)\n",
      "\n",
      "Train Epoch: 422 [0/60000 (0%)]\tLoss: 0.162127\n",
      "\n",
      "Test set: Avg. loss: 0.3010, Accuracy: 9113/10000 (91%)\n",
      "\n",
      "Train Epoch: 423 [0/60000 (0%)]\tLoss: 0.448524\n",
      "\n",
      "Test set: Avg. loss: 0.3491, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Train Epoch: 424 [0/60000 (0%)]\tLoss: 0.101507\n",
      "\n",
      "Test set: Avg. loss: 0.5265, Accuracy: 8380/10000 (84%)\n",
      "\n",
      "Train Epoch: 425 [0/60000 (0%)]\tLoss: 0.786201\n",
      "\n",
      "Test set: Avg. loss: 0.4448, Accuracy: 8661/10000 (87%)\n",
      "\n",
      "Train Epoch: 426 [0/60000 (0%)]\tLoss: 0.475555\n",
      "\n",
      "Test set: Avg. loss: 0.4318, Accuracy: 8707/10000 (87%)\n",
      "\n",
      "Train Epoch: 427 [0/60000 (0%)]\tLoss: 0.194592\n",
      "\n",
      "Test set: Avg. loss: 0.3333, Accuracy: 9002/10000 (90%)\n",
      "\n",
      "Train Epoch: 428 [0/60000 (0%)]\tLoss: 0.439813\n",
      "\n",
      "Test set: Avg. loss: 0.2802, Accuracy: 9153/10000 (92%)\n",
      "\n",
      "Train Epoch: 429 [0/60000 (0%)]\tLoss: 0.334316\n",
      "\n",
      "Test set: Avg. loss: 0.3201, Accuracy: 9004/10000 (90%)\n",
      "\n",
      "Train Epoch: 430 [0/60000 (0%)]\tLoss: 0.375963\n",
      "\n",
      "Test set: Avg. loss: 0.2947, Accuracy: 9132/10000 (91%)\n",
      "\n",
      "Train Epoch: 431 [0/60000 (0%)]\tLoss: 0.274206\n",
      "\n",
      "Test set: Avg. loss: 0.2893, Accuracy: 9134/10000 (91%)\n",
      "\n",
      "Train Epoch: 432 [0/60000 (0%)]\tLoss: 0.254250\n",
      "\n",
      "Test set: Avg. loss: 0.3112, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "Train Epoch: 433 [0/60000 (0%)]\tLoss: 0.404789\n",
      "\n",
      "Test set: Avg. loss: 0.2489, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train Epoch: 434 [0/60000 (0%)]\tLoss: 0.176362\n",
      "\n",
      "Test set: Avg. loss: 0.2835, Accuracy: 9146/10000 (91%)\n",
      "\n",
      "Train Epoch: 435 [0/60000 (0%)]\tLoss: 0.305825\n",
      "\n",
      "Test set: Avg. loss: 0.2803, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Train Epoch: 436 [0/60000 (0%)]\tLoss: 0.304654\n",
      "\n",
      "Test set: Avg. loss: 0.2682, Accuracy: 9234/10000 (92%)\n",
      "\n",
      "Train Epoch: 437 [0/60000 (0%)]\tLoss: 0.089229\n",
      "\n",
      "Test set: Avg. loss: 0.2649, Accuracy: 9252/10000 (93%)\n",
      "\n",
      "Train Epoch: 438 [0/60000 (0%)]\tLoss: 0.303752\n",
      "\n",
      "Test set: Avg. loss: 0.2610, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Train Epoch: 439 [0/60000 (0%)]\tLoss: 0.357517\n",
      "\n",
      "Test set: Avg. loss: 0.2443, Accuracy: 9278/10000 (93%)\n",
      "\n",
      "Train Epoch: 440 [0/60000 (0%)]\tLoss: 0.032327\n",
      "\n",
      "Test set: Avg. loss: 0.2531, Accuracy: 9263/10000 (93%)\n",
      "\n",
      "Train Epoch: 441 [0/60000 (0%)]\tLoss: 0.103213\n",
      "\n",
      "Test set: Avg. loss: 0.2284, Accuracy: 9350/10000 (94%)\n",
      "\n",
      "Train Epoch: 442 [0/60000 (0%)]\tLoss: 0.477641\n",
      "\n",
      "Test set: Avg. loss: 0.3077, Accuracy: 9050/10000 (90%)\n",
      "\n",
      "Train Epoch: 443 [0/60000 (0%)]\tLoss: 0.340221\n",
      "\n",
      "Test set: Avg. loss: 0.3231, Accuracy: 9035/10000 (90%)\n",
      "\n",
      "Train Epoch: 444 [0/60000 (0%)]\tLoss: 0.285415\n",
      "\n",
      "Test set: Avg. loss: 0.3257, Accuracy: 9017/10000 (90%)\n",
      "\n",
      "Train Epoch: 445 [0/60000 (0%)]\tLoss: 0.343057\n",
      "\n",
      "Test set: Avg. loss: 0.3378, Accuracy: 9020/10000 (90%)\n",
      "\n",
      "Train Epoch: 446 [0/60000 (0%)]\tLoss: 0.266993\n",
      "\n",
      "Test set: Avg. loss: 0.3059, Accuracy: 9077/10000 (91%)\n",
      "\n",
      "Train Epoch: 447 [0/60000 (0%)]\tLoss: 0.388171\n",
      "\n",
      "Test set: Avg. loss: 0.2724, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Train Epoch: 448 [0/60000 (0%)]\tLoss: 0.243064\n",
      "\n",
      "Test set: Avg. loss: 0.2740, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Train Epoch: 449 [0/60000 (0%)]\tLoss: 0.274465\n",
      "\n",
      "Test set: Avg. loss: 0.2987, Accuracy: 9076/10000 (91%)\n",
      "\n",
      "Train Epoch: 450 [0/60000 (0%)]\tLoss: 0.323436\n",
      "\n",
      "Test set: Avg. loss: 0.3006, Accuracy: 9103/10000 (91%)\n",
      "\n",
      "Train Epoch: 451 [0/60000 (0%)]\tLoss: 0.341656\n",
      "\n",
      "Test set: Avg. loss: 0.2475, Accuracy: 9304/10000 (93%)\n",
      "\n",
      "Train Epoch: 452 [0/60000 (0%)]\tLoss: 0.317328\n",
      "\n",
      "Test set: Avg. loss: 0.2469, Accuracy: 9278/10000 (93%)\n",
      "\n",
      "Train Epoch: 453 [0/60000 (0%)]\tLoss: 0.168208\n",
      "\n",
      "Test set: Avg. loss: 0.2447, Accuracy: 9301/10000 (93%)\n",
      "\n",
      "Train Epoch: 454 [0/60000 (0%)]\tLoss: 0.116948\n",
      "\n",
      "Test set: Avg. loss: 0.2328, Accuracy: 9332/10000 (93%)\n",
      "\n",
      "Train Epoch: 455 [0/60000 (0%)]\tLoss: 0.237187\n",
      "\n",
      "Test set: Avg. loss: 0.2862, Accuracy: 9151/10000 (92%)\n",
      "\n",
      "Train Epoch: 456 [0/60000 (0%)]\tLoss: 0.264904\n",
      "\n",
      "Test set: Avg. loss: 0.2476, Accuracy: 9287/10000 (93%)\n",
      "\n",
      "Train Epoch: 457 [0/60000 (0%)]\tLoss: 0.099258\n",
      "\n",
      "Test set: Avg. loss: 0.2756, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Train Epoch: 458 [0/60000 (0%)]\tLoss: 0.060890\n",
      "\n",
      "Test set: Avg. loss: 0.2825, Accuracy: 9168/10000 (92%)\n",
      "\n",
      "Train Epoch: 459 [0/60000 (0%)]\tLoss: 0.192535\n",
      "\n",
      "Test set: Avg. loss: 0.2503, Accuracy: 9291/10000 (93%)\n",
      "\n",
      "Train Epoch: 460 [0/60000 (0%)]\tLoss: 0.281425\n",
      "\n",
      "Test set: Avg. loss: 0.2785, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Train Epoch: 461 [0/60000 (0%)]\tLoss: 0.321335\n",
      "\n",
      "Test set: Avg. loss: 0.2621, Accuracy: 9252/10000 (93%)\n",
      "\n",
      "Train Epoch: 462 [0/60000 (0%)]\tLoss: 0.303246\n",
      "\n",
      "Test set: Avg. loss: 0.2540, Accuracy: 9286/10000 (93%)\n",
      "\n",
      "Train Epoch: 463 [0/60000 (0%)]\tLoss: 0.184862\n",
      "\n",
      "Test set: Avg. loss: 0.2729, Accuracy: 9240/10000 (92%)\n",
      "\n",
      "Train Epoch: 464 [0/60000 (0%)]\tLoss: 0.167789\n",
      "\n",
      "Test set: Avg. loss: 0.2867, Accuracy: 9173/10000 (92%)\n",
      "\n",
      "Train Epoch: 465 [0/60000 (0%)]\tLoss: 0.132587\n",
      "\n",
      "Test set: Avg. loss: 0.2612, Accuracy: 9234/10000 (92%)\n",
      "\n",
      "Train Epoch: 466 [0/60000 (0%)]\tLoss: 0.281981\n",
      "\n",
      "Test set: Avg. loss: 0.2491, Accuracy: 9265/10000 (93%)\n",
      "\n",
      "Train Epoch: 467 [0/60000 (0%)]\tLoss: 0.188789\n",
      "\n",
      "Test set: Avg. loss: 0.2437, Accuracy: 9273/10000 (93%)\n",
      "\n",
      "Train Epoch: 468 [0/60000 (0%)]\tLoss: 0.293532\n",
      "\n",
      "Test set: Avg. loss: 0.2839, Accuracy: 9151/10000 (92%)\n",
      "\n",
      "Train Epoch: 469 [0/60000 (0%)]\tLoss: 0.204274\n",
      "\n",
      "Test set: Avg. loss: 0.2611, Accuracy: 9248/10000 (92%)\n",
      "\n",
      "Train Epoch: 470 [0/60000 (0%)]\tLoss: 0.236470\n",
      "\n",
      "Test set: Avg. loss: 0.2559, Accuracy: 9243/10000 (92%)\n",
      "\n",
      "Train Epoch: 471 [0/60000 (0%)]\tLoss: 0.279640\n",
      "\n",
      "Test set: Avg. loss: 0.2475, Accuracy: 9286/10000 (93%)\n",
      "\n",
      "Train Epoch: 472 [0/60000 (0%)]\tLoss: 0.108902\n",
      "\n",
      "Test set: Avg. loss: 0.2691, Accuracy: 9221/10000 (92%)\n",
      "\n",
      "Train Epoch: 473 [0/60000 (0%)]\tLoss: 0.294303\n",
      "\n",
      "Test set: Avg. loss: 0.2913, Accuracy: 9161/10000 (92%)\n",
      "\n",
      "Train Epoch: 474 [0/60000 (0%)]\tLoss: 0.634158\n",
      "\n",
      "Test set: Avg. loss: 0.2724, Accuracy: 9220/10000 (92%)\n",
      "\n",
      "Train Epoch: 475 [0/60000 (0%)]\tLoss: 0.535031\n",
      "\n",
      "Test set: Avg. loss: 0.2678, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Train Epoch: 476 [0/60000 (0%)]\tLoss: 0.301306\n",
      "\n",
      "Test set: Avg. loss: 0.3333, Accuracy: 8962/10000 (90%)\n",
      "\n",
      "Train Epoch: 477 [0/60000 (0%)]\tLoss: 0.310728\n",
      "\n",
      "Test set: Avg. loss: 0.2379, Accuracy: 9301/10000 (93%)\n",
      "\n",
      "Train Epoch: 478 [0/60000 (0%)]\tLoss: 0.222774\n",
      "\n",
      "Test set: Avg. loss: 0.2628, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Train Epoch: 479 [0/60000 (0%)]\tLoss: 0.609382\n",
      "\n",
      "Test set: Avg. loss: 0.2679, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Train Epoch: 480 [0/60000 (0%)]\tLoss: 0.177326\n",
      "\n",
      "Test set: Avg. loss: 0.2605, Accuracy: 9217/10000 (92%)\n",
      "\n",
      "Train Epoch: 481 [0/60000 (0%)]\tLoss: 0.270564\n",
      "\n",
      "Test set: Avg. loss: 0.2641, Accuracy: 9178/10000 (92%)\n",
      "\n",
      "Train Epoch: 482 [0/60000 (0%)]\tLoss: 0.226230\n",
      "\n",
      "Test set: Avg. loss: 0.2459, Accuracy: 9261/10000 (93%)\n",
      "\n",
      "Train Epoch: 483 [0/60000 (0%)]\tLoss: 0.132685\n",
      "\n",
      "Test set: Avg. loss: 0.2560, Accuracy: 9237/10000 (92%)\n",
      "\n",
      "Train Epoch: 484 [0/60000 (0%)]\tLoss: 0.243476\n",
      "\n",
      "Test set: Avg. loss: 0.2435, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train Epoch: 485 [0/60000 (0%)]\tLoss: 0.153333\n",
      "\n",
      "Test set: Avg. loss: 0.2370, Accuracy: 9307/10000 (93%)\n",
      "\n",
      "Train Epoch: 486 [0/60000 (0%)]\tLoss: 0.179601\n",
      "\n",
      "Test set: Avg. loss: 0.2365, Accuracy: 9308/10000 (93%)\n",
      "\n",
      "Train Epoch: 487 [0/60000 (0%)]\tLoss: 0.108669\n",
      "\n",
      "Test set: Avg. loss: 0.2301, Accuracy: 9316/10000 (93%)\n",
      "\n",
      "Train Epoch: 488 [0/60000 (0%)]\tLoss: 0.140460\n",
      "\n",
      "Test set: Avg. loss: 0.2451, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "Train Epoch: 489 [0/60000 (0%)]\tLoss: 0.202027\n",
      "\n",
      "Test set: Avg. loss: 0.2549, Accuracy: 9248/10000 (92%)\n",
      "\n",
      "Train Epoch: 490 [0/60000 (0%)]\tLoss: 0.303513\n",
      "\n",
      "Test set: Avg. loss: 0.2686, Accuracy: 9256/10000 (93%)\n",
      "\n",
      "Train Epoch: 491 [0/60000 (0%)]\tLoss: 0.313939\n",
      "\n",
      "Test set: Avg. loss: 0.3366, Accuracy: 9041/10000 (90%)\n",
      "\n",
      "Train Epoch: 492 [0/60000 (0%)]\tLoss: 0.335324\n",
      "\n",
      "Test set: Avg. loss: 0.2823, Accuracy: 9193/10000 (92%)\n",
      "\n",
      "Train Epoch: 493 [0/60000 (0%)]\tLoss: 0.150385\n",
      "\n",
      "Test set: Avg. loss: 0.3092, Accuracy: 9097/10000 (91%)\n",
      "\n",
      "Train Epoch: 494 [0/60000 (0%)]\tLoss: 0.378634\n",
      "\n",
      "Test set: Avg. loss: 0.2512, Accuracy: 9237/10000 (92%)\n",
      "\n",
      "Train Epoch: 495 [0/60000 (0%)]\tLoss: 0.096740\n",
      "\n",
      "Test set: Avg. loss: 0.2579, Accuracy: 9230/10000 (92%)\n",
      "\n",
      "Train Epoch: 496 [0/60000 (0%)]\tLoss: 0.215885\n",
      "\n",
      "Test set: Avg. loss: 0.2625, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Train Epoch: 497 [0/60000 (0%)]\tLoss: 0.126797\n",
      "\n",
      "Test set: Avg. loss: 0.2698, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Train Epoch: 498 [0/60000 (0%)]\tLoss: 0.133364\n",
      "\n",
      "Test set: Avg. loss: 0.2680, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Train Epoch: 499 [0/60000 (0%)]\tLoss: 0.230889\n",
      "\n",
      "Test set: Avg. loss: 0.2573, Accuracy: 9222/10000 (92%)\n",
      "\n",
      "Train Epoch: 500 [0/60000 (0%)]\tLoss: 0.358859\n",
      "\n",
      "Test set: Avg. loss: 0.2221, Accuracy: 9335/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model1, test_loader)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch, model1, optimizer1, train_loader)\n",
    "    test(model1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
