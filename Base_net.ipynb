{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x193e02001d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "random_seed = 420\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network flowchart:\n",
    "#input vector --- random initialized weights ---> hyperdimensional vecotor ---> one_hot_net l1 ---> ...ln... ---> sigmoid/softmax output\n",
    "#One hot net\n",
    "\n",
    "class One_hot_op(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A, W, epsilon):\n",
    "        Z = torch.matmul(W, A)\n",
    "        #ctx.Z = Z\n",
    "        #ctx.A = A\n",
    "        #ctx.W = W\n",
    "        #ctx.epsilon = epsilon\n",
    "        ctx.save_for_backward(Z,A,W,epsilon)\n",
    "        ret = Z > epsilon\n",
    "        #print(ret[1:10][1:10])\n",
    "        return ret.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dA):\n",
    "        Z,A,W,epsilon = ctx.saved_tensors\n",
    "        step = Z > epsilon\n",
    "        step = step.float()\n",
    "        dL_dZ = dL_dA * step \n",
    "        \n",
    "        dZ_dW = torch.transpose(A, 0,1)\n",
    "        dZ_dW = torch.sign(dZ_dW)\n",
    "        dZ_dA = torch.transpose(W, 0,1)\n",
    "        dZ_dA = torch.sign(dZ_dA)\n",
    "        dA = torch.matmul(dZ_dA,dL_dZ)\n",
    "        dW = torch.matmul(dL_dZ,dZ_dW)\n",
    "        return dA, dW, None\n",
    "\n",
    "\n",
    "class One_hot_layer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, initialization_f, epsilon):\n",
    "        super(One_hot_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.initialization_f = initialization_f\n",
    "        initialized_weight = initialization_f(out_dim, in_dim)\n",
    "        self.weight = nn.Parameter(initialized_weight, requires_grad = True)\n",
    "        self.op = One_hot_op\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_dim) + ',' \\\n",
    "               + str(self.out_dim) + ')'\n",
    "        \n",
    "    def forward(self, A):\n",
    "        #print(self.weight[:3][:3])\n",
    "        return self.op.apply(A, self.weight, self.epsilon)\n",
    "\n",
    "class Linear_noise_op(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, W, noise):\n",
    "        ctx.noise = noise\n",
    "        return W\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dW):\n",
    "        #print(\"go\")\n",
    "        #print(dW.shape)\n",
    "        return apply_gaussian_noise(dW, ctx.noise, device = dW.device), None\n",
    "    \n",
    "class Linear(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim,initialization_f = None,device = torch.device(\"cuda:0\")):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.device = device\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_dim, in_dim), requires_grad = True)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dim,1), requires_grad = True)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_dim) + ',' \\\n",
    "               + str(self.out_dim) + ')'\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / self.weight.size(1) ** 1 / 2\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, X, noise = None, grad_noise = None):\n",
    "        #print(self.__class__.__name__, self.weight[:2,:2])\n",
    "        \n",
    "        if grad_noise is not None and grad_noise != 0:\n",
    "            W = Linear_noise_op.apply(self.weight, grad_noise)\n",
    "            B = Linear_noise_op.apply(self.bias, grad_noise)\n",
    "        else:\n",
    "            W = self.weight\n",
    "            B = self.bias\n",
    "        \n",
    "        \n",
    "        if noise is None or noise == 0:\n",
    "            return torch.matmul(W, X) + B\n",
    "        else:\n",
    "            return torch.matmul(apply_percentage_gaussian_noise(W, noise, device = self.device), X) + apply_percentage_gaussian_noise(B, noise, device = self.device)\n",
    "        '''\n",
    "        #return torch.matmul(self.weight, X) + self.bias\n",
    "        if noise is None or noise == 0:\n",
    "            return torch.matmul(self.weight, X) + self.bias\n",
    "        else:\n",
    "            return torch.matmul(apply_gaussian_noise(self.weight, noise, device = self.device), X) + apply_gaussian_noise(self.bias, noise, device = self.device)\n",
    "        '''\n",
    "class One_hot_net(nn.Module):\n",
    "    def __init__(self, in_dim, n_class, f_encoder, encoder_multiplier, f_initializer, epsilon, n_layers=2, layer_size_factor=[1, 5], dropout=[-1, 0.5]):\n",
    "        super(One_hot_net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.in_dim = in_dim\n",
    "        feature_len = int(in_dim * encoder_multiplier)\n",
    "        self.feature_len = feature_len\n",
    "        self.n_layers=n_layers\n",
    "        self.layer_size_factor=layer_size_factor\n",
    "        self.dropout=dropout\n",
    "        self.epsilon = epsilon\n",
    "        self.n_class = n_class\n",
    "        self.f_encoder = f_encoder\n",
    "        self.f_initializer = f_initializer\n",
    "        for i in range(n_layers):\n",
    "            if dropout[i] > 0:\n",
    "                self.layers.append(nn.Dropout(dropout[i]))\n",
    "            if i < n_layers - 1:\n",
    "                self.layers.append(\n",
    "                    One_hot_layer(int(feature_len // layer_size_factor[i]), int(feature_len // layer_size_factor[i + 1]), f_initializer, epsilon))\n",
    "        #self.tail = nn.Linear(int(feature_len // layer_size_factor[-1]), n_class)\n",
    "        self.tail = Linear(int(feature_len // layer_size_factor[-1]), n_class, f_initializer)\n",
    "        self.out = nn.LogSoftmax(dim = 0)\n",
    "    \n",
    "    def flatten(self, X):\n",
    "        return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = torch.transpose(X, 0, 1)\n",
    "        #X = self.f_encoder.apply_wnoise(X, sd = 0.5)\n",
    "        X = self.f_encoder.apply(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        #X = torch.transpose(X, 0, 1)\n",
    "        #X = apply_binary_noise(X, 0.05)\n",
    "        X = self.tail(X, noise = 0, grad_noise = 0)\n",
    "        return self.out(X).T\n",
    "\n",
    "class toy_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_Net, self).__init__()\n",
    "        self.fc2 = Linear(784, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 0)\n",
    "    def flatten(self, X):\n",
    "            return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = x.T\n",
    "        x = (x > -0.4).float()\n",
    "        x = self.fc2(x, noise = 0)\n",
    "        return self.out(x).T\n",
    "    \n",
    "class toy_Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_Net2, self).__init__()\n",
    "        self.fc1 = Linear(784, 300)\n",
    "        self.fc2 = Linear(300, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 0)\n",
    "    def flatten(self, X):\n",
    "            return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = x.T\n",
    "        x = self.fc1(x, noise = 0, grad_noise = 0)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x, noise = 0, grad_noise = 0)\n",
    "        return self.out(x).T\n",
    "    \n",
    "class toy_Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_Net3, self).__init__()\n",
    "        self.fc1 = Linear(784, 400)\n",
    "        self.fc2 = Linear(400, 100)\n",
    "        self.fc3 = Linear(100, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 0)\n",
    "    def flatten(self, X):\n",
    "            return X.view(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = x.T\n",
    "        x = self.fc1(x, noise = 0.5, grad_noise = 1)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x, noise = 0.5, grad_noise = 1)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x, noise = 0.5, grad_noise = 1)\n",
    "        return self.out(x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise \n",
    "def apply_gaussian_noise(tensor, sd, device = torch.device(\"cuda:0\")):\n",
    "    tensor = tensor + (sd)*torch.randn(*tuple(tensor.shape)).to(device)\n",
    "    return tensor\n",
    "\n",
    "def apply_binary_noise(tensor, p, device = torch.device(\"cuda:0\")):\n",
    "    #change 1 entries to 0\n",
    "    tensor = tensor * (torch.rand(*tuple(tensor.shape))>(p/2)).float().to(device)\n",
    "    #change 0 entries to 1\n",
    "    tensor = tensor + (torch.rand(*tuple(tensor.shape))>(1-p/2)).float().to(device)\n",
    "    return torch.sign(tensor)\n",
    "\n",
    "def apply_percentage_gaussian_noise(tensor, p, device = torch.device(\"cuda:0\")):\n",
    "    tensor = tensor + p * torch.randn(*tuple(tensor.shape)).to(device) * torch.mean(tensor)\n",
    "    \n",
    "#a = [[1,1,0,0,1,1], [1,1,0,0,1,1], [1,1,0,0,1,1]]\n",
    "#a = torch.tensor(a)\n",
    "#print((torch.rand(*tuple(a.shape))<(0.1/2)).float())\n",
    "#print(a)\n",
    "#print(apply_binary_noise(a, 0.1, device = torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializers and encoders\n",
    "def uniform_initializer(out_dim, in_dim, cuda = True):\n",
    "    tensor = torch.empty(out_dim, in_dim)\n",
    "    if cuda:\n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2).cuda()\n",
    "    else: \n",
    "        return torch.nn.init.uniform_(tensor, a=-2, b=2)\n",
    "\n",
    "class simple_encoder():\n",
    "    def __init__(self, out_dim, in_dim):\n",
    "        self.W = uniform_initializer(out_dim, in_dim)\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return torch.matmul(self.W, X)\n",
    "    \n",
    "class simple_encoder_wthreshold():\n",
    "    def __init__(self, out_dim, in_dim, epsilon, cuda = True):\n",
    "        self.W = uniform_initializer(out_dim, in_dim, cuda)\n",
    "        self.device = torch.device(\"cuda:0\") if cuda else torch.device(\"cpu\")\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def apply(self, X):\n",
    "        return (torch.matmul(self.W, X) > self.epsilon).float()\n",
    "    \n",
    "    def apply_wnoise(self, X, sd):\n",
    "        return (torch.matmul(apply_percentage_gaussian_noise(self.W, sd, device = self.device), X) > self.epsilon).float()\n",
    "    \n",
    "class non_linear_encoder():\n",
    "    def __init__(self, out_dim, in_dim, activation, cuda = True):\n",
    "        self.W = uniform_initializer(out_dim, in_dim, cuda)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def apply(self, X):\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        return self.activation((torch.matmul(self.W, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'in_dim': 784,\n",
    "    'n_class': 10,\n",
    "    'f_encoder': simple_encoder_wthreshold(784*20, 784, 10e-3),\n",
    "    'f_initializer': uniform_initializer,\n",
    "    'encoder_multiplier': 20,\n",
    "    'epsilon': 10e-3,\n",
    "    'n_layers': 1,\n",
    "    'layer_size_factor': [1, 1, 1],\n",
    "    'dropout': [0.6, -1, -1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#model1 = One_hot_net(parameters['in_dim'], parameters['n_class'], parameters['f_encoder'], parameters['encoder_multiplier'], parameters['f_initializer'], parameters['epsilon'], parameters['n_layers'], parameters['layer_size_factor'], parameters['dropout']).to(device)\n",
    "model1 = toy_Net2().to(device)\n",
    "#model1 = toy_Net3().to(device)\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer1 = torch.optim.SGD([{'params': model1.layers.parameters(), 'lr': 0.01}, {'params': model1.tail.parameters(), 'lr': 0.01}], lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 2]         235,500\n",
      "            Linear-2                    [-1, 2]           3,010\n",
      "        LogSoftmax-3                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 0.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model1, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, trainloader, log_interval = 10, device = torch.device(\"cuda:0\")):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output[:5,:])\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        #model.fc1.grad[:3,:3]\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(model.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device = torch.device(\"cuda:0\")):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caixu\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3026, Accuracy: 974/10000 (9.7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302495\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.302232\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.301812\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.301188\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.299707\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.298447\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.296140\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.292431\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.281122\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.265923\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.254190\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.197264\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.092805\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.035573\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.997353\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.827253\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.688593\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.416398\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.357357\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.277233\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.200489\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.184188\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.980285\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.970034\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.891184\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.957147\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.845099\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.750310\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.956269\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.783445\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.714178\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.529079\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.764906\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.659845\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.519930\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.433807\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.507969\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.680698\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.588874\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.600862\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.437004\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.376641\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.536329\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.848709\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.464327\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.416120\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.376334\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.529743\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.512715\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.532882\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.392702\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.725148\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.390649\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.568502\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.455862\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.334986\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.312739\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.340310\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.427832\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.366974\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.422106\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.333499\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.582897\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.615244\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.520414\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.378578\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.535086\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.404106\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.231732\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.390263\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.391608\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.661412\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.323844\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.216515\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.290045\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.352145\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.220288\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.554236\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.234030\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.341793\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.517415\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.282811\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.319978\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.309110\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.411680\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.187574\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.217023\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.273130\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.360328\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.641155\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.223031\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.468245\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.169779\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.307991\n",
      "\n",
      "Test set: Avg. loss: 0.3223, Accuracy: 9073/10000 (90.7%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.423683\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.279212\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.465078\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.444423\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.446836\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.308335\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.259717\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.233238\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.325085\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.315816\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.579872\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.519089\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.452771\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.321757\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.323412\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.213330\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.293936\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.341082\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.219813\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.309364\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.314576\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.404757\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.238126\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.307879\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.334991\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.274161\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.314273\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.072565\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.214593\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.387276\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.255687\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.275358\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.243728\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.266107\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.213861\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.352907\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.225579\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.348765\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.498948\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.165140\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.501667\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.178371\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.434944\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.183484\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.142358\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.390727\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.261425\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.198567\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.175894\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.218925\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.332006\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.280369\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.169801\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.162698\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.528400\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.415733\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.307328\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.250068\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.357656\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.280350\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.175448\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.360638\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.155567\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.247769\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.459084\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.229830\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.193427\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.147897\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.347506\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.274136\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.141517\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.182415\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.252118\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.293018\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.325346\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.270223\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.282739\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.194387\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.389445\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.363959\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.249061\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.265407\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.226410\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.194275\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.215683\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.302804\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.250264\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.251380\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.103029\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.170525\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.172316\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.114783\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.325885\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.290552\n",
      "\n",
      "Test set: Avg. loss: 0.2457, Accuracy: 9279/10000 (92.8%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.368237\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.179511\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.238600\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.081559\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.132965\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.306978\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.118972\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.256923\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.196922\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.199757\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.279821\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.149488\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.153942\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.201559\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.321192\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.373509\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.141853\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.227300\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.218231\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.238917\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.164754\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.414604\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.180705\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.209519\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.258726\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.260081\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.198847\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.381617\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.375629\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.347874\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.248818\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.158307\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.164523\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.130495\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.132601\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.387948\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.216279\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.242399\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.154731\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.294055\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.157078\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.142613\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.239852\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.225628\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.335138\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.258512\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.137986\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.174684\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.097979\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.165678\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.203732\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.180590\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.163269\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.112974\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.292631\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.156397\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.186709\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.278050\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.183923\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.193301\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.307208\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.261174\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.361901\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.179518\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.175571\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.271081\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.162541\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.208870\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.253648\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.486269\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.160450\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.116976\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.169952\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.262442\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.137191\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.206017\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.512642\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.238225\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.336709\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.125903\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.097516\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.115766\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.188051\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.257972\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.243612\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.166772\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.165074\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.112248\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.298549\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.109340\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.206809\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.156081\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.192863\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.112353\n",
      "\n",
      "Test set: Avg. loss: 0.1990, Accuracy: 9414/10000 (94.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.073607\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.194808\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.186208\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.149344\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.193701\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.133441\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.229987\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.225067\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.165739\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.237395\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.124695\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.097097\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.129667\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.163938\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.120187\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.281709\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.265502\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.144005\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.134325\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.338349\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.130176\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.142025\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.083640\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.218850\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.098484\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.251227\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.199044\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.228584\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.106911\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.138216\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.091614\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.209193\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.119458\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.044497\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.181708\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.126783\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.398395\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.390890\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.219758\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.612813\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.128028\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.242180\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.211398\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.137001\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.152359\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.199194\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.238087\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.146293\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.170521\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.102482\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.188064\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.217963\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.212510\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.221994\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.121683\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.091673\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.171856\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.123364\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.162039\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.294875\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.136326\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.097655\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.177022\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.082759\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.106467\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.412982\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.212532\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.217701\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.066449\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.126315\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.174462\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.369873\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.278726\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.199104\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.216932\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.192535\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.186531\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.163655\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.156555\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.132108\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.110892\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.155633\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.137608\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.149318\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.072175\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.254974\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.126900\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.095155\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.168956\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.253031\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.330248\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.148988\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.141977\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.156907\n",
      "\n",
      "Test set: Avg. loss: 0.1717, Accuracy: 9498/10000 (95.0%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.211960\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.106876\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.199189\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.098439\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.403091\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.109172\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.167707\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.155233\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.191834\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.074710\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.088440\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.177295\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.139460\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.082395\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.052754\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.171078\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.188512\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.206861\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.152028\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.100036\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.435935\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.116304\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.105098\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.086581\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.136068\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.149313\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.206762\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.268051\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.089492\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.139826\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.231154\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.182985\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.099171\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.144353\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.199900\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.145358\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.134384\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.241690\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.115192\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.130234\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.163510\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.147867\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.155792\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.119008\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.141056\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.229858\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.063241\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.173116\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.321523\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.062414\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.216514\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.143308\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.062161\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.115713\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.251057\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.142247\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.138264\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.269049\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.168249\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.159659\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.154359\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.178106\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.071900\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.228921\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.104562\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.207134\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.073257\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.136838\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.275639\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.102363\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.093920\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.258503\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.100749\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.155000\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.170989\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.071051\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.253941\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.170033\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.148630\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.115257\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.134812\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.124299\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.095850\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.127059\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.144011\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.113828\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.113206\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.205893\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.242643\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.244633\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.118406\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.177852\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.108891\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.164793\n",
      "\n",
      "Test set: Avg. loss: 0.1488, Accuracy: 9569/10000 (95.7%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.270394\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.091823\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.056811\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.052844\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.156222\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.155883\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.113773\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.034475\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.094828\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.283810\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.090470\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.148402\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.094741\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.064578\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.154279\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.353880\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.074567\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.101009\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.181775\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.059204\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.116750\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.122997\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.116052\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.214571\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.024284\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.115136\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.060712\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.102973\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.211993\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.107653\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.128141\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.145441\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.125935\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.140836\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.091470\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.105524\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.158361\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.164184\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.170220\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.177318\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.042255\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.150926\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.077341\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.280354\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.153247\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.141942\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.073406\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.193967\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.126850\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.119064\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.150306\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.153623\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.126027\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.156051\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.255181\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.145622\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.185531\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.057300\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.183774\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.081287\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.092286\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.087945\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.404823\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.178373\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.157288\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.047831\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.149427\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.045409\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.155530\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.238146\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.059607\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.106357\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.155078\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.115107\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.070471\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.046355\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.081279\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.181558\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.205891\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.068266\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.079117\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.054390\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.242845\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.231482\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.125560\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.093655\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.171826\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.114512\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.376040\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.188835\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.157710\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.085300\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.215189\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.062532\n",
      "\n",
      "Test set: Avg. loss: 0.1359, Accuracy: 9602/10000 (96.0%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.115210\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.081113\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.103997\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.170217\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.157654\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.063279\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.092295\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.114385\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.110072\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.058311\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.072055\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.060821\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.126360\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.119550\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.120014\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.265825\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.101766\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.058297\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.045170\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.239589\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.261166\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.076817\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.085420\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.105152\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.193986\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.109408\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.057602\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.143651\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.107515\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.234089\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.140011\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.231247\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.118559\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.119227\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.125425\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.039152\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.114382\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.089900\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.041729\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.125036\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.206937\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.141630\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.201423\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.182641\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.084591\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.078718\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.080479\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.072766\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.218788\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.096437\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.055743\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.127896\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.227538\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.099144\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.192633\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.138873\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.080508\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.191415\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.080384\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.081270\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.056940\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.073479\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.078792\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.089047\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.152981\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.072457\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.131165\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.144619\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.109791\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.064950\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.068371\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.133219\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.089811\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.091541\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.138336\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.159406\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.078231\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.274253\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.099036\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.122282\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.213742\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.097921\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.243079\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.085532\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.057765\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.121065\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.058682\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.183949\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.032535\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.072586\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.172710\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.131971\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.019991\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.078860\n",
      "\n",
      "Test set: Avg. loss: 0.1208, Accuracy: 9649/10000 (96.5%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.130260\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.101875\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.118718\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.075808\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.048647\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.278993\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.211742\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.102185\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.165898\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.144864\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.070654\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.101459\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.132343\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.090155\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.025650\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.078262\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.041827\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.135240\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.049162\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.074403\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.198072\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.047950\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.053937\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.190214\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.122315\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.187074\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.106424\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.086160\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.095685\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.103311\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.076551\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.078558\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.108216\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.090901\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.120145\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.113670\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.170326\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.107816\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.212744\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.127243\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.079349\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.058295\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.073610\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.038005\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.218334\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.140582\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.203900\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.089165\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.122263\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.182774\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.132656\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.071556\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.090038\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.124499\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.026584\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.186411\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.088322\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.217018\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.028520\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.057854\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.109874\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.056213\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.062834\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.179928\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.153168\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.155110\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.044447\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.156204\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.070515\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.043595\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.164151\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.078346\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.109150\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.081550\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.057822\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.055793\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.082988\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.117779\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.045097\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.117525\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.159996\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.058727\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.049487\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.223951\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.239857\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.065836\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.136586\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.033258\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.168832\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.098400\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.050598\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.062799\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.206373\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.092427\n",
      "\n",
      "Test set: Avg. loss: 0.1132, Accuracy: 9679/10000 (96.8%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.119506\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.040930\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.159737\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.140148\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.072075\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.079496\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.143505\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.077894\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.039926\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.087737\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.083789\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.059511\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.033710\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.057678\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.147975\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.096562\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.162000\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.071434\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.048185\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.044657\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.030601\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.164337\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.085802\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.158784\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.046565\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.076298\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.032532\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.182510\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.116958\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.197411\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.128262\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.070685\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.084891\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.025027\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.103031\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.098856\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.038392\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.075089\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.163448\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.034736\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.064725\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.158056\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.106023\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.046347\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.106391\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.133669\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.058091\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.029536\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.136417\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.068364\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.103915\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.088700\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.046743\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.067041\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.025244\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.136999\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.073594\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.168701\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.046174\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.040047\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.072954\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.118792\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.091936\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.139573\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.108446\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.089107\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.089866\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.113824\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.099368\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.076295\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.206710\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.187244\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.109951\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.112106\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.147503\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.041647\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.130555\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.049117\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.084660\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.060769\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.094878\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.151774\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.043417\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.081194\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.071950\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.097694\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.049530\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.189086\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.079030\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.145370\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.092257\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.084343\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.056702\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.080139\n",
      "\n",
      "Test set: Avg. loss: 0.1027, Accuracy: 9707/10000 (97.1%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.050710\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.084363\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.024155\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.130636\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.110008\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.110047\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.074266\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.178481\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.053388\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.029034\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.051459\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.205404\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.027690\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.263949\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.112781\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.068104\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.114159\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.077190\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.054743\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.049068\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.050970\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.023639\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.081672\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.108627\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.015122\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.121510\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.170440\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.015464\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.128416\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.110642\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.146427\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.050183\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.037628\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.229348\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.057084\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.067019\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.031500\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.064715\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.068372\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.169174\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.028050\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.087812\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.051462\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.177634\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.178402\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.072016\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.045385\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.179573\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.145293\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.133134\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.094274\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.168575\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.273111\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.070517\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.145369\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.054959\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.042831\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.080371\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.054967\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.097689\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.040938\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.069996\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.059079\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.064142\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.027629\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.084002\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.080810\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.042257\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.163945\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.081620\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.061044\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.065492\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.067622\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.157340\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.033755\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.066189\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.130726\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.086061\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.040378\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.045775\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.045562\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.024223\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.033665\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.042934\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.075021\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.081856\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.100917\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.158317\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.093539\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.176122\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.045914\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.026116\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.049817\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.041659\n",
      "\n",
      "Test set: Avg. loss: 0.0971, Accuracy: 9720/10000 (97.2%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.042312\n",
      "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.106233\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.040481\n",
      "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.053145\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.032638\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.090028\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.055976\n",
      "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.071984\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.133331\n",
      "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.031329\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.112722\n",
      "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.038387\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.085803\n",
      "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.108659\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.029846\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.185098\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.116100\n",
      "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.093960\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.048108\n",
      "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.056616\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.087677\n",
      "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.092143\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.069267\n",
      "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.053400\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.022639\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.069065\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.066584\n",
      "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.122149\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.101413\n",
      "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.211428\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.084218\n",
      "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.174360\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.091247\n",
      "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.093381\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.040014\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.088190\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.150261\n",
      "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.046922\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.087612\n",
      "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.049584\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.129738\n",
      "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.052092\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.021967\n",
      "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.028863\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.047520\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.076961\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.053682\n",
      "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.024070\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.151764\n",
      "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.183506\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.108591\n",
      "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.100324\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.044769\n",
      "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.100014\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.112601\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.120343\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.086049\n",
      "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.174955\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.051170\n",
      "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.120409\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.063133\n",
      "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.142682\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.216676\n",
      "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.030650\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.100150\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.121826\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.160350\n",
      "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.188922\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.114627\n",
      "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.095017\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.032309\n",
      "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.047677\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.132428\n",
      "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.128503\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.058712\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.075706\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.071434\n",
      "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.066750\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.083897\n",
      "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.054845\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.085017\n",
      "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.097321\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.054910\n",
      "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.244543\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.047391\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.039338\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.041278\n",
      "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.146170\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.051101\n",
      "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.046423\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.032219\n",
      "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.016103\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.083658\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.136037\n",
      "\n",
      "Test set: Avg. loss: 0.0927, Accuracy: 9723/10000 (97.2%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.080790\n",
      "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.085860\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.114621\n",
      "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.052901\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.037594\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.021098\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.194188\n",
      "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.049480\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.064077\n",
      "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.153614\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.053155\n",
      "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.077273\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.034626\n",
      "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.039908\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.071447\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.173687\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.191981\n",
      "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.081522\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.115726\n",
      "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.174059\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.026023\n",
      "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.058604\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.049195\n",
      "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.046473\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.052804\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.032663\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.150889\n",
      "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.048060\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.149939\n",
      "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.056395\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.157910\n",
      "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.091082\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.032999\n",
      "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.057401\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.030642\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.050847\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.103195\n",
      "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.045281\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.032813\n",
      "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.068640\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.030856\n",
      "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.033646\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.119899\n",
      "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.022684\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.027120\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.031496\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.050953\n",
      "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.036583\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.056584\n",
      "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.100396\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.098322\n",
      "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.027187\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.028571\n",
      "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.018302\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.068084\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.176430\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.135661\n",
      "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.057303\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.038822\n",
      "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.053888\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.173034\n",
      "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.077511\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.029915\n",
      "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.122421\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.103483\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.168375\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.060109\n",
      "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.078886\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.026908\n",
      "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.098684\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.053898\n",
      "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.029514\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.027125\n",
      "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.153448\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.045395\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.058600\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.050549\n",
      "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.210528\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.041134\n",
      "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.140111\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.061692\n",
      "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.049869\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.034858\n",
      "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.060387\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.122147\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.073019\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.124731\n",
      "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.206963\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.041707\n",
      "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.054466\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.072618\n",
      "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.122282\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.100602\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.038056\n",
      "\n",
      "Test set: Avg. loss: 0.0882, Accuracy: 9743/10000 (97.4%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.079197\n",
      "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.134527\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.028533\n",
      "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.051034\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.117512\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.041340\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.059470\n",
      "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.026753\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.018002\n",
      "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.083325\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.058217\n",
      "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.045590\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.052263\n",
      "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.073827\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.037471\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.068659\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.022941\n",
      "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.095276\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.059827\n",
      "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.052949\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.059953\n",
      "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.061551\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.136888\n",
      "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.053643\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.049512\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.029066\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.066183\n",
      "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.091785\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.065825\n",
      "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.078986\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.155789\n",
      "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.035720\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.083953\n",
      "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.009410\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.064961\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.033205\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.157380\n",
      "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.037745\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.074030\n",
      "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.089818\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.056651\n",
      "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.045432\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.068353\n",
      "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.070992\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.153450\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.026063\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.069128\n",
      "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.147184\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.028491\n",
      "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.139348\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.011447\n",
      "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.027483\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.015339\n",
      "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.123029\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.207842\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.053507\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.064342\n",
      "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.027701\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.058370\n",
      "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.045282\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.047915\n",
      "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.016580\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.079396\n",
      "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.123600\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.043358\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.079143\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.102032\n",
      "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.027535\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.028778\n",
      "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.053823\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.055510\n",
      "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.015470\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.058053\n",
      "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.220848\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.090704\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.080074\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.106990\n",
      "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.098384\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.076429\n",
      "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.085038\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.054031\n",
      "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.071854\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.090826\n",
      "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.040449\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.034479\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.009547\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.229776\n",
      "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.039751\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.026723\n",
      "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.037763\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.095317\n",
      "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.053472\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.023183\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.018612\n",
      "\n",
      "Test set: Avg. loss: 0.0843, Accuracy: 9756/10000 (97.6%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.027773\n",
      "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.045875\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.043151\n",
      "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.043151\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.172366\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.045553\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.133756\n",
      "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.105861\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.019447\n",
      "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.032503\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.031955\n",
      "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.035199\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.038369\n",
      "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.059660\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.019763\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.044824\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.044222\n",
      "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.024094\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.053060\n",
      "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.100375\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.057479\n",
      "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.050472\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.124453\n",
      "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.077294\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.014164\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.071174\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.052558\n",
      "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.046198\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.025252\n",
      "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.041365\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.083098\n",
      "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.042340\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.029894\n",
      "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.038170\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.067706\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.031195\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.073111\n",
      "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.100820\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.065934\n",
      "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.117245\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.096454\n",
      "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.087667\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.014797\n",
      "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.084655\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.106077\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.149009\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.027342\n",
      "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.037802\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.027833\n",
      "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.019813\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.126101\n",
      "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.016052\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.028155\n",
      "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.039856\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.112588\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.094408\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.044860\n",
      "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.023186\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.074222\n",
      "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.023256\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.038738\n",
      "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.022557\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.046603\n",
      "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.098720\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.072286\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.069052\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.024744\n",
      "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.029415\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.020960\n",
      "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.081718\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.030413\n",
      "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.062449\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.122137\n",
      "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.075876\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.023703\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.042650\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.026919\n",
      "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.012795\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.028089\n",
      "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.052644\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.093248\n",
      "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.150497\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.036014\n",
      "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.054389\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.066672\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.041021\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.034625\n",
      "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.013417\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.028541\n",
      "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.096860\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.130553\n",
      "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.032402\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.038601\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.035846\n",
      "\n",
      "Test set: Avg. loss: 0.0819, Accuracy: 9757/10000 (97.6%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.069214\n",
      "Train Epoch: 15 [640/60000 (1%)]\tLoss: 0.073072\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.053244\n",
      "Train Epoch: 15 [1920/60000 (3%)]\tLoss: 0.048744\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.045382\n",
      "Train Epoch: 15 [3200/60000 (5%)]\tLoss: 0.032444\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.059815\n",
      "Train Epoch: 15 [4480/60000 (7%)]\tLoss: 0.014042\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.053978\n",
      "Train Epoch: 15 [5760/60000 (10%)]\tLoss: 0.056234\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.046777\n",
      "Train Epoch: 15 [7040/60000 (12%)]\tLoss: 0.033685\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.042095\n",
      "Train Epoch: 15 [8320/60000 (14%)]\tLoss: 0.013809\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.050451\n",
      "Train Epoch: 15 [9600/60000 (16%)]\tLoss: 0.063958\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.038442\n",
      "Train Epoch: 15 [10880/60000 (18%)]\tLoss: 0.060554\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.051587\n",
      "Train Epoch: 15 [12160/60000 (20%)]\tLoss: 0.033901\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.034511\n",
      "Train Epoch: 15 [13440/60000 (22%)]\tLoss: 0.037656\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.057178\n",
      "Train Epoch: 15 [14720/60000 (25%)]\tLoss: 0.018550\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.027250\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.029449\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.074580\n",
      "Train Epoch: 15 [17280/60000 (29%)]\tLoss: 0.094480\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.037177\n",
      "Train Epoch: 15 [18560/60000 (31%)]\tLoss: 0.023697\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.019526\n",
      "Train Epoch: 15 [19840/60000 (33%)]\tLoss: 0.054543\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.059508\n",
      "Train Epoch: 15 [21120/60000 (35%)]\tLoss: 0.057556\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.032753\n",
      "Train Epoch: 15 [22400/60000 (37%)]\tLoss: 0.021246\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.061120\n",
      "Train Epoch: 15 [23680/60000 (39%)]\tLoss: 0.037039\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.066222\n",
      "Train Epoch: 15 [24960/60000 (42%)]\tLoss: 0.066155\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.024617\n",
      "Train Epoch: 15 [26240/60000 (44%)]\tLoss: 0.059050\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.071403\n",
      "Train Epoch: 15 [27520/60000 (46%)]\tLoss: 0.059302\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.052747\n",
      "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.039656\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.140115\n",
      "Train Epoch: 15 [30080/60000 (50%)]\tLoss: 0.047072\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.134574\n",
      "Train Epoch: 15 [31360/60000 (52%)]\tLoss: 0.137685\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.042720\n",
      "Train Epoch: 15 [32640/60000 (54%)]\tLoss: 0.053473\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.055543\n",
      "Train Epoch: 15 [33920/60000 (57%)]\tLoss: 0.033979\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.148385\n",
      "Train Epoch: 15 [35200/60000 (59%)]\tLoss: 0.045537\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.097667\n",
      "Train Epoch: 15 [36480/60000 (61%)]\tLoss: 0.025673\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.029199\n",
      "Train Epoch: 15 [37760/60000 (63%)]\tLoss: 0.080212\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.059718\n",
      "Train Epoch: 15 [39040/60000 (65%)]\tLoss: 0.032888\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.067851\n",
      "Train Epoch: 15 [40320/60000 (67%)]\tLoss: 0.279884\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.120223\n",
      "Train Epoch: 15 [41600/60000 (69%)]\tLoss: 0.078911\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.024933\n",
      "Train Epoch: 15 [42880/60000 (71%)]\tLoss: 0.083595\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.020602\n",
      "Train Epoch: 15 [44160/60000 (74%)]\tLoss: 0.114715\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.057579\n",
      "Train Epoch: 15 [45440/60000 (76%)]\tLoss: 0.013319\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.018523\n",
      "Train Epoch: 15 [46720/60000 (78%)]\tLoss: 0.075248\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.036919\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.071151\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.037488\n",
      "Train Epoch: 15 [49280/60000 (82%)]\tLoss: 0.062437\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.081433\n",
      "Train Epoch: 15 [50560/60000 (84%)]\tLoss: 0.019686\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.124924\n",
      "Train Epoch: 15 [51840/60000 (86%)]\tLoss: 0.035508\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.062581\n",
      "Train Epoch: 15 [53120/60000 (88%)]\tLoss: 0.014014\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.049083\n",
      "Train Epoch: 15 [54400/60000 (91%)]\tLoss: 0.040916\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.009630\n",
      "Train Epoch: 15 [55680/60000 (93%)]\tLoss: 0.053250\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.034545\n",
      "Train Epoch: 15 [56960/60000 (95%)]\tLoss: 0.061841\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.017805\n",
      "Train Epoch: 15 [58240/60000 (97%)]\tLoss: 0.107926\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.055698\n",
      "Train Epoch: 15 [59520/60000 (99%)]\tLoss: 0.050536\n",
      "\n",
      "Test set: Avg. loss: 0.0801, Accuracy: 9749/10000 (97.5%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.008974\n",
      "Train Epoch: 16 [640/60000 (1%)]\tLoss: 0.049224\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.025526\n",
      "Train Epoch: 16 [1920/60000 (3%)]\tLoss: 0.026139\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.100287\n",
      "Train Epoch: 16 [3200/60000 (5%)]\tLoss: 0.067352\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.055236\n",
      "Train Epoch: 16 [4480/60000 (7%)]\tLoss: 0.034221\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.055912\n",
      "Train Epoch: 16 [5760/60000 (10%)]\tLoss: 0.149531\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.016988\n",
      "Train Epoch: 16 [7040/60000 (12%)]\tLoss: 0.016873\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.055022\n",
      "Train Epoch: 16 [8320/60000 (14%)]\tLoss: 0.080584\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.020813\n",
      "Train Epoch: 16 [9600/60000 (16%)]\tLoss: 0.038147\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.048829\n",
      "Train Epoch: 16 [10880/60000 (18%)]\tLoss: 0.028076\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.042783\n",
      "Train Epoch: 16 [12160/60000 (20%)]\tLoss: 0.017369\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.029772\n",
      "Train Epoch: 16 [13440/60000 (22%)]\tLoss: 0.040011\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.059377\n",
      "Train Epoch: 16 [14720/60000 (25%)]\tLoss: 0.012755\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.087063\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.066806\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.022028\n",
      "Train Epoch: 16 [17280/60000 (29%)]\tLoss: 0.018897\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.062826\n",
      "Train Epoch: 16 [18560/60000 (31%)]\tLoss: 0.019340\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.049447\n",
      "Train Epoch: 16 [19840/60000 (33%)]\tLoss: 0.035081\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.056598\n",
      "Train Epoch: 16 [21120/60000 (35%)]\tLoss: 0.013952\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.166778\n",
      "Train Epoch: 16 [22400/60000 (37%)]\tLoss: 0.095228\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.083412\n",
      "Train Epoch: 16 [23680/60000 (39%)]\tLoss: 0.036741\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.083797\n",
      "Train Epoch: 16 [24960/60000 (42%)]\tLoss: 0.045300\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.034399\n",
      "Train Epoch: 16 [26240/60000 (44%)]\tLoss: 0.079660\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.058931\n",
      "Train Epoch: 16 [27520/60000 (46%)]\tLoss: 0.026776\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.090907\n",
      "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.091528\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.022266\n",
      "Train Epoch: 16 [30080/60000 (50%)]\tLoss: 0.181648\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.039062\n",
      "Train Epoch: 16 [31360/60000 (52%)]\tLoss: 0.104400\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.046268\n",
      "Train Epoch: 16 [32640/60000 (54%)]\tLoss: 0.043665\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.031579\n",
      "Train Epoch: 16 [33920/60000 (57%)]\tLoss: 0.023620\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.126122\n",
      "Train Epoch: 16 [35200/60000 (59%)]\tLoss: 0.098514\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.083455\n",
      "Train Epoch: 16 [36480/60000 (61%)]\tLoss: 0.069281\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.052205\n",
      "Train Epoch: 16 [37760/60000 (63%)]\tLoss: 0.030049\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.024347\n",
      "Train Epoch: 16 [39040/60000 (65%)]\tLoss: 0.026318\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.154103\n",
      "Train Epoch: 16 [40320/60000 (67%)]\tLoss: 0.016412\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.025015\n",
      "Train Epoch: 16 [41600/60000 (69%)]\tLoss: 0.060916\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.057990\n",
      "Train Epoch: 16 [42880/60000 (71%)]\tLoss: 0.047194\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.045511\n",
      "Train Epoch: 16 [44160/60000 (74%)]\tLoss: 0.029949\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.037775\n",
      "Train Epoch: 16 [45440/60000 (76%)]\tLoss: 0.019358\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.045622\n",
      "Train Epoch: 16 [46720/60000 (78%)]\tLoss: 0.055112\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.025770\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.045717\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.062891\n",
      "Train Epoch: 16 [49280/60000 (82%)]\tLoss: 0.047630\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.035249\n",
      "Train Epoch: 16 [50560/60000 (84%)]\tLoss: 0.046274\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.079433\n",
      "Train Epoch: 16 [51840/60000 (86%)]\tLoss: 0.054865\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.022160\n",
      "Train Epoch: 16 [53120/60000 (88%)]\tLoss: 0.085477\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.116296\n",
      "Train Epoch: 16 [54400/60000 (91%)]\tLoss: 0.040462\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.039849\n",
      "Train Epoch: 16 [55680/60000 (93%)]\tLoss: 0.059158\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.019110\n",
      "Train Epoch: 16 [56960/60000 (95%)]\tLoss: 0.014632\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.103583\n",
      "Train Epoch: 16 [58240/60000 (97%)]\tLoss: 0.011327\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.054203\n",
      "Train Epoch: 16 [59520/60000 (99%)]\tLoss: 0.017832\n",
      "\n",
      "Test set: Avg. loss: 0.0773, Accuracy: 9770/10000 (97.7%)\n",
      "\n",
      "\n",
      "--- saving model for best accuracy ---\n",
      "--- saving finished ---\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.023301\n",
      "Train Epoch: 17 [640/60000 (1%)]\tLoss: 0.019396\n",
      "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.035551\n",
      "Train Epoch: 17 [1920/60000 (3%)]\tLoss: 0.039693\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.029009\n",
      "Train Epoch: 17 [3200/60000 (5%)]\tLoss: 0.022392\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.031409\n",
      "Train Epoch: 17 [4480/60000 (7%)]\tLoss: 0.045493\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.014655\n",
      "Train Epoch: 17 [5760/60000 (10%)]\tLoss: 0.020791\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.013927\n",
      "Train Epoch: 17 [7040/60000 (12%)]\tLoss: 0.054037\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.029809\n",
      "Train Epoch: 17 [8320/60000 (14%)]\tLoss: 0.047456\n",
      "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.035453\n",
      "Train Epoch: 17 [9600/60000 (16%)]\tLoss: 0.050034\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.056375\n",
      "Train Epoch: 17 [10880/60000 (18%)]\tLoss: 0.031859\n",
      "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.097949\n",
      "Train Epoch: 17 [12160/60000 (20%)]\tLoss: 0.025429\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.025954\n",
      "Train Epoch: 17 [13440/60000 (22%)]\tLoss: 0.055560\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.046849\n",
      "Train Epoch: 17 [14720/60000 (25%)]\tLoss: 0.013604\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.054143\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.042292\n",
      "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.035278\n",
      "Train Epoch: 17 [17280/60000 (29%)]\tLoss: 0.016129\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.015331\n",
      "Train Epoch: 17 [18560/60000 (31%)]\tLoss: 0.090075\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.088304\n",
      "Train Epoch: 17 [19840/60000 (33%)]\tLoss: 0.102341\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.102602\n",
      "Train Epoch: 17 [21120/60000 (35%)]\tLoss: 0.014583\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.024699\n",
      "Train Epoch: 17 [22400/60000 (37%)]\tLoss: 0.038480\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.069135\n",
      "Train Epoch: 17 [23680/60000 (39%)]\tLoss: 0.069404\n"
     ]
    }
   ],
   "source": [
    "model_name = \"base_net1\"\n",
    "acc_max = test(model1, test_loader)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch, model1, optimizer1, train_loader)\n",
    "    acc = test(model1, test_loader)\n",
    "    if acc > acc_max:\n",
    "        acc = acc_max\n",
    "        print()\n",
    "        print(\"--- saving model for best accuracy ---\")\n",
    "        #torch.save(model1.state_dict(), 'results/'+model_name+'.pth')\n",
    "        #torch.save(optimizer1.state_dict(), 'results/'+model_name+'_optimizer.pth')\n",
    "        print(\"--- saving finished ---\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model1.state_dict(), 'results/base_model.pth')\n",
    "#torch.save(optimizer1.state_dict(), 'results/base_optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "fig = plt.figure()\n",
    "model1.eval()\n",
    "output = model1(example_data.to(torch.device(\"cuda:0\"))).cpu().detach()\n",
    "prediction = torch.argmax(output, dim = 1)\n",
    "print(prediction)\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"G T: {} P: {}\".format(example_targets[i], prediction[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
